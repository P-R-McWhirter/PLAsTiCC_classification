{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from utilities import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import gc\n",
    "import itertools\n",
    "%matplotlib inline\n",
    "\n",
    "gc.enable()\n",
    "\n",
    "train = pd.read_csv('training_set.csv')\n",
    "train['flux_ratio_sq'] = np.power(train['flux'] / train['flux_err'], 2.0)\n",
    "train['flux_by_flux_ratio_sq'] = train['flux'] * train['flux_ratio_sq']\n",
    "train_det = train.where(train['detected'] == 1)\n",
    "\n",
    "aggs = {\n",
    "    'flux': ['min', 'max', 'mean', 'median', 'std','skew'],\n",
    "    'flux_err': ['min', 'max', 'mean', 'median', 'std','skew'],\n",
    "    'detected': ['mean'],\n",
    "    'flux_ratio_sq':['sum','skew'],\n",
    "    'flux_by_flux_ratio_sq':['sum','skew'],\n",
    "}\n",
    "\n",
    "aggs_det = {\n",
    "    'mjd': ['min', 'max', 'size'],\n",
    "    'passband': ['mean', 'std', 'var'],\n",
    "}\n",
    "\n",
    "agg_train = train.groupby('object_id').agg(aggs)\n",
    "agg_train_det = train_det.groupby('object_id').agg(aggs_det)\n",
    "\n",
    "new_columns = [\n",
    "    k + '_' + agg for k in aggs.keys() for agg in aggs[k]\n",
    "]\n",
    "new_columns_det = [\n",
    "    k + '_' + agg for k in aggs_det.keys() for agg in aggs_det[k]\n",
    "]\n",
    "\n",
    "agg_train.columns = new_columns\n",
    "agg_train['flux_diff'] = agg_train['flux_max'] - agg_train['flux_min']\n",
    "agg_train['flux_dif2'] = (agg_train['flux_max'] - agg_train['flux_min']) / agg_train['flux_mean']\n",
    "agg_train['flux_w_mean'] = agg_train['flux_by_flux_ratio_sq_sum'] / agg_train['flux_ratio_sq_sum']\n",
    "agg_train['flux_dif3'] = (agg_train['flux_max'] - agg_train['flux_min']) / agg_train['flux_w_mean']\n",
    "\n",
    "agg_train_det.columns = new_columns_det\n",
    "agg_train_det['mjd_diff'] = agg_train_det['mjd_max'] - agg_train_det['mjd_min']\n",
    "\n",
    "agg_train_det.columns = agg_train_det.columns + \"_det\"\n",
    "\n",
    "del agg_train_det['mjd_max_det'], agg_train_det['mjd_min_det']\n",
    "\n",
    "agg_train = pd.concat([agg_train, agg_train_det], axis=1, join='inner')\n",
    "\n",
    "del train, train_det, agg_train_det\n",
    "gc.collect()\n",
    "\n",
    "agg_train = agg_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                              | 0/6 [00:00<?, ?it/s]F:\\Documents\\Kaggle\\PLAsTiCC\\utilities.py:222: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  X[:,:,i_ch] = dat_.as_matrix()\n",
      "100%|██████████████████████████████████████████████████████████████████████| 6/6 [00:31<00:00,  5.21s/it]\n",
      "  0%|                                                                              | 0/6 [00:00<?, ?it/s]F:\\Documents\\Kaggle\\PLAsTiCC\\utilities.py:266: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  X[:,:,i_ch] = dat_.as_matrix()\n",
      "100%|██████████████████████████████████████████████████████████████████████| 6/6 [00:14<00:00,  2.40s/it]\n"
     ]
    }
   ],
   "source": [
    "X_feats = pd.read_csv('training_set_metadata_head.csv')\n",
    "X_feats = X_feats.iloc[:,np.array([7, 8, 9, 10])]\n",
    "X_feats['distmod'].fillna(0, inplace=True)\n",
    "X_feats = X_feats.values\n",
    "\n",
    "X_period = pd.read_csv('F:\\\\Documents\\\\Kaggle\\\\Results2\\\\lc_period.csv', header=None).values\n",
    "X_power = pd.read_csv('F:\\\\Documents\\\\Kaggle\\\\Results2\\\\lc_power.csv', header=None).values\n",
    "X_range = pd.read_csv('F:\\\\Documents\\\\Kaggle\\\\Results2\\\\lc_range.csv', header=None).values\n",
    "X_skew = pd.read_csv('F:\\\\Documents\\\\Kaggle\\\\Results2\\\\lc_skewness.csv', header=None).values\n",
    "\n",
    "X_feats = np.concatenate((X_feats, X_period, X_power, X_range, X_skew, agg_train), axis = 1)\n",
    "\n",
    "X_all, labels_all = read_data_all2(data_path=\"F:\\\\Documents\\\\Kaggle\\\\PLAsTiCC\")\n",
    "X_all_p, labels_all_p = read_data_all2_p(data_path=\"F:\\\\Documents\\\\Kaggle\\\\PLAsTiCC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize?\n",
    "X_all[:,1:1999,:] = standardize_full(X_all[:,1:1999,:])\n",
    "X_all_p = standardize_full(X_all_p)\n",
    "X_feats = standardize_feats_full(X_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.65604672, -0.51838063, -1.53349927, ...,  1.43768042,\n",
       "         1.60602404,  1.3282128 ],\n",
       "       [-0.65604672, -0.51838063, -1.53349927, ...,  0.17531013,\n",
       "        -0.01337359, -0.62363898],\n",
       "       [-0.65604672, -0.51838063, -1.53349927, ..., -0.02197492,\n",
       "        -0.21165453,  1.61488196],\n",
       "       ...,\n",
       "       [ 4.07982946,  3.38275786,  0.92914195, ...,  0.67226942,\n",
       "         0.55175057, -0.66359923],\n",
       "       [ 0.30872651, -0.03760535,  0.7052746 , ...,  0.37909655,\n",
       "         0.20699545, -0.71820108],\n",
       "       [-0.65604672, -0.51838063, -1.53349927, ...,  1.00470792,\n",
       "         0.98225836,  1.73802519]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, labels_train, labels_test = train_test_split(X_all, labels_all,\n",
    "                                                stratify = labels_all, random_state = 111, test_size = 0.2)\n",
    "\n",
    "X_train_feats, X_test_feats, _ , _ = train_test_split(X_feats, labels_all,\n",
    "                                                stratify = labels_all, random_state = 111, test_size = 0.2)\n",
    "\n",
    "X_train_p, X_test_p, _ , _ = train_test_split(X_all_p, labels_all,\n",
    "                                                stratify = labels_all, random_state = 111, test_size = 0.2)\n",
    "\n",
    "X_tr, X_vld, lab_tr, lab_vld = train_test_split(X_train, labels_train, \n",
    "                                                stratify = labels_train, random_state = 222, test_size = 0.2)\n",
    "\n",
    "X_tr_f, X_vld_f, lab_tr_f, lab_vld_f = train_test_split(X_train_feats, labels_train, \n",
    "                                                stratify = labels_train, random_state = 222, test_size = 0.2)\n",
    "\n",
    "X_tr_p, X_vld_p, lab_tr_p, lab_vld_p = train_test_split(X_train_p, labels_train, \n",
    "                                                stratify = labels_train, random_state = 222, test_size = 0.2)\n",
    "\n",
    "X_tr_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.65604672, -0.51838063, -1.53349927, ...,  1.43768042,\n",
       "         1.60602404,  1.3282128 ],\n",
       "       [-0.65604672, -0.51838063, -1.53349927, ...,  0.17531013,\n",
       "        -0.01337359, -0.62363898],\n",
       "       [-0.65604672, -0.51838063, -1.53349927, ..., -0.02197492,\n",
       "        -0.21165453,  1.61488196],\n",
       "       ...,\n",
       "       [ 4.07982946,  3.38275786,  0.92914195, ...,  0.67226942,\n",
       "         0.55175057, -0.66359923],\n",
       "       [ 0.30872651, -0.03760535,  0.7052746 , ...,  0.37909655,\n",
       "         0.20699545, -0.71820108],\n",
       "       [-0.65604672, -0.51838063, -1.53349927, ...,  1.00470792,\n",
       "         0.98225836,  1.73802519]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr = one_hot(lab_tr)\n",
    "y_vld = one_hot(lab_vld)\n",
    "y_test = one_hot(labels_test)\n",
    "\n",
    "X_tr_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ross\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100       # Batch size\n",
    "seq_len = 2000          # Number of steps\n",
    "learning_rate = 0.00002\n",
    "epochs = 1000\n",
    "\n",
    "n_classes = 14\n",
    "n_channels = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "# Construct placeholders\n",
    "with graph.as_default():\n",
    "    inputs_ = tf.placeholder(tf.float32, [None, seq_len, n_channels], name = 'inputs')\n",
    "    inputs2_ = tf.placeholder(tf.float32, [None, 34], name = 'inputs2')\n",
    "    inputs3_ = tf.placeholder(tf.float32, [None, seq_len/2, n_channels], name = 'inputs')\n",
    "    labels_ = tf.placeholder(tf.float32, [None, n_classes], name = 'labels')\n",
    "    keep_prob_ = tf.placeholder(tf.float32, name = 'keep')\n",
    "    learning_rate_ = tf.placeholder(tf.float32, name = 'learning_rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, 8, 64]\n",
      "[None, 4, 64]\n"
     ]
    }
   ],
   "source": [
    "with graph.as_default():\n",
    "    # (batch, 128, 9) --> (batch, 64, 18)\n",
    "    conv1 = tf.layers.conv1d(inputs=inputs_, filters=32, kernel_size=10, strides=2, \n",
    "                             padding='same', activation = tf.nn.relu)\n",
    "    max_pool_1 = tf.layers.max_pooling1d(inputs=conv1, pool_size=20, strides=2, padding='same')\n",
    "    \n",
    "    # (batch, 64, 18) --> (batch, 32, 36)\n",
    "    conv2 = tf.layers.conv1d(inputs=max_pool_1, filters=32, kernel_size=10, strides=2, \n",
    "                             padding='same', activation = tf.nn.relu)\n",
    "    max_pool_2 = tf.layers.max_pooling1d(inputs=conv2, pool_size=16, strides=2, padding='same')\n",
    "    \n",
    "    # (batch, 32, 36) --> (batch, 16, 72)\n",
    "    conv3 = tf.layers.conv1d(inputs=max_pool_2, filters=64, kernel_size=10, strides=2, \n",
    "                             padding='same', activation = tf.nn.relu)\n",
    "    max_pool_3 = tf.layers.max_pooling1d(inputs=conv3, pool_size=12, strides=2, padding='same')\n",
    "    \n",
    "    # (batch, 16, 72) --> (batch, 8, 144)\n",
    "    conv4 = tf.layers.conv1d(inputs=max_pool_3, filters=64, kernel_size=10, strides=2, \n",
    "                             padding='same', activation = tf.nn.relu)\n",
    "    max_pool_4 = tf.layers.max_pooling1d(inputs=conv4, pool_size=8, strides=2, padding='same')\n",
    "    \n",
    "with graph.as_default():\n",
    "    # (batch, 128, 9) --> (batch, 64, 18)\n",
    "    conv1_p = tf.layers.conv1d(inputs=inputs3_, filters=32, kernel_size=10, strides=2, \n",
    "                             padding='same', activation = tf.nn.relu)\n",
    "    max_pool_1_p = tf.layers.max_pooling1d(inputs=conv1_p, pool_size=10, strides=2, padding='same')\n",
    "    \n",
    "    # (batch, 64, 18) --> (batch, 32, 36)\n",
    "    conv2_p = tf.layers.conv1d(inputs=max_pool_1_p, filters=32, kernel_size=10, strides=2, \n",
    "                             padding='same', activation = tf.nn.relu)\n",
    "    max_pool_2_p = tf.layers.max_pooling1d(inputs=conv2_p, pool_size=8, strides=2, padding='same')\n",
    "    \n",
    "    # (batch, 32, 36) --> (batch, 16, 72)\n",
    "    conv3_p = tf.layers.conv1d(inputs=max_pool_2_p, filters=64, kernel_size=10, strides=2, \n",
    "                             padding='same', activation = tf.nn.relu)\n",
    "    max_pool_3_p = tf.layers.max_pooling1d(inputs=conv3_p, pool_size=6, strides=2, padding='same')\n",
    "    \n",
    "    # (batch, 16, 72) --> (batch, 8, 144)\n",
    "    conv4_p = tf.layers.conv1d(inputs=max_pool_3_p, filters=64, kernel_size=10, strides=2, \n",
    "                             padding='same', activation = tf.nn.relu)\n",
    "    max_pool_4_p = tf.layers.max_pooling1d(inputs=conv4_p, pool_size=4, strides=2, padding='same')\n",
    "    \n",
    "print(max_pool_4.get_shape().as_list())\n",
    "print(max_pool_4_p.get_shape().as_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, 832]\n"
     ]
    }
   ],
   "source": [
    "with graph.as_default():\n",
    "    # Flatten and add dropout\n",
    "    nnfeats = tf.layers.dense(inputs=inputs2_, units=512, activation=tf.nn.tanh)\n",
    "    nnfeats2 = tf.nn.dropout(nnfeats, keep_prob=keep_prob_)\n",
    "    nnfeats3 = tf.layers.dense(inputs=nnfeats2, units=256, activation=tf.nn.tanh)\n",
    "    nnfeats4 = tf.nn.dropout(nnfeats3, keep_prob=keep_prob_)\n",
    "    nnfeats5 = tf.layers.dense(inputs=nnfeats4, units=128, activation=tf.nn.tanh)\n",
    "    nnfeats6 = tf.nn.dropout(nnfeats5, keep_prob=keep_prob_)\n",
    "    nnfeats7 = tf.layers.dense(inputs=nnfeats6, units=64, activation=tf.nn.tanh)\n",
    "    nnfeats8 = tf.nn.dropout(nnfeats7, keep_prob=keep_prob_)\n",
    "    \n",
    "    flat = tf.concat([tf.reshape(max_pool_4, (-1, 8*64)), nnfeats8, tf.reshape(max_pool_4_p, (-1, 4*64))], 1)\n",
    "    flat2 = tf.nn.dropout(flat, keep_prob=keep_prob_)\n",
    "    flat3 = tf.layers.dense(inputs=flat2, units=512, activation=tf.nn.tanh)\n",
    "    flat4 = tf.nn.dropout(flat3, keep_prob=keep_prob_)\n",
    "    \n",
    "    # Predictions\n",
    "    logits = tf.layers.dense(flat4, n_classes)\n",
    "    \n",
    "    # Cost function and optimizer\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels_))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate_).minimize(cost)\n",
    "    \n",
    "    # Accuracy\n",
    "    correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(labels_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "    \n",
    "print(flat.get_shape().as_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (os.path.exists('checkpoints-cnn') == False):\n",
    "    !mkdir checkpoints-cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/600 Iteration: 5 Train loss: 2.775682 Train acc: 0.100000\n",
      "Epoch: 0/600 Iteration: 10 Train loss: 2.766908 Train acc: 0.110000\n",
      "Epoch: 0/600 Iteration: 10 Validation loss: 2.604243 Validation acc: 0.070833\n",
      "Epoch: 0/600 Iteration: 15 Train loss: 2.777820 Train acc: 0.110000\n",
      "Epoch: 0/600 Iteration: 20 Train loss: 2.659730 Train acc: 0.140000\n",
      "Epoch: 0/600 Iteration: 20 Validation loss: 2.573689 Validation acc: 0.088333\n",
      "Epoch: 0/600 Iteration: 25 Train loss: 2.723391 Train acc: 0.080000\n",
      "Epoch: 0/600 Iteration: 30 Train loss: 2.765467 Train acc: 0.070000\n",
      "Epoch: 0/600 Iteration: 30 Validation loss: 2.545670 Validation acc: 0.115833\n",
      "Epoch: 0/600 Iteration: 35 Train loss: 2.665018 Train acc: 0.100000\n",
      "Epoch: 0/600 Iteration: 40 Train loss: 2.798372 Train acc: 0.130000\n",
      "Epoch: 0/600 Iteration: 40 Validation loss: 2.519348 Validation acc: 0.162500\n",
      "Epoch: 0/600 Iteration: 45 Train loss: 2.684702 Train acc: 0.100000\n",
      "Epoch: 0/600 Iteration: 50 Train loss: 2.760364 Train acc: 0.090000\n",
      "Epoch: 0/600 Iteration: 50 Validation loss: 2.495559 Validation acc: 0.216667\n",
      "Epoch: 1/600 Iteration: 55 Train loss: 2.662495 Train acc: 0.110000\n",
      "Epoch: 1/600 Iteration: 60 Train loss: 2.692520 Train acc: 0.120000\n",
      "Epoch: 1/600 Iteration: 60 Validation loss: 2.472873 Validation acc: 0.265833\n",
      "Epoch: 1/600 Iteration: 65 Train loss: 2.732372 Train acc: 0.110000\n",
      "Epoch: 1/600 Iteration: 70 Train loss: 2.574081 Train acc: 0.120000\n",
      "Epoch: 1/600 Iteration: 70 Validation loss: 2.450412 Validation acc: 0.325833\n",
      "Epoch: 1/600 Iteration: 75 Train loss: 2.653860 Train acc: 0.100000\n",
      "Epoch: 1/600 Iteration: 80 Train loss: 2.616400 Train acc: 0.120000\n",
      "Epoch: 1/600 Iteration: 80 Validation loss: 2.428949 Validation acc: 0.372500\n",
      "Epoch: 1/600 Iteration: 85 Train loss: 2.645862 Train acc: 0.100000\n",
      "Epoch: 1/600 Iteration: 90 Train loss: 2.737933 Train acc: 0.110000\n",
      "Epoch: 1/600 Iteration: 90 Validation loss: 2.407233 Validation acc: 0.430000\n",
      "Epoch: 1/600 Iteration: 95 Train loss: 2.674253 Train acc: 0.110000\n",
      "Epoch: 1/600 Iteration: 100 Train loss: 2.605741 Train acc: 0.130000\n",
      "Epoch: 1/600 Iteration: 100 Validation loss: 2.386070 Validation acc: 0.464167\n",
      "Epoch: 2/600 Iteration: 105 Train loss: 2.531146 Train acc: 0.180000\n",
      "Epoch: 2/600 Iteration: 110 Train loss: 2.672565 Train acc: 0.100000\n",
      "Epoch: 2/600 Iteration: 110 Validation loss: 2.365098 Validation acc: 0.485833\n",
      "Epoch: 2/600 Iteration: 115 Train loss: 2.605334 Train acc: 0.140000\n",
      "Epoch: 2/600 Iteration: 120 Train loss: 2.538518 Train acc: 0.160000\n",
      "Epoch: 2/600 Iteration: 120 Validation loss: 2.343191 Validation acc: 0.504167\n",
      "Epoch: 2/600 Iteration: 125 Train loss: 2.579862 Train acc: 0.150000\n",
      "Epoch: 2/600 Iteration: 130 Train loss: 2.417321 Train acc: 0.210000\n",
      "Epoch: 2/600 Iteration: 130 Validation loss: 2.320803 Validation acc: 0.516667\n",
      "Epoch: 2/600 Iteration: 135 Train loss: 2.505727 Train acc: 0.190000\n",
      "Epoch: 2/600 Iteration: 140 Train loss: 2.571971 Train acc: 0.190000\n",
      "Epoch: 2/600 Iteration: 140 Validation loss: 2.298154 Validation acc: 0.522500\n",
      "Epoch: 2/600 Iteration: 145 Train loss: 2.548257 Train acc: 0.200000\n",
      "Epoch: 2/600 Iteration: 150 Train loss: 2.561076 Train acc: 0.100000\n",
      "Epoch: 2/600 Iteration: 150 Validation loss: 2.276721 Validation acc: 0.522500\n",
      "Epoch: 3/600 Iteration: 155 Train loss: 2.554798 Train acc: 0.140000\n",
      "Epoch: 3/600 Iteration: 160 Train loss: 2.522672 Train acc: 0.220000\n",
      "Epoch: 3/600 Iteration: 160 Validation loss: 2.254169 Validation acc: 0.523333\n",
      "Epoch: 3/600 Iteration: 165 Train loss: 2.493834 Train acc: 0.170000\n",
      "Epoch: 3/600 Iteration: 170 Train loss: 2.394427 Train acc: 0.200000\n",
      "Epoch: 3/600 Iteration: 170 Validation loss: 2.230079 Validation acc: 0.530000\n",
      "Epoch: 3/600 Iteration: 175 Train loss: 2.610808 Train acc: 0.190000\n",
      "Epoch: 3/600 Iteration: 180 Train loss: 2.415107 Train acc: 0.200000\n",
      "Epoch: 3/600 Iteration: 180 Validation loss: 2.206294 Validation acc: 0.530000\n",
      "Epoch: 3/600 Iteration: 185 Train loss: 2.508129 Train acc: 0.220000\n",
      "Epoch: 3/600 Iteration: 190 Train loss: 2.506835 Train acc: 0.210000\n",
      "Epoch: 3/600 Iteration: 190 Validation loss: 2.182768 Validation acc: 0.530833\n",
      "Epoch: 3/600 Iteration: 195 Train loss: 2.458505 Train acc: 0.170000\n",
      "Epoch: 3/600 Iteration: 200 Train loss: 2.394484 Train acc: 0.230000\n",
      "Epoch: 3/600 Iteration: 200 Validation loss: 2.158613 Validation acc: 0.535000\n",
      "Epoch: 4/600 Iteration: 205 Train loss: 2.365760 Train acc: 0.180000\n",
      "Epoch: 4/600 Iteration: 210 Train loss: 2.549331 Train acc: 0.190000\n",
      "Epoch: 4/600 Iteration: 210 Validation loss: 2.134332 Validation acc: 0.537500\n",
      "Epoch: 4/600 Iteration: 215 Train loss: 2.481265 Train acc: 0.180000\n",
      "Epoch: 4/600 Iteration: 220 Train loss: 2.331146 Train acc: 0.270000\n",
      "Epoch: 4/600 Iteration: 220 Validation loss: 2.108983 Validation acc: 0.538333\n",
      "Epoch: 4/600 Iteration: 225 Train loss: 2.406161 Train acc: 0.230000\n",
      "Epoch: 4/600 Iteration: 230 Train loss: 2.379982 Train acc: 0.220000\n",
      "Epoch: 4/600 Iteration: 230 Validation loss: 2.084698 Validation acc: 0.537500\n",
      "Epoch: 4/600 Iteration: 235 Train loss: 2.364334 Train acc: 0.280000\n",
      "Epoch: 4/600 Iteration: 240 Train loss: 2.384857 Train acc: 0.280000\n",
      "Epoch: 4/600 Iteration: 240 Validation loss: 2.059741 Validation acc: 0.539167\n",
      "Epoch: 4/600 Iteration: 245 Train loss: 2.512727 Train acc: 0.210000\n",
      "Epoch: 4/600 Iteration: 250 Train loss: 2.261240 Train acc: 0.300000\n",
      "Epoch: 4/600 Iteration: 250 Validation loss: 2.034571 Validation acc: 0.540000\n",
      "Epoch: 5/600 Iteration: 255 Train loss: 2.277440 Train acc: 0.390000\n",
      "Epoch: 5/600 Iteration: 260 Train loss: 2.526294 Train acc: 0.260000\n",
      "Epoch: 5/600 Iteration: 260 Validation loss: 2.010427 Validation acc: 0.538333\n",
      "Epoch: 5/600 Iteration: 265 Train loss: 2.289652 Train acc: 0.280000\n",
      "Epoch: 5/600 Iteration: 270 Train loss: 2.295155 Train acc: 0.300000\n",
      "Epoch: 5/600 Iteration: 270 Validation loss: 1.984111 Validation acc: 0.538333\n",
      "Epoch: 5/600 Iteration: 275 Train loss: 2.322225 Train acc: 0.320000\n",
      "Epoch: 5/600 Iteration: 280 Train loss: 2.245429 Train acc: 0.270000\n",
      "Epoch: 5/600 Iteration: 280 Validation loss: 1.956959 Validation acc: 0.539167\n",
      "Epoch: 5/600 Iteration: 285 Train loss: 2.266063 Train acc: 0.310000\n",
      "Epoch: 5/600 Iteration: 290 Train loss: 2.319526 Train acc: 0.320000\n",
      "Epoch: 5/600 Iteration: 290 Validation loss: 1.930857 Validation acc: 0.540000\n",
      "Epoch: 5/600 Iteration: 295 Train loss: 2.253811 Train acc: 0.300000\n",
      "Epoch: 5/600 Iteration: 300 Train loss: 2.198931 Train acc: 0.320000\n",
      "Epoch: 5/600 Iteration: 300 Validation loss: 1.904839 Validation acc: 0.541667\n",
      "Epoch: 6/600 Iteration: 305 Train loss: 2.271650 Train acc: 0.310000\n",
      "Epoch: 6/600 Iteration: 310 Train loss: 2.332829 Train acc: 0.280000\n",
      "Epoch: 6/600 Iteration: 310 Validation loss: 1.879230 Validation acc: 0.541667\n",
      "Epoch: 6/600 Iteration: 315 Train loss: 2.379502 Train acc: 0.320000\n",
      "Epoch: 6/600 Iteration: 320 Train loss: 2.260298 Train acc: 0.310000\n",
      "Epoch: 6/600 Iteration: 320 Validation loss: 1.852165 Validation acc: 0.541667\n",
      "Epoch: 6/600 Iteration: 325 Train loss: 2.265229 Train acc: 0.330000\n",
      "Epoch: 6/600 Iteration: 330 Train loss: 2.115896 Train acc: 0.350000\n",
      "Epoch: 6/600 Iteration: 330 Validation loss: 1.825764 Validation acc: 0.541667\n",
      "Epoch: 6/600 Iteration: 335 Train loss: 2.162846 Train acc: 0.360000\n",
      "Epoch: 6/600 Iteration: 340 Train loss: 2.166677 Train acc: 0.390000\n",
      "Epoch: 6/600 Iteration: 340 Validation loss: 1.801607 Validation acc: 0.542500\n",
      "Epoch: 6/600 Iteration: 345 Train loss: 2.276945 Train acc: 0.300000\n",
      "Epoch: 6/600 Iteration: 350 Train loss: 2.077897 Train acc: 0.360000\n",
      "Epoch: 6/600 Iteration: 350 Validation loss: 1.778658 Validation acc: 0.543333\n",
      "Epoch: 7/600 Iteration: 355 Train loss: 2.018191 Train acc: 0.440000\n",
      "Epoch: 7/600 Iteration: 360 Train loss: 2.285758 Train acc: 0.370000\n",
      "Epoch: 7/600 Iteration: 360 Validation loss: 1.756300 Validation acc: 0.542500\n",
      "Epoch: 7/600 Iteration: 365 Train loss: 2.165380 Train acc: 0.340000\n",
      "Epoch: 7/600 Iteration: 370 Train loss: 2.101277 Train acc: 0.410000\n",
      "Epoch: 7/600 Iteration: 370 Validation loss: 1.731646 Validation acc: 0.542500\n",
      "Epoch: 7/600 Iteration: 375 Train loss: 1.993338 Train acc: 0.420000\n",
      "Epoch: 7/600 Iteration: 380 Train loss: 2.097767 Train acc: 0.390000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/600 Iteration: 380 Validation loss: 1.709171 Validation acc: 0.543333\n",
      "Epoch: 7/600 Iteration: 385 Train loss: 2.065768 Train acc: 0.360000\n",
      "Epoch: 7/600 Iteration: 390 Train loss: 2.214712 Train acc: 0.360000\n",
      "Epoch: 7/600 Iteration: 390 Validation loss: 1.687847 Validation acc: 0.543333\n",
      "Epoch: 7/600 Iteration: 395 Train loss: 1.991967 Train acc: 0.430000\n",
      "Epoch: 7/600 Iteration: 400 Train loss: 2.063411 Train acc: 0.420000\n",
      "Epoch: 7/600 Iteration: 400 Validation loss: 1.668612 Validation acc: 0.542500\n",
      "Epoch: 8/600 Iteration: 405 Train loss: 2.004390 Train acc: 0.420000\n",
      "Epoch: 8/600 Iteration: 410 Train loss: 2.156096 Train acc: 0.390000\n",
      "Epoch: 8/600 Iteration: 410 Validation loss: 1.651346 Validation acc: 0.541667\n",
      "Epoch: 8/600 Iteration: 415 Train loss: 1.876970 Train acc: 0.470000\n",
      "Epoch: 8/600 Iteration: 420 Train loss: 2.075485 Train acc: 0.310000\n",
      "Epoch: 8/600 Iteration: 420 Validation loss: 1.634457 Validation acc: 0.540833\n",
      "Epoch: 8/600 Iteration: 425 Train loss: 2.009559 Train acc: 0.420000\n",
      "Epoch: 8/600 Iteration: 430 Train loss: 2.040527 Train acc: 0.370000\n",
      "Epoch: 8/600 Iteration: 430 Validation loss: 1.618271 Validation acc: 0.541667\n",
      "Epoch: 8/600 Iteration: 435 Train loss: 1.997539 Train acc: 0.400000\n",
      "Epoch: 8/600 Iteration: 440 Train loss: 1.961075 Train acc: 0.390000\n",
      "Epoch: 8/600 Iteration: 440 Validation loss: 1.603973 Validation acc: 0.542500\n",
      "Epoch: 8/600 Iteration: 445 Train loss: 1.985204 Train acc: 0.430000\n",
      "Epoch: 8/600 Iteration: 450 Train loss: 1.955659 Train acc: 0.440000\n",
      "Epoch: 8/600 Iteration: 450 Validation loss: 1.590939 Validation acc: 0.540833\n",
      "Epoch: 9/600 Iteration: 455 Train loss: 1.927382 Train acc: 0.390000\n",
      "Epoch: 9/600 Iteration: 460 Train loss: 2.069742 Train acc: 0.440000\n",
      "Epoch: 9/600 Iteration: 460 Validation loss: 1.578016 Validation acc: 0.540833\n",
      "Epoch: 9/600 Iteration: 465 Train loss: 1.938607 Train acc: 0.420000\n",
      "Epoch: 9/600 Iteration: 470 Train loss: 1.817838 Train acc: 0.470000\n",
      "Epoch: 9/600 Iteration: 470 Validation loss: 1.566048 Validation acc: 0.540833\n",
      "Epoch: 9/600 Iteration: 475 Train loss: 2.048260 Train acc: 0.410000\n",
      "Epoch: 9/600 Iteration: 480 Train loss: 1.985318 Train acc: 0.380000\n",
      "Epoch: 9/600 Iteration: 480 Validation loss: 1.555597 Validation acc: 0.540833\n",
      "Epoch: 9/600 Iteration: 485 Train loss: 1.914158 Train acc: 0.450000\n",
      "Epoch: 9/600 Iteration: 490 Train loss: 1.909904 Train acc: 0.430000\n",
      "Epoch: 9/600 Iteration: 490 Validation loss: 1.546174 Validation acc: 0.540833\n",
      "Epoch: 9/600 Iteration: 495 Train loss: 1.962629 Train acc: 0.370000\n",
      "Epoch: 9/600 Iteration: 500 Train loss: 1.826381 Train acc: 0.460000\n",
      "Epoch: 9/600 Iteration: 500 Validation loss: 1.536844 Validation acc: 0.543333\n",
      "Epoch: 10/600 Iteration: 505 Train loss: 1.927713 Train acc: 0.470000\n",
      "Epoch: 10/600 Iteration: 510 Train loss: 1.918519 Train acc: 0.440000\n",
      "Epoch: 10/600 Iteration: 510 Validation loss: 1.525816 Validation acc: 0.543333\n",
      "Epoch: 10/600 Iteration: 515 Train loss: 1.907944 Train acc: 0.470000\n",
      "Epoch: 10/600 Iteration: 520 Train loss: 1.840271 Train acc: 0.410000\n",
      "Epoch: 10/600 Iteration: 520 Validation loss: 1.515318 Validation acc: 0.544167\n",
      "Epoch: 10/600 Iteration: 525 Train loss: 1.772473 Train acc: 0.490000\n",
      "Epoch: 10/600 Iteration: 530 Train loss: 1.935851 Train acc: 0.360000\n",
      "Epoch: 10/600 Iteration: 530 Validation loss: 1.506242 Validation acc: 0.544167\n",
      "Epoch: 10/600 Iteration: 535 Train loss: 1.799824 Train acc: 0.460000\n",
      "Epoch: 10/600 Iteration: 540 Train loss: 1.763147 Train acc: 0.430000\n",
      "Epoch: 10/600 Iteration: 540 Validation loss: 1.498595 Validation acc: 0.545000\n",
      "Epoch: 10/600 Iteration: 545 Train loss: 1.853700 Train acc: 0.500000\n",
      "Epoch: 10/600 Iteration: 550 Train loss: 1.739701 Train acc: 0.490000\n",
      "Epoch: 10/600 Iteration: 550 Validation loss: 1.491870 Validation acc: 0.544167\n",
      "Epoch: 11/600 Iteration: 555 Train loss: 1.778545 Train acc: 0.450000\n",
      "Epoch: 11/600 Iteration: 560 Train loss: 1.862832 Train acc: 0.500000\n",
      "Epoch: 11/600 Iteration: 560 Validation loss: 1.482724 Validation acc: 0.544167\n",
      "Epoch: 11/600 Iteration: 565 Train loss: 1.866694 Train acc: 0.470000\n",
      "Epoch: 11/600 Iteration: 570 Train loss: 1.950462 Train acc: 0.370000\n",
      "Epoch: 11/600 Iteration: 570 Validation loss: 1.474080 Validation acc: 0.546667\n",
      "Epoch: 11/600 Iteration: 575 Train loss: 1.768480 Train acc: 0.470000\n",
      "Epoch: 11/600 Iteration: 580 Train loss: 1.903030 Train acc: 0.410000\n",
      "Epoch: 11/600 Iteration: 580 Validation loss: 1.468307 Validation acc: 0.545833\n",
      "Epoch: 11/600 Iteration: 585 Train loss: 1.785102 Train acc: 0.450000\n",
      "Epoch: 11/600 Iteration: 590 Train loss: 1.861606 Train acc: 0.440000\n",
      "Epoch: 11/600 Iteration: 590 Validation loss: 1.463976 Validation acc: 0.545000\n",
      "Epoch: 11/600 Iteration: 595 Train loss: 1.884322 Train acc: 0.420000\n",
      "Epoch: 11/600 Iteration: 600 Train loss: 1.586698 Train acc: 0.520000\n",
      "Epoch: 11/600 Iteration: 600 Validation loss: 1.458330 Validation acc: 0.544167\n",
      "Epoch: 12/600 Iteration: 605 Train loss: 1.671736 Train acc: 0.500000\n",
      "Epoch: 12/600 Iteration: 610 Train loss: 1.926283 Train acc: 0.450000\n",
      "Epoch: 12/600 Iteration: 610 Validation loss: 1.451204 Validation acc: 0.545000\n",
      "Epoch: 12/600 Iteration: 615 Train loss: 1.721173 Train acc: 0.510000\n",
      "Epoch: 12/600 Iteration: 620 Train loss: 1.779656 Train acc: 0.390000\n",
      "Epoch: 12/600 Iteration: 620 Validation loss: 1.443657 Validation acc: 0.545000\n",
      "Epoch: 12/600 Iteration: 625 Train loss: 1.745375 Train acc: 0.450000\n",
      "Epoch: 12/600 Iteration: 630 Train loss: 1.973523 Train acc: 0.370000\n",
      "Epoch: 12/600 Iteration: 630 Validation loss: 1.436297 Validation acc: 0.547500\n",
      "Epoch: 12/600 Iteration: 635 Train loss: 1.724286 Train acc: 0.460000\n",
      "Epoch: 12/600 Iteration: 640 Train loss: 1.712347 Train acc: 0.440000\n",
      "Epoch: 12/600 Iteration: 640 Validation loss: 1.430890 Validation acc: 0.547500\n",
      "Epoch: 12/600 Iteration: 645 Train loss: 1.767582 Train acc: 0.440000\n",
      "Epoch: 12/600 Iteration: 650 Train loss: 1.603423 Train acc: 0.490000\n",
      "Epoch: 12/600 Iteration: 650 Validation loss: 1.424664 Validation acc: 0.547500\n",
      "Epoch: 13/600 Iteration: 655 Train loss: 1.698586 Train acc: 0.480000\n",
      "Epoch: 13/600 Iteration: 660 Train loss: 1.876478 Train acc: 0.460000\n",
      "Epoch: 13/600 Iteration: 660 Validation loss: 1.416955 Validation acc: 0.547500\n",
      "Epoch: 13/600 Iteration: 665 Train loss: 1.732313 Train acc: 0.480000\n",
      "Epoch: 13/600 Iteration: 670 Train loss: 1.724703 Train acc: 0.490000\n",
      "Epoch: 13/600 Iteration: 670 Validation loss: 1.411844 Validation acc: 0.547500\n",
      "Epoch: 13/600 Iteration: 675 Train loss: 1.719397 Train acc: 0.450000\n",
      "Epoch: 13/600 Iteration: 680 Train loss: 1.723686 Train acc: 0.460000\n",
      "Epoch: 13/600 Iteration: 680 Validation loss: 1.407559 Validation acc: 0.548333\n",
      "Epoch: 13/600 Iteration: 685 Train loss: 1.706948 Train acc: 0.450000\n",
      "Epoch: 13/600 Iteration: 690 Train loss: 1.750991 Train acc: 0.460000\n",
      "Epoch: 13/600 Iteration: 690 Validation loss: 1.403632 Validation acc: 0.547500\n",
      "Epoch: 13/600 Iteration: 695 Train loss: 1.705225 Train acc: 0.480000\n",
      "Epoch: 13/600 Iteration: 700 Train loss: 1.617823 Train acc: 0.450000\n",
      "Epoch: 13/600 Iteration: 700 Validation loss: 1.399501 Validation acc: 0.548333\n",
      "Epoch: 14/600 Iteration: 705 Train loss: 1.607836 Train acc: 0.500000\n",
      "Epoch: 14/600 Iteration: 710 Train loss: 1.784719 Train acc: 0.510000\n",
      "Epoch: 14/600 Iteration: 710 Validation loss: 1.395119 Validation acc: 0.547500\n",
      "Epoch: 14/600 Iteration: 715 Train loss: 1.617331 Train acc: 0.570000\n",
      "Epoch: 14/600 Iteration: 720 Train loss: 1.756982 Train acc: 0.450000\n",
      "Epoch: 14/600 Iteration: 720 Validation loss: 1.388655 Validation acc: 0.547500\n",
      "Epoch: 14/600 Iteration: 725 Train loss: 1.702023 Train acc: 0.530000\n",
      "Epoch: 14/600 Iteration: 730 Train loss: 1.771425 Train acc: 0.430000\n",
      "Epoch: 14/600 Iteration: 730 Validation loss: 1.382006 Validation acc: 0.550000\n",
      "Epoch: 14/600 Iteration: 735 Train loss: 1.778495 Train acc: 0.460000\n",
      "Epoch: 14/600 Iteration: 740 Train loss: 1.650325 Train acc: 0.410000\n",
      "Epoch: 14/600 Iteration: 740 Validation loss: 1.378295 Validation acc: 0.549167\n",
      "Epoch: 14/600 Iteration: 745 Train loss: 1.676865 Train acc: 0.460000\n",
      "Epoch: 14/600 Iteration: 750 Train loss: 1.613267 Train acc: 0.450000\n",
      "Epoch: 14/600 Iteration: 750 Validation loss: 1.373934 Validation acc: 0.549167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15/600 Iteration: 755 Train loss: 1.703597 Train acc: 0.450000\n",
      "Epoch: 15/600 Iteration: 760 Train loss: 1.822989 Train acc: 0.420000\n",
      "Epoch: 15/600 Iteration: 760 Validation loss: 1.369974 Validation acc: 0.550000\n",
      "Epoch: 15/600 Iteration: 765 Train loss: 1.619920 Train acc: 0.490000\n",
      "Epoch: 15/600 Iteration: 770 Train loss: 1.645536 Train acc: 0.450000\n",
      "Epoch: 15/600 Iteration: 770 Validation loss: 1.365642 Validation acc: 0.550000\n",
      "Epoch: 15/600 Iteration: 775 Train loss: 1.676790 Train acc: 0.500000\n",
      "Epoch: 15/600 Iteration: 780 Train loss: 1.891579 Train acc: 0.380000\n",
      "Epoch: 15/600 Iteration: 780 Validation loss: 1.361409 Validation acc: 0.550000\n",
      "Epoch: 15/600 Iteration: 785 Train loss: 1.601577 Train acc: 0.540000\n",
      "Epoch: 15/600 Iteration: 790 Train loss: 1.650536 Train acc: 0.490000\n",
      "Epoch: 15/600 Iteration: 790 Validation loss: 1.356931 Validation acc: 0.551667\n",
      "Epoch: 15/600 Iteration: 795 Train loss: 1.644554 Train acc: 0.500000\n",
      "Epoch: 15/600 Iteration: 800 Train loss: 1.438960 Train acc: 0.520000\n",
      "Epoch: 15/600 Iteration: 800 Validation loss: 1.352129 Validation acc: 0.552500\n",
      "Epoch: 16/600 Iteration: 805 Train loss: 1.612929 Train acc: 0.480000\n",
      "Epoch: 16/600 Iteration: 810 Train loss: 1.794593 Train acc: 0.500000\n",
      "Epoch: 16/600 Iteration: 810 Validation loss: 1.347470 Validation acc: 0.550833\n",
      "Epoch: 16/600 Iteration: 815 Train loss: 1.604716 Train acc: 0.570000\n",
      "Epoch: 16/600 Iteration: 820 Train loss: 1.743384 Train acc: 0.440000\n",
      "Epoch: 16/600 Iteration: 820 Validation loss: 1.343614 Validation acc: 0.551667\n",
      "Epoch: 16/600 Iteration: 825 Train loss: 1.615506 Train acc: 0.440000\n",
      "Epoch: 16/600 Iteration: 830 Train loss: 1.773535 Train acc: 0.510000\n",
      "Epoch: 16/600 Iteration: 830 Validation loss: 1.340415 Validation acc: 0.551667\n",
      "Epoch: 16/600 Iteration: 835 Train loss: 1.598703 Train acc: 0.540000\n",
      "Epoch: 16/600 Iteration: 840 Train loss: 1.627563 Train acc: 0.510000\n",
      "Epoch: 16/600 Iteration: 840 Validation loss: 1.336731 Validation acc: 0.554167\n",
      "Epoch: 16/600 Iteration: 845 Train loss: 1.515897 Train acc: 0.450000\n",
      "Epoch: 16/600 Iteration: 850 Train loss: 1.456723 Train acc: 0.550000\n",
      "Epoch: 16/600 Iteration: 850 Validation loss: 1.331160 Validation acc: 0.555833\n",
      "Epoch: 17/600 Iteration: 855 Train loss: 1.607270 Train acc: 0.480000\n",
      "Epoch: 17/600 Iteration: 860 Train loss: 1.698228 Train acc: 0.460000\n",
      "Epoch: 17/600 Iteration: 860 Validation loss: 1.326300 Validation acc: 0.557500\n",
      "Epoch: 17/600 Iteration: 865 Train loss: 1.628030 Train acc: 0.520000\n",
      "Epoch: 17/600 Iteration: 870 Train loss: 1.623492 Train acc: 0.480000\n",
      "Epoch: 17/600 Iteration: 870 Validation loss: 1.323558 Validation acc: 0.558333\n",
      "Epoch: 17/600 Iteration: 875 Train loss: 1.629262 Train acc: 0.470000\n",
      "Epoch: 17/600 Iteration: 880 Train loss: 1.673096 Train acc: 0.430000\n",
      "Epoch: 17/600 Iteration: 880 Validation loss: 1.321488 Validation acc: 0.559167\n",
      "Epoch: 17/600 Iteration: 885 Train loss: 1.624877 Train acc: 0.520000\n",
      "Epoch: 17/600 Iteration: 890 Train loss: 1.485898 Train acc: 0.530000\n",
      "Epoch: 17/600 Iteration: 890 Validation loss: 1.318550 Validation acc: 0.559167\n",
      "Epoch: 17/600 Iteration: 895 Train loss: 1.569334 Train acc: 0.530000\n",
      "Epoch: 17/600 Iteration: 900 Train loss: 1.454727 Train acc: 0.570000\n",
      "Epoch: 17/600 Iteration: 900 Validation loss: 1.315115 Validation acc: 0.560000\n",
      "Epoch: 18/600 Iteration: 905 Train loss: 1.501976 Train acc: 0.440000\n",
      "Epoch: 18/600 Iteration: 910 Train loss: 1.522974 Train acc: 0.560000\n",
      "Epoch: 18/600 Iteration: 910 Validation loss: 1.311936 Validation acc: 0.561667\n",
      "Epoch: 18/600 Iteration: 915 Train loss: 1.642954 Train acc: 0.530000\n",
      "Epoch: 18/600 Iteration: 920 Train loss: 1.569335 Train acc: 0.480000\n",
      "Epoch: 18/600 Iteration: 920 Validation loss: 1.307910 Validation acc: 0.561667\n",
      "Epoch: 18/600 Iteration: 925 Train loss: 1.567828 Train acc: 0.500000\n",
      "Epoch: 18/600 Iteration: 930 Train loss: 1.634455 Train acc: 0.480000\n",
      "Epoch: 18/600 Iteration: 930 Validation loss: 1.304776 Validation acc: 0.562500\n",
      "Epoch: 18/600 Iteration: 935 Train loss: 1.533329 Train acc: 0.490000\n",
      "Epoch: 18/600 Iteration: 940 Train loss: 1.471461 Train acc: 0.510000\n",
      "Epoch: 18/600 Iteration: 940 Validation loss: 1.302358 Validation acc: 0.564167\n",
      "Epoch: 18/600 Iteration: 945 Train loss: 1.518373 Train acc: 0.550000\n",
      "Epoch: 18/600 Iteration: 950 Train loss: 1.538121 Train acc: 0.510000\n",
      "Epoch: 18/600 Iteration: 950 Validation loss: 1.300956 Validation acc: 0.566667\n",
      "Epoch: 19/600 Iteration: 955 Train loss: 1.632294 Train acc: 0.490000\n",
      "Epoch: 19/600 Iteration: 960 Train loss: 1.699037 Train acc: 0.480000\n",
      "Epoch: 19/600 Iteration: 960 Validation loss: 1.296603 Validation acc: 0.567500\n",
      "Epoch: 19/600 Iteration: 965 Train loss: 1.420802 Train acc: 0.580000\n",
      "Epoch: 19/600 Iteration: 970 Train loss: 1.639902 Train acc: 0.490000\n",
      "Epoch: 19/600 Iteration: 970 Validation loss: 1.293191 Validation acc: 0.570000\n",
      "Epoch: 19/600 Iteration: 975 Train loss: 1.457055 Train acc: 0.540000\n",
      "Epoch: 19/600 Iteration: 980 Train loss: 1.616949 Train acc: 0.430000\n",
      "Epoch: 19/600 Iteration: 980 Validation loss: 1.290799 Validation acc: 0.570000\n",
      "Epoch: 19/600 Iteration: 985 Train loss: 1.535530 Train acc: 0.540000\n",
      "Epoch: 19/600 Iteration: 990 Train loss: 1.495491 Train acc: 0.480000\n",
      "Epoch: 19/600 Iteration: 990 Validation loss: 1.289361 Validation acc: 0.570833\n",
      "Epoch: 19/600 Iteration: 995 Train loss: 1.598744 Train acc: 0.440000\n",
      "Epoch: 19/600 Iteration: 1000 Train loss: 1.464983 Train acc: 0.510000\n",
      "Epoch: 19/600 Iteration: 1000 Validation loss: 1.287485 Validation acc: 0.571667\n",
      "Epoch: 20/600 Iteration: 1005 Train loss: 1.490158 Train acc: 0.510000\n",
      "Epoch: 20/600 Iteration: 1010 Train loss: 1.562753 Train acc: 0.470000\n",
      "Epoch: 20/600 Iteration: 1010 Validation loss: 1.284016 Validation acc: 0.571667\n",
      "Epoch: 20/600 Iteration: 1015 Train loss: 1.499538 Train acc: 0.580000\n",
      "Epoch: 20/600 Iteration: 1020 Train loss: 1.580120 Train acc: 0.460000\n",
      "Epoch: 20/600 Iteration: 1020 Validation loss: 1.281272 Validation acc: 0.572500\n",
      "Epoch: 20/600 Iteration: 1025 Train loss: 1.573932 Train acc: 0.470000\n",
      "Epoch: 20/600 Iteration: 1030 Train loss: 1.579731 Train acc: 0.490000\n",
      "Epoch: 20/600 Iteration: 1030 Validation loss: 1.279586 Validation acc: 0.573333\n",
      "Epoch: 20/600 Iteration: 1035 Train loss: 1.490927 Train acc: 0.520000\n",
      "Epoch: 20/600 Iteration: 1040 Train loss: 1.369015 Train acc: 0.530000\n",
      "Epoch: 20/600 Iteration: 1040 Validation loss: 1.277659 Validation acc: 0.573333\n",
      "Epoch: 20/600 Iteration: 1045 Train loss: 1.453802 Train acc: 0.540000\n",
      "Epoch: 20/600 Iteration: 1050 Train loss: 1.344433 Train acc: 0.520000\n",
      "Epoch: 20/600 Iteration: 1050 Validation loss: 1.276094 Validation acc: 0.574167\n",
      "Epoch: 21/600 Iteration: 1055 Train loss: 1.450362 Train acc: 0.500000\n",
      "Epoch: 21/600 Iteration: 1060 Train loss: 1.544106 Train acc: 0.490000\n",
      "Epoch: 21/600 Iteration: 1060 Validation loss: 1.272851 Validation acc: 0.575000\n",
      "Epoch: 21/600 Iteration: 1065 Train loss: 1.377550 Train acc: 0.570000\n",
      "Epoch: 21/600 Iteration: 1070 Train loss: 1.530421 Train acc: 0.520000\n",
      "Epoch: 21/600 Iteration: 1070 Validation loss: 1.270688 Validation acc: 0.575833\n",
      "Epoch: 21/600 Iteration: 1075 Train loss: 1.625672 Train acc: 0.460000\n",
      "Epoch: 21/600 Iteration: 1080 Train loss: 1.625618 Train acc: 0.470000\n",
      "Epoch: 21/600 Iteration: 1080 Validation loss: 1.268783 Validation acc: 0.576667\n",
      "Epoch: 21/600 Iteration: 1085 Train loss: 1.563145 Train acc: 0.470000\n",
      "Epoch: 21/600 Iteration: 1090 Train loss: 1.399140 Train acc: 0.530000\n",
      "Epoch: 21/600 Iteration: 1090 Validation loss: 1.267458 Validation acc: 0.575833\n",
      "Epoch: 21/600 Iteration: 1095 Train loss: 1.524222 Train acc: 0.490000\n",
      "Epoch: 21/600 Iteration: 1100 Train loss: 1.417323 Train acc: 0.530000\n",
      "Epoch: 21/600 Iteration: 1100 Validation loss: 1.265810 Validation acc: 0.579167\n",
      "Epoch: 22/600 Iteration: 1105 Train loss: 1.442431 Train acc: 0.560000\n",
      "Epoch: 22/600 Iteration: 1110 Train loss: 1.509797 Train acc: 0.520000\n",
      "Epoch: 22/600 Iteration: 1110 Validation loss: 1.264017 Validation acc: 0.578333\n",
      "Epoch: 22/600 Iteration: 1115 Train loss: 1.340120 Train acc: 0.620000\n",
      "Epoch: 22/600 Iteration: 1120 Train loss: 1.448111 Train acc: 0.540000\n",
      "Epoch: 22/600 Iteration: 1120 Validation loss: 1.260550 Validation acc: 0.578333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22/600 Iteration: 1125 Train loss: 1.472625 Train acc: 0.560000\n",
      "Epoch: 22/600 Iteration: 1130 Train loss: 1.629639 Train acc: 0.480000\n",
      "Epoch: 22/600 Iteration: 1130 Validation loss: 1.258265 Validation acc: 0.579167\n",
      "Epoch: 22/600 Iteration: 1135 Train loss: 1.495597 Train acc: 0.550000\n",
      "Epoch: 22/600 Iteration: 1140 Train loss: 1.461803 Train acc: 0.540000\n",
      "Epoch: 22/600 Iteration: 1140 Validation loss: 1.256047 Validation acc: 0.580000\n",
      "Epoch: 22/600 Iteration: 1145 Train loss: 1.541895 Train acc: 0.490000\n",
      "Epoch: 22/600 Iteration: 1150 Train loss: 1.481341 Train acc: 0.490000\n",
      "Epoch: 22/600 Iteration: 1150 Validation loss: 1.253653 Validation acc: 0.581667\n",
      "Epoch: 23/600 Iteration: 1155 Train loss: 1.452740 Train acc: 0.510000\n",
      "Epoch: 23/600 Iteration: 1160 Train loss: 1.683107 Train acc: 0.460000\n",
      "Epoch: 23/600 Iteration: 1160 Validation loss: 1.250184 Validation acc: 0.581667\n",
      "Epoch: 23/600 Iteration: 1165 Train loss: 1.401970 Train acc: 0.570000\n",
      "Epoch: 23/600 Iteration: 1170 Train loss: 1.469259 Train acc: 0.540000\n",
      "Epoch: 23/600 Iteration: 1170 Validation loss: 1.248437 Validation acc: 0.581667\n",
      "Epoch: 23/600 Iteration: 1175 Train loss: 1.594494 Train acc: 0.520000\n",
      "Epoch: 23/600 Iteration: 1180 Train loss: 1.443430 Train acc: 0.490000\n",
      "Epoch: 23/600 Iteration: 1180 Validation loss: 1.247730 Validation acc: 0.583333\n",
      "Epoch: 23/600 Iteration: 1185 Train loss: 1.441410 Train acc: 0.540000\n",
      "Epoch: 23/600 Iteration: 1190 Train loss: 1.332534 Train acc: 0.570000\n",
      "Epoch: 23/600 Iteration: 1190 Validation loss: 1.246340 Validation acc: 0.582500\n",
      "Epoch: 23/600 Iteration: 1195 Train loss: 1.549661 Train acc: 0.500000\n",
      "Epoch: 23/600 Iteration: 1200 Train loss: 1.378906 Train acc: 0.560000\n",
      "Epoch: 23/600 Iteration: 1200 Validation loss: 1.243494 Validation acc: 0.584167\n",
      "Epoch: 24/600 Iteration: 1205 Train loss: 1.402689 Train acc: 0.500000\n",
      "Epoch: 24/600 Iteration: 1210 Train loss: 1.528074 Train acc: 0.520000\n",
      "Epoch: 24/600 Iteration: 1210 Validation loss: 1.240251 Validation acc: 0.586667\n",
      "Epoch: 24/600 Iteration: 1215 Train loss: 1.411724 Train acc: 0.620000\n",
      "Epoch: 24/600 Iteration: 1220 Train loss: 1.497150 Train acc: 0.490000\n",
      "Epoch: 24/600 Iteration: 1220 Validation loss: 1.238262 Validation acc: 0.587500\n",
      "Epoch: 24/600 Iteration: 1225 Train loss: 1.580739 Train acc: 0.520000\n",
      "Epoch: 24/600 Iteration: 1230 Train loss: 1.493307 Train acc: 0.560000\n",
      "Epoch: 24/600 Iteration: 1230 Validation loss: 1.236992 Validation acc: 0.587500\n",
      "Epoch: 24/600 Iteration: 1235 Train loss: 1.480250 Train acc: 0.520000\n",
      "Epoch: 24/600 Iteration: 1240 Train loss: 1.456792 Train acc: 0.520000\n",
      "Epoch: 24/600 Iteration: 1240 Validation loss: 1.236036 Validation acc: 0.588333\n",
      "Epoch: 24/600 Iteration: 1245 Train loss: 1.482197 Train acc: 0.540000\n",
      "Epoch: 24/600 Iteration: 1250 Train loss: 1.409275 Train acc: 0.500000\n",
      "Epoch: 24/600 Iteration: 1250 Validation loss: 1.234738 Validation acc: 0.589167\n",
      "Epoch: 25/600 Iteration: 1255 Train loss: 1.394215 Train acc: 0.520000\n",
      "Epoch: 25/600 Iteration: 1260 Train loss: 1.520788 Train acc: 0.510000\n",
      "Epoch: 25/600 Iteration: 1260 Validation loss: 1.232149 Validation acc: 0.589167\n",
      "Epoch: 25/600 Iteration: 1265 Train loss: 1.384649 Train acc: 0.590000\n",
      "Epoch: 25/600 Iteration: 1270 Train loss: 1.490216 Train acc: 0.480000\n",
      "Epoch: 25/600 Iteration: 1270 Validation loss: 1.231232 Validation acc: 0.588333\n",
      "Epoch: 25/600 Iteration: 1275 Train loss: 1.507946 Train acc: 0.470000\n",
      "Epoch: 25/600 Iteration: 1280 Train loss: 1.586308 Train acc: 0.460000\n",
      "Epoch: 25/600 Iteration: 1280 Validation loss: 1.231469 Validation acc: 0.590000\n",
      "Epoch: 25/600 Iteration: 1285 Train loss: 1.428048 Train acc: 0.550000\n",
      "Epoch: 25/600 Iteration: 1290 Train loss: 1.342281 Train acc: 0.510000\n",
      "Epoch: 25/600 Iteration: 1290 Validation loss: 1.231275 Validation acc: 0.589167\n",
      "Epoch: 25/600 Iteration: 1295 Train loss: 1.481004 Train acc: 0.560000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-ba62a7e7e93f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[1;31m# Loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m             \u001b[0mtrain_acc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[0mtrain_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 889\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    890\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1120\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1317\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1318\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1322\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1323\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1324\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1302\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1304\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "validation_acc = []\n",
    "validation_loss = []\n",
    "\n",
    "train_acc = []\n",
    "train_loss = []\n",
    "\n",
    "with graph.as_default():\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    iteration = 1\n",
    "   \n",
    "    # Loop over epochs\n",
    "    for e in range(epochs):\n",
    "        \n",
    "        # Loop over batches\n",
    "        for x,y,x_f,x_p in get_batches(X_tr, y_tr, X_tr_f, X_tr_p, batch_size):\n",
    "            \n",
    "            # Feed dictionary\n",
    "            feed = {inputs_ : x, labels_ : y, inputs2_ : x_f, inputs3_ : x_p, keep_prob_ : 0.5, learning_rate_ : learning_rate}\n",
    "            \n",
    "            # Loss\n",
    "            loss, _ , acc = sess.run([cost, optimizer, accuracy], feed_dict = feed)\n",
    "            train_acc.append(acc)\n",
    "            train_loss.append(loss)\n",
    "            \n",
    "            # Print at each 5 iters\n",
    "            if (iteration % 5 == 0):\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {:d}\".format(iteration),\n",
    "                      \"Train loss: {:6f}\".format(loss),\n",
    "                      \"Train acc: {:.6f}\".format(acc))\n",
    "            \n",
    "            # Compute validation loss at every 10 iterations\n",
    "            if (iteration%10 == 0):                \n",
    "                val_acc_ = []\n",
    "                val_loss_ = []\n",
    "                \n",
    "                for x_v, y_v, x_v_f, x_v_p in get_batches(X_vld, y_vld, X_vld_f, X_vld_p, batch_size):\n",
    "                    # Feed\n",
    "                    feed = {inputs_ : x_v, inputs2_ : x_v_f, inputs3_ : x_v_p, labels_ : y_v, keep_prob_ : 1.0}  \n",
    "                    \n",
    "                    # Loss\n",
    "                    loss_v, acc_v = sess.run([cost, accuracy], feed_dict = feed)                    \n",
    "                    val_acc_.append(acc_v)\n",
    "                    val_loss_.append(loss_v)\n",
    "                \n",
    "                # Print info\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {:d}\".format(iteration),\n",
    "                      \"Validation loss: {:6f}\".format(np.mean(val_loss_)),\n",
    "                      \"Validation acc: {:.6f}\".format(np.mean(val_acc_)))\n",
    "                \n",
    "                # Store\n",
    "                validation_acc.append(np.mean(val_acc_))\n",
    "                validation_loss.append(np.mean(val_loss_))\n",
    "            \n",
    "            # Iterate \n",
    "            iteration += 1\n",
    "    \n",
    "    saver.save(sess,\"checkpoints-cnn/har.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and test loss\n",
    "t = np.arange(iteration-1)\n",
    "\n",
    "plt.figure(figsize = (6,6))\n",
    "plt.plot(t, np.array(train_loss), 'r-', t[t % 10 == 0], np.array(validation_loss), 'b*')\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Accuracies\n",
    "plt.figure(figsize = (6,6))\n",
    "\n",
    "plt.plot(t, np.array(train_acc), 'r-', t[t % 10 == 0], validation_acc, 'b*')\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"Accuray\")\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = []\n",
    "test_loss = []\n",
    "test_pred = []\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    # Restore\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints-cnn'))\n",
    "    \n",
    "    for x_t, y_t, x_t_f, x_t_p in get_batches(X_test, y_test, X_test_feats, X_test_p, 157):\n",
    "        feed = {inputs_: x_t,\n",
    "                labels_: y_t,\n",
    "                inputs2_: x_t_f,\n",
    "                inputs3_: x_t_p,\n",
    "                keep_prob_: 1}\n",
    "        \n",
    "        batch_loss, batch_acc = sess.run([cost, accuracy], feed_dict=feed)\n",
    "        test_acc.append(batch_acc)\n",
    "        test_loss.append(batch_loss)\n",
    "        \n",
    "        predict=tf.argmax(logits,1)\n",
    "        best = predict.eval(feed_dict=feed)\n",
    "        test_pred.append(best)\n",
    "    \n",
    "    print(\"Test accuracy: {:.6f}\".format(np.mean(test_acc)))\n",
    "    print(\"Test loss: {:.6f}\".format(np.mean(test_loss)))\n",
    "    \n",
    "    oof_preds = np.concatenate(test_pred, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.asarray(labels_test))\n",
    "\n",
    "print(oof_preds+1)\n",
    "\n",
    "cnf_matrix = confusion_matrix(np.asarray(labels_test), oof_preds+1)\n",
    "sample_sub = pd.read_csv('sample_submission.csv')\n",
    "class_names = list(sample_sub.columns[1:-1])\n",
    "del sample_sub;gc.collect()\n",
    "plt.figure(figsize=(12,12))\n",
    "foo = plot_confusion_matrix(cnf_matrix, classes=class_names,normalize=True,\n",
    "                      title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
