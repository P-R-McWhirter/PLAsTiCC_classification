{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from utilities import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import gc\n",
    "import itertools\n",
    "%matplotlib inline\n",
    "\n",
    "gc.enable()\n",
    "\n",
    "train = pd.read_csv('training_set.csv')\n",
    "train['flux_ratio_sq'] = np.power(train['flux'] / train['flux_err'], 2.0)\n",
    "train['flux_by_flux_ratio_sq'] = train['flux'] * train['flux_ratio_sq']\n",
    "train_det = train.where(train['detected'] == 1)\n",
    "\n",
    "aggs = {\n",
    "    'flux': ['min', 'max', 'mean', 'median', 'std','skew'],\n",
    "    'flux_err': ['min', 'max', 'mean', 'median', 'std','skew'],\n",
    "    'detected': ['mean'],\n",
    "    'flux_ratio_sq':['sum','skew'],\n",
    "    'flux_by_flux_ratio_sq':['sum','skew'],\n",
    "}\n",
    "\n",
    "aggs_det = {\n",
    "    'mjd': ['min', 'max', 'size'],\n",
    "    'passband': ['mean', 'std', 'var'],\n",
    "}\n",
    "\n",
    "agg_train = train.groupby('object_id').agg(aggs)\n",
    "agg_train_det = train_det.groupby('object_id').agg(aggs_det)\n",
    "\n",
    "new_columns = [\n",
    "    k + '_' + agg for k in aggs.keys() for agg in aggs[k]\n",
    "]\n",
    "new_columns_det = [\n",
    "    k + '_' + agg for k in aggs_det.keys() for agg in aggs_det[k]\n",
    "]\n",
    "\n",
    "agg_train.columns = new_columns\n",
    "agg_train['flux_diff'] = agg_train['flux_max'] - agg_train['flux_min']\n",
    "agg_train['flux_dif2'] = (agg_train['flux_max'] - agg_train['flux_min']) / agg_train['flux_mean']\n",
    "agg_train['flux_w_mean'] = agg_train['flux_by_flux_ratio_sq_sum'] / agg_train['flux_ratio_sq_sum']\n",
    "agg_train['flux_dif3'] = (agg_train['flux_max'] - agg_train['flux_min']) / agg_train['flux_w_mean']\n",
    "\n",
    "agg_train_det.columns = new_columns_det\n",
    "agg_train_det['mjd_diff'] = agg_train_det['mjd_max'] - agg_train_det['mjd_min']\n",
    "\n",
    "agg_train_det.columns = agg_train_det.columns + \"_det\"\n",
    "\n",
    "del agg_train_det['mjd_max_det'], agg_train_det['mjd_min_det']\n",
    "\n",
    "agg_train = pd.concat([agg_train, agg_train_det], axis=1, join='inner')\n",
    "\n",
    "del train, train_det, agg_train_det\n",
    "gc.collect()\n",
    "\n",
    "agg_train = agg_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                              | 0/6 [00:00<?, ?it/s]F:\\Documents\\Kaggle\\PLAsTiCC\\utilities.py:222: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  X[:,:,i_ch] = dat_.as_matrix()\n",
      "100%|██████████████████████████████████████████████████████████████████████| 6/6 [00:31<00:00,  5.30s/it]\n",
      "  0%|                                                                              | 0/6 [00:00<?, ?it/s]F:\\Documents\\Kaggle\\PLAsTiCC\\utilities.py:266: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  X[:,:,i_ch] = dat_.as_matrix()\n",
      "100%|██████████████████████████████████████████████████████████████████████| 6/6 [00:14<00:00,  2.39s/it]\n"
     ]
    }
   ],
   "source": [
    "X_feats = pd.read_csv('training_set_metadata_head.csv')\n",
    "X_feats = X_feats.iloc[:,np.array([7, 8, 9, 10])]\n",
    "X_feats['distmod'].fillna(0, inplace=True)\n",
    "X_feats = X_feats.values\n",
    "\n",
    "X_period = pd.read_csv('F:\\\\Documents\\\\Kaggle\\\\Results2\\\\lc_period.csv', header=None).values\n",
    "X_power = pd.read_csv('F:\\\\Documents\\\\Kaggle\\\\Results2\\\\lc_power.csv', header=None).values\n",
    "X_range = pd.read_csv('F:\\\\Documents\\\\Kaggle\\\\Results2\\\\lc_range.csv', header=None).values\n",
    "X_skew = pd.read_csv('F:\\\\Documents\\\\Kaggle\\\\Results2\\\\lc_skewness.csv', header=None).values\n",
    "\n",
    "X_feats = np.concatenate((X_feats, X_period, X_power, X_range, X_skew, agg_train), axis = 1)\n",
    "\n",
    "X_all, labels_all = read_data_all2(data_path=\"F:\\\\Documents\\\\Kaggle\\\\PLAsTiCC\")\n",
    "X_all_p, labels_all_p = read_data_all2_p(data_path=\"F:\\\\Documents\\\\Kaggle\\\\PLAsTiCC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize?\n",
    "X_all[:,1:1999,:] = standardize_full(X_all[:,1:1999,:])\n",
    "X_all_p = standardize_full(X_all_p)\n",
    "X_feats = standardize_feats_full(X_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.65604672, -0.51838063, -1.53349927, ...,  1.43768042,\n",
       "         1.60602404,  1.3282128 ],\n",
       "       [-0.65604672, -0.51838063, -1.53349927, ...,  0.17531013,\n",
       "        -0.01337359, -0.62363898],\n",
       "       [-0.65604672, -0.51838063, -1.53349927, ..., -0.02197492,\n",
       "        -0.21165453,  1.61488196],\n",
       "       ...,\n",
       "       [ 4.07982946,  3.38275786,  0.92914195, ...,  0.67226942,\n",
       "         0.55175057, -0.66359923],\n",
       "       [ 0.30872651, -0.03760535,  0.7052746 , ...,  0.37909655,\n",
       "         0.20699545, -0.71820108],\n",
       "       [-0.65604672, -0.51838063, -1.53349927, ...,  1.00470792,\n",
       "         0.98225836,  1.73802519]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, labels_train, labels_test = train_test_split(X_all, labels_all,\n",
    "                                                stratify = labels_all, random_state = 111, test_size = 0.2)\n",
    "\n",
    "X_train_feats, X_test_feats, _ , _ = train_test_split(X_feats, labels_all,\n",
    "                                                stratify = labels_all, random_state = 111, test_size = 0.2)\n",
    "\n",
    "X_train_p, X_test_p, _ , _ = train_test_split(X_all_p, labels_all,\n",
    "                                                stratify = labels_all, random_state = 111, test_size = 0.2)\n",
    "\n",
    "X_tr, X_vld, lab_tr, lab_vld = train_test_split(X_train, labels_train, \n",
    "                                                stratify = labels_train, random_state = 222, test_size = 0.2)\n",
    "\n",
    "X_tr_f, X_vld_f, lab_tr_f, lab_vld_f = train_test_split(X_train_feats, labels_train, \n",
    "                                                stratify = labels_train, random_state = 222, test_size = 0.2)\n",
    "\n",
    "X_tr_p, X_vld_p, lab_tr_p, lab_vld_p = train_test_split(X_train_p, labels_train, \n",
    "                                                stratify = labels_train, random_state = 222, test_size = 0.2)\n",
    "\n",
    "X_tr_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.65604672, -0.51838063, -1.53349927, ...,  1.43768042,\n",
       "         1.60602404,  1.3282128 ],\n",
       "       [-0.65604672, -0.51838063, -1.53349927, ...,  0.17531013,\n",
       "        -0.01337359, -0.62363898],\n",
       "       [-0.65604672, -0.51838063, -1.53349927, ..., -0.02197492,\n",
       "        -0.21165453,  1.61488196],\n",
       "       ...,\n",
       "       [ 4.07982946,  3.38275786,  0.92914195, ...,  0.67226942,\n",
       "         0.55175057, -0.66359923],\n",
       "       [ 0.30872651, -0.03760535,  0.7052746 , ...,  0.37909655,\n",
       "         0.20699545, -0.71820108],\n",
       "       [-0.65604672, -0.51838063, -1.53349927, ...,  1.00470792,\n",
       "         0.98225836,  1.73802519]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr = one_hot(lab_tr)\n",
    "y_vld = one_hot(lab_vld)\n",
    "y_test = one_hot(labels_test)\n",
    "\n",
    "X_tr_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ross\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100       # Batch size\n",
    "seq_len = 2000          # Number of steps\n",
    "learning_rate = 0.00002\n",
    "epochs = 600\n",
    "\n",
    "n_classes = 14\n",
    "n_channels = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "# Construct placeholders\n",
    "with graph.as_default():\n",
    "    inputs_ = tf.placeholder(tf.float32, [None, seq_len, n_channels], name = 'inputs')\n",
    "    inputs2_ = tf.placeholder(tf.float32, [None, 34], name = 'inputs2')\n",
    "    inputs3_ = tf.placeholder(tf.float32, [None, seq_len/2, n_channels], name = 'inputs')\n",
    "    labels_ = tf.placeholder(tf.float32, [None, n_classes], name = 'labels')\n",
    "    keep_prob_ = tf.placeholder(tf.float32, name = 'keep')\n",
    "    learning_rate_ = tf.placeholder(tf.float32, name = 'learning_rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, 8, 64]\n",
      "[None, 4, 64]\n"
     ]
    }
   ],
   "source": [
    "with graph.as_default():\n",
    "    # (batch, 128, 9) --> (batch, 64, 18)\n",
    "    conv1 = tf.layers.conv1d(inputs=inputs_, filters=32, kernel_size=10, strides=2, \n",
    "                             padding='same', activation = tf.nn.relu)\n",
    "    max_pool_1 = tf.layers.max_pooling1d(inputs=conv1, pool_size=20, strides=2, padding='same')\n",
    "    \n",
    "    # (batch, 64, 18) --> (batch, 32, 36)\n",
    "    conv2 = tf.layers.conv1d(inputs=max_pool_1, filters=32, kernel_size=10, strides=2, \n",
    "                             padding='same', activation = tf.nn.relu)\n",
    "    max_pool_2 = tf.layers.max_pooling1d(inputs=conv2, pool_size=16, strides=2, padding='same')\n",
    "    \n",
    "    # (batch, 32, 36) --> (batch, 16, 72)\n",
    "    conv3 = tf.layers.conv1d(inputs=max_pool_2, filters=64, kernel_size=10, strides=2, \n",
    "                             padding='same', activation = tf.nn.relu)\n",
    "    max_pool_3 = tf.layers.max_pooling1d(inputs=conv3, pool_size=12, strides=2, padding='same')\n",
    "    \n",
    "    # (batch, 16, 72) --> (batch, 8, 144)\n",
    "    conv4 = tf.layers.conv1d(inputs=max_pool_3, filters=64, kernel_size=10, strides=2, \n",
    "                             padding='same', activation = tf.nn.relu)\n",
    "    max_pool_4 = tf.layers.max_pooling1d(inputs=conv4, pool_size=8, strides=2, padding='same')\n",
    "    \n",
    "with graph.as_default():\n",
    "    # (batch, 128, 9) --> (batch, 64, 18)\n",
    "    conv1_p = tf.layers.conv1d(inputs=inputs3_, filters=32, kernel_size=10, strides=2, \n",
    "                             padding='same', activation = tf.nn.relu)\n",
    "    max_pool_1_p = tf.layers.max_pooling1d(inputs=conv1_p, pool_size=10, strides=2, padding='same')\n",
    "    \n",
    "    # (batch, 64, 18) --> (batch, 32, 36)\n",
    "    conv2_p = tf.layers.conv1d(inputs=max_pool_1_p, filters=32, kernel_size=10, strides=2, \n",
    "                             padding='same', activation = tf.nn.relu)\n",
    "    max_pool_2_p = tf.layers.max_pooling1d(inputs=conv2_p, pool_size=8, strides=2, padding='same')\n",
    "    \n",
    "    # (batch, 32, 36) --> (batch, 16, 72)\n",
    "    conv3_p = tf.layers.conv1d(inputs=max_pool_2_p, filters=64, kernel_size=10, strides=2, \n",
    "                             padding='same', activation = tf.nn.relu)\n",
    "    max_pool_3_p = tf.layers.max_pooling1d(inputs=conv3_p, pool_size=6, strides=2, padding='same')\n",
    "    \n",
    "    # (batch, 16, 72) --> (batch, 8, 144)\n",
    "    conv4_p = tf.layers.conv1d(inputs=max_pool_3_p, filters=64, kernel_size=10, strides=2, \n",
    "                             padding='same', activation = tf.nn.relu)\n",
    "    max_pool_4_p = tf.layers.max_pooling1d(inputs=conv4_p, pool_size=4, strides=2, padding='same')\n",
    "    \n",
    "print(max_pool_4.get_shape().as_list())\n",
    "print(max_pool_4_p.get_shape().as_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, 768]\n"
     ]
    }
   ],
   "source": [
    "with graph.as_default():\n",
    "    # Flatten and add dropout\n",
    "    nnfeats = tf.layers.dense(inputs=inputs2_, units=512, activation=tf.nn.tanh)\n",
    "    nnfeats2 = tf.nn.dropout(nnfeats, keep_prob=keep_prob_)\n",
    "    nnfeats3 = tf.layers.dense(inputs=nnfeats2, units=256, activation=tf.nn.tanh)\n",
    "    nnfeats4 = tf.nn.dropout(nnfeats3, keep_prob=keep_prob_)\n",
    "    nnfeats5 = tf.layers.dense(inputs=nnfeats4, units=128, activation=tf.nn.tanh)\n",
    "    nnfeats6 = tf.nn.dropout(nnfeats5, keep_prob=keep_prob_)\n",
    "    nnfeats7 = tf.layers.dense(inputs=nnfeats6, units=64, activation=tf.nn.tanh)\n",
    "    nnfeats8 = tf.nn.dropout(nnfeats7, keep_prob=keep_prob_)\n",
    "    \n",
    "    flat = tf.concat([tf.reshape(max_pool_4, (-1, 8*64)), nnfeats8, tf.reshape(max_pool_4_p, (-1, 4*64))], 1)\n",
    "    flat2 = tf.nn.dropout(flat, keep_prob=keep_prob_)\n",
    "    flat3 = tf.layers.dense(inputs=flat2, units=512, activation=tf.nn.tanh)\n",
    "    flat4 = tf.nn.dropout(flat3, keep_prob=keep_prob_)\n",
    "    \n",
    "    # Predictions\n",
    "    logits = tf.layers.dense(flat4, n_classes)\n",
    "    \n",
    "    # Cost function and optimizer\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels_))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate_).minimize(cost)\n",
    "    \n",
    "    # Accuracy\n",
    "    correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(labels_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "    \n",
    "print(flat.get_shape().as_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (os.path.exists('checkpoints-cnn') == False):\n",
    "    !mkdir checkpoints-cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/152 Iteration: 5 Train loss: 2.646871 Train acc: 0.170000\n",
      "Epoch: 0/152 Iteration: 10 Train loss: 2.653467 Train acc: 0.230000\n",
      "Epoch: 0/152 Iteration: 10 Validation loss: 2.565601 Validation acc: 0.315833\n",
      "Epoch: 0/152 Iteration: 15 Train loss: 2.588856 Train acc: 0.210000\n",
      "Epoch: 0/152 Iteration: 20 Train loss: 2.559656 Train acc: 0.280000\n",
      "Epoch: 0/152 Iteration: 20 Validation loss: 2.521897 Validation acc: 0.345000\n",
      "Epoch: 0/152 Iteration: 25 Train loss: 2.601722 Train acc: 0.290000\n",
      "Epoch: 0/152 Iteration: 30 Train loss: 2.533322 Train acc: 0.280000\n",
      "Epoch: 0/152 Iteration: 30 Validation loss: 2.490645 Validation acc: 0.350000\n",
      "Epoch: 0/152 Iteration: 35 Train loss: 2.486918 Train acc: 0.290000\n",
      "Epoch: 0/152 Iteration: 40 Train loss: 2.601532 Train acc: 0.280000\n",
      "Epoch: 0/152 Iteration: 40 Validation loss: 2.458695 Validation acc: 0.373333\n",
      "Epoch: 0/152 Iteration: 45 Train loss: 2.560991 Train acc: 0.340000\n",
      "Epoch: 0/152 Iteration: 50 Train loss: 2.403465 Train acc: 0.370000\n",
      "Epoch: 0/152 Iteration: 50 Validation loss: 2.423618 Validation acc: 0.370833\n",
      "Epoch: 1/152 Iteration: 55 Train loss: 2.378300 Train acc: 0.340000\n",
      "Epoch: 1/152 Iteration: 60 Train loss: 2.607546 Train acc: 0.310000\n",
      "Epoch: 1/152 Iteration: 60 Validation loss: 2.379053 Validation acc: 0.370833\n",
      "Epoch: 1/152 Iteration: 65 Train loss: 2.446085 Train acc: 0.280000\n",
      "Epoch: 1/152 Iteration: 70 Train loss: 2.343923 Train acc: 0.310000\n",
      "Epoch: 1/152 Iteration: 70 Validation loss: 2.323730 Validation acc: 0.365833\n",
      "Epoch: 1/152 Iteration: 75 Train loss: 2.410892 Train acc: 0.300000\n",
      "Epoch: 1/152 Iteration: 80 Train loss: 2.348123 Train acc: 0.260000\n",
      "Epoch: 1/152 Iteration: 80 Validation loss: 2.259924 Validation acc: 0.358333\n",
      "Epoch: 1/152 Iteration: 85 Train loss: 2.294981 Train acc: 0.330000\n",
      "Epoch: 1/152 Iteration: 90 Train loss: 2.282598 Train acc: 0.290000\n",
      "Epoch: 1/152 Iteration: 90 Validation loss: 2.190639 Validation acc: 0.360833\n",
      "Epoch: 1/152 Iteration: 95 Train loss: 2.263690 Train acc: 0.370000\n",
      "Epoch: 1/152 Iteration: 100 Train loss: 2.011079 Train acc: 0.400000\n",
      "Epoch: 1/152 Iteration: 100 Validation loss: 2.122840 Validation acc: 0.359167\n",
      "Epoch: 2/152 Iteration: 105 Train loss: 2.118780 Train acc: 0.330000\n",
      "Epoch: 2/152 Iteration: 110 Train loss: 2.236461 Train acc: 0.370000\n",
      "Epoch: 2/152 Iteration: 110 Validation loss: 2.048611 Validation acc: 0.368333\n",
      "Epoch: 2/152 Iteration: 115 Train loss: 2.248703 Train acc: 0.310000\n",
      "Epoch: 2/152 Iteration: 120 Train loss: 2.112266 Train acc: 0.320000\n",
      "Epoch: 2/152 Iteration: 120 Validation loss: 1.996195 Validation acc: 0.367500\n",
      "Epoch: 2/152 Iteration: 125 Train loss: 2.105477 Train acc: 0.330000\n",
      "Epoch: 2/152 Iteration: 130 Train loss: 2.173378 Train acc: 0.280000\n",
      "Epoch: 2/152 Iteration: 130 Validation loss: 1.964300 Validation acc: 0.377500\n",
      "Epoch: 2/152 Iteration: 135 Train loss: 1.976150 Train acc: 0.360000\n",
      "Epoch: 2/152 Iteration: 140 Train loss: 2.026472 Train acc: 0.300000\n",
      "Epoch: 2/152 Iteration: 140 Validation loss: 1.941869 Validation acc: 0.381667\n",
      "Epoch: 2/152 Iteration: 145 Train loss: 2.038655 Train acc: 0.360000\n",
      "Epoch: 2/152 Iteration: 150 Train loss: 1.866537 Train acc: 0.380000\n",
      "Epoch: 2/152 Iteration: 150 Validation loss: 1.920611 Validation acc: 0.385000\n",
      "Epoch: 3/152 Iteration: 155 Train loss: 1.903575 Train acc: 0.340000\n",
      "Epoch: 3/152 Iteration: 160 Train loss: 2.018815 Train acc: 0.360000\n",
      "Epoch: 3/152 Iteration: 160 Validation loss: 1.879436 Validation acc: 0.393333\n",
      "Epoch: 3/152 Iteration: 165 Train loss: 2.056278 Train acc: 0.330000\n",
      "Epoch: 3/152 Iteration: 170 Train loss: 1.995235 Train acc: 0.320000\n",
      "Epoch: 3/152 Iteration: 170 Validation loss: 1.860262 Validation acc: 0.395000\n",
      "Epoch: 3/152 Iteration: 175 Train loss: 2.059273 Train acc: 0.350000\n",
      "Epoch: 3/152 Iteration: 180 Train loss: 2.031982 Train acc: 0.320000\n",
      "Epoch: 3/152 Iteration: 180 Validation loss: 1.848782 Validation acc: 0.400000\n",
      "Epoch: 3/152 Iteration: 185 Train loss: 1.917521 Train acc: 0.380000\n",
      "Epoch: 3/152 Iteration: 190 Train loss: 1.897542 Train acc: 0.350000\n",
      "Epoch: 3/152 Iteration: 190 Validation loss: 1.834365 Validation acc: 0.398333\n",
      "Epoch: 3/152 Iteration: 195 Train loss: 1.917676 Train acc: 0.410000\n",
      "Epoch: 3/152 Iteration: 200 Train loss: 1.833795 Train acc: 0.380000\n",
      "Epoch: 3/152 Iteration: 200 Validation loss: 1.828480 Validation acc: 0.400000\n",
      "Epoch: 4/152 Iteration: 205 Train loss: 1.793880 Train acc: 0.440000\n",
      "Epoch: 4/152 Iteration: 210 Train loss: 1.874753 Train acc: 0.370000\n",
      "Epoch: 4/152 Iteration: 210 Validation loss: 1.809264 Validation acc: 0.408333\n",
      "Epoch: 4/152 Iteration: 215 Train loss: 1.998480 Train acc: 0.320000\n",
      "Epoch: 4/152 Iteration: 220 Train loss: 1.922959 Train acc: 0.380000\n",
      "Epoch: 4/152 Iteration: 220 Validation loss: 1.795020 Validation acc: 0.410833\n",
      "Epoch: 4/152 Iteration: 225 Train loss: 1.941384 Train acc: 0.380000\n",
      "Epoch: 4/152 Iteration: 230 Train loss: 2.030009 Train acc: 0.320000\n",
      "Epoch: 4/152 Iteration: 230 Validation loss: 1.796216 Validation acc: 0.413333\n",
      "Epoch: 4/152 Iteration: 235 Train loss: 1.747280 Train acc: 0.420000\n",
      "Epoch: 4/152 Iteration: 240 Train loss: 1.887691 Train acc: 0.380000\n",
      "Epoch: 4/152 Iteration: 240 Validation loss: 1.787668 Validation acc: 0.418333\n",
      "Epoch: 4/152 Iteration: 245 Train loss: 1.839689 Train acc: 0.410000\n",
      "Epoch: 4/152 Iteration: 250 Train loss: 1.830401 Train acc: 0.390000\n",
      "Epoch: 4/152 Iteration: 250 Validation loss: 1.776238 Validation acc: 0.419167\n",
      "Epoch: 5/152 Iteration: 255 Train loss: 1.708365 Train acc: 0.420000\n",
      "Epoch: 5/152 Iteration: 260 Train loss: 1.792047 Train acc: 0.430000\n",
      "Epoch: 5/152 Iteration: 260 Validation loss: 1.761109 Validation acc: 0.420833\n",
      "Epoch: 5/152 Iteration: 265 Train loss: 2.006407 Train acc: 0.330000\n",
      "Epoch: 5/152 Iteration: 270 Train loss: 1.899473 Train acc: 0.350000\n",
      "Epoch: 5/152 Iteration: 270 Validation loss: 1.747493 Validation acc: 0.425000\n",
      "Epoch: 5/152 Iteration: 275 Train loss: 1.910150 Train acc: 0.380000\n",
      "Epoch: 5/152 Iteration: 280 Train loss: 2.003560 Train acc: 0.320000\n",
      "Epoch: 5/152 Iteration: 280 Validation loss: 1.737466 Validation acc: 0.426667\n",
      "Epoch: 5/152 Iteration: 285 Train loss: 1.729029 Train acc: 0.440000\n",
      "Epoch: 5/152 Iteration: 290 Train loss: 1.824646 Train acc: 0.360000\n",
      "Epoch: 5/152 Iteration: 290 Validation loss: 1.729432 Validation acc: 0.430833\n",
      "Epoch: 5/152 Iteration: 295 Train loss: 1.861378 Train acc: 0.390000\n",
      "Epoch: 5/152 Iteration: 300 Train loss: 1.745464 Train acc: 0.430000\n",
      "Epoch: 5/152 Iteration: 300 Validation loss: 1.724334 Validation acc: 0.439167\n",
      "Epoch: 6/152 Iteration: 305 Train loss: 1.702553 Train acc: 0.430000\n",
      "Epoch: 6/152 Iteration: 310 Train loss: 1.742139 Train acc: 0.440000\n",
      "Epoch: 6/152 Iteration: 310 Validation loss: 1.716664 Validation acc: 0.434167\n",
      "Epoch: 6/152 Iteration: 315 Train loss: 1.810998 Train acc: 0.390000\n",
      "Epoch: 6/152 Iteration: 320 Train loss: 1.843297 Train acc: 0.450000\n",
      "Epoch: 6/152 Iteration: 320 Validation loss: 1.702268 Validation acc: 0.444167\n",
      "Epoch: 6/152 Iteration: 325 Train loss: 1.954001 Train acc: 0.380000\n",
      "Epoch: 6/152 Iteration: 330 Train loss: 1.844403 Train acc: 0.400000\n",
      "Epoch: 6/152 Iteration: 330 Validation loss: 1.693179 Validation acc: 0.445000\n",
      "Epoch: 6/152 Iteration: 335 Train loss: 1.680964 Train acc: 0.450000\n",
      "Epoch: 6/152 Iteration: 340 Train loss: 1.715777 Train acc: 0.420000\n",
      "Epoch: 6/152 Iteration: 340 Validation loss: 1.687091 Validation acc: 0.445833\n",
      "Epoch: 6/152 Iteration: 345 Train loss: 1.804040 Train acc: 0.450000\n",
      "Epoch: 6/152 Iteration: 350 Train loss: 1.690458 Train acc: 0.420000\n",
      "Epoch: 6/152 Iteration: 350 Validation loss: 1.681185 Validation acc: 0.446667\n",
      "Epoch: 7/152 Iteration: 355 Train loss: 1.636627 Train acc: 0.450000\n",
      "Epoch: 7/152 Iteration: 360 Train loss: 1.763875 Train acc: 0.480000\n",
      "Epoch: 7/152 Iteration: 360 Validation loss: 1.670592 Validation acc: 0.450000\n",
      "Epoch: 7/152 Iteration: 365 Train loss: 1.794860 Train acc: 0.390000\n",
      "Epoch: 7/152 Iteration: 370 Train loss: 1.845105 Train acc: 0.400000\n",
      "Epoch: 7/152 Iteration: 370 Validation loss: 1.662260 Validation acc: 0.453333\n",
      "Epoch: 7/152 Iteration: 375 Train loss: 1.768297 Train acc: 0.420000\n",
      "Epoch: 7/152 Iteration: 380 Train loss: 1.880728 Train acc: 0.390000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/152 Iteration: 380 Validation loss: 1.653559 Validation acc: 0.452500\n",
      "Epoch: 7/152 Iteration: 385 Train loss: 1.719721 Train acc: 0.450000\n",
      "Epoch: 7/152 Iteration: 390 Train loss: 1.673046 Train acc: 0.420000\n",
      "Epoch: 7/152 Iteration: 390 Validation loss: 1.650471 Validation acc: 0.452500\n",
      "Epoch: 7/152 Iteration: 395 Train loss: 1.629957 Train acc: 0.420000\n",
      "Epoch: 7/152 Iteration: 400 Train loss: 1.792924 Train acc: 0.410000\n",
      "Epoch: 7/152 Iteration: 400 Validation loss: 1.637054 Validation acc: 0.463333\n",
      "Epoch: 8/152 Iteration: 405 Train loss: 1.648302 Train acc: 0.410000\n",
      "Epoch: 8/152 Iteration: 410 Train loss: 1.694417 Train acc: 0.480000\n",
      "Epoch: 8/152 Iteration: 410 Validation loss: 1.632807 Validation acc: 0.455833\n",
      "Epoch: 8/152 Iteration: 415 Train loss: 1.735870 Train acc: 0.420000\n",
      "Epoch: 8/152 Iteration: 420 Train loss: 1.744581 Train acc: 0.440000\n",
      "Epoch: 8/152 Iteration: 420 Validation loss: 1.624888 Validation acc: 0.465000\n",
      "Epoch: 8/152 Iteration: 425 Train loss: 1.843948 Train acc: 0.450000\n",
      "Epoch: 8/152 Iteration: 430 Train loss: 1.830153 Train acc: 0.430000\n",
      "Epoch: 8/152 Iteration: 430 Validation loss: 1.616076 Validation acc: 0.466667\n",
      "Epoch: 8/152 Iteration: 435 Train loss: 1.644047 Train acc: 0.500000\n",
      "Epoch: 8/152 Iteration: 440 Train loss: 1.661916 Train acc: 0.450000\n",
      "Epoch: 8/152 Iteration: 440 Validation loss: 1.609047 Validation acc: 0.466667\n",
      "Epoch: 8/152 Iteration: 445 Train loss: 1.595109 Train acc: 0.460000\n",
      "Epoch: 8/152 Iteration: 450 Train loss: 1.701720 Train acc: 0.430000\n",
      "Epoch: 8/152 Iteration: 450 Validation loss: 1.598812 Validation acc: 0.468333\n",
      "Epoch: 9/152 Iteration: 455 Train loss: 1.500469 Train acc: 0.510000\n",
      "Epoch: 9/152 Iteration: 460 Train loss: 1.605649 Train acc: 0.490000\n",
      "Epoch: 9/152 Iteration: 460 Validation loss: 1.599725 Validation acc: 0.469167\n",
      "Epoch: 9/152 Iteration: 465 Train loss: 1.738087 Train acc: 0.450000\n",
      "Epoch: 9/152 Iteration: 470 Train loss: 1.639867 Train acc: 0.450000\n",
      "Epoch: 9/152 Iteration: 470 Validation loss: 1.589380 Validation acc: 0.471667\n",
      "Epoch: 9/152 Iteration: 475 Train loss: 1.791052 Train acc: 0.420000\n",
      "Epoch: 9/152 Iteration: 480 Train loss: 1.843715 Train acc: 0.420000\n",
      "Epoch: 9/152 Iteration: 480 Validation loss: 1.583548 Validation acc: 0.475833\n",
      "Epoch: 9/152 Iteration: 485 Train loss: 1.479822 Train acc: 0.540000\n",
      "Epoch: 9/152 Iteration: 490 Train loss: 1.550729 Train acc: 0.510000\n",
      "Epoch: 9/152 Iteration: 490 Validation loss: 1.571180 Validation acc: 0.475000\n",
      "Epoch: 9/152 Iteration: 495 Train loss: 1.609611 Train acc: 0.460000\n",
      "Epoch: 9/152 Iteration: 500 Train loss: 1.637493 Train acc: 0.440000\n",
      "Epoch: 9/152 Iteration: 500 Validation loss: 1.564384 Validation acc: 0.475000\n",
      "Epoch: 10/152 Iteration: 505 Train loss: 1.469587 Train acc: 0.470000\n",
      "Epoch: 10/152 Iteration: 510 Train loss: 1.649365 Train acc: 0.480000\n",
      "Epoch: 10/152 Iteration: 510 Validation loss: 1.570418 Validation acc: 0.482500\n",
      "Epoch: 10/152 Iteration: 515 Train loss: 1.673123 Train acc: 0.490000\n",
      "Epoch: 10/152 Iteration: 520 Train loss: 1.724011 Train acc: 0.470000\n",
      "Epoch: 10/152 Iteration: 520 Validation loss: 1.555311 Validation acc: 0.476667\n",
      "Epoch: 10/152 Iteration: 525 Train loss: 1.769913 Train acc: 0.440000\n",
      "Epoch: 10/152 Iteration: 530 Train loss: 1.726971 Train acc: 0.440000\n",
      "Epoch: 10/152 Iteration: 530 Validation loss: 1.547543 Validation acc: 0.485000\n",
      "Epoch: 10/152 Iteration: 535 Train loss: 1.476806 Train acc: 0.560000\n",
      "Epoch: 10/152 Iteration: 540 Train loss: 1.599628 Train acc: 0.460000\n",
      "Epoch: 10/152 Iteration: 540 Validation loss: 1.542834 Validation acc: 0.480000\n",
      "Epoch: 10/152 Iteration: 545 Train loss: 1.613754 Train acc: 0.430000\n",
      "Epoch: 10/152 Iteration: 550 Train loss: 1.754610 Train acc: 0.440000\n",
      "Epoch: 10/152 Iteration: 550 Validation loss: 1.530133 Validation acc: 0.482500\n",
      "Epoch: 11/152 Iteration: 555 Train loss: 1.463156 Train acc: 0.500000\n",
      "Epoch: 11/152 Iteration: 560 Train loss: 1.634526 Train acc: 0.470000\n",
      "Epoch: 11/152 Iteration: 560 Validation loss: 1.533111 Validation acc: 0.495000\n",
      "Epoch: 11/152 Iteration: 565 Train loss: 1.594378 Train acc: 0.450000\n",
      "Epoch: 11/152 Iteration: 570 Train loss: 1.711693 Train acc: 0.440000\n",
      "Epoch: 11/152 Iteration: 570 Validation loss: 1.525288 Validation acc: 0.479167\n",
      "Epoch: 11/152 Iteration: 575 Train loss: 1.671741 Train acc: 0.480000\n",
      "Epoch: 11/152 Iteration: 580 Train loss: 1.606776 Train acc: 0.430000\n",
      "Epoch: 11/152 Iteration: 580 Validation loss: 1.520172 Validation acc: 0.493333\n",
      "Epoch: 11/152 Iteration: 585 Train loss: 1.525244 Train acc: 0.510000\n",
      "Epoch: 11/152 Iteration: 590 Train loss: 1.515046 Train acc: 0.510000\n",
      "Epoch: 11/152 Iteration: 590 Validation loss: 1.514161 Validation acc: 0.490000\n",
      "Epoch: 11/152 Iteration: 595 Train loss: 1.472284 Train acc: 0.460000\n",
      "Epoch: 11/152 Iteration: 600 Train loss: 1.632380 Train acc: 0.410000\n",
      "Epoch: 11/152 Iteration: 600 Validation loss: 1.505622 Validation acc: 0.492500\n",
      "Epoch: 12/152 Iteration: 605 Train loss: 1.427013 Train acc: 0.510000\n",
      "Epoch: 12/152 Iteration: 610 Train loss: 1.577623 Train acc: 0.490000\n",
      "Epoch: 12/152 Iteration: 610 Validation loss: 1.503748 Validation acc: 0.507500\n",
      "Epoch: 12/152 Iteration: 615 Train loss: 1.605315 Train acc: 0.470000\n",
      "Epoch: 12/152 Iteration: 620 Train loss: 1.525413 Train acc: 0.480000\n",
      "Epoch: 12/152 Iteration: 620 Validation loss: 1.493721 Validation acc: 0.490000\n",
      "Epoch: 12/152 Iteration: 625 Train loss: 1.650238 Train acc: 0.500000\n",
      "Epoch: 12/152 Iteration: 630 Train loss: 1.581198 Train acc: 0.470000\n",
      "Epoch: 12/152 Iteration: 630 Validation loss: 1.494876 Validation acc: 0.510833\n",
      "Epoch: 12/152 Iteration: 635 Train loss: 1.461466 Train acc: 0.570000\n",
      "Epoch: 12/152 Iteration: 640 Train loss: 1.523041 Train acc: 0.500000\n",
      "Epoch: 12/152 Iteration: 640 Validation loss: 1.477771 Validation acc: 0.502500\n",
      "Epoch: 12/152 Iteration: 645 Train loss: 1.414831 Train acc: 0.530000\n",
      "Epoch: 12/152 Iteration: 650 Train loss: 1.603207 Train acc: 0.450000\n",
      "Epoch: 12/152 Iteration: 650 Validation loss: 1.481873 Validation acc: 0.505833\n",
      "Epoch: 13/152 Iteration: 655 Train loss: 1.413002 Train acc: 0.500000\n",
      "Epoch: 13/152 Iteration: 660 Train loss: 1.547648 Train acc: 0.470000\n",
      "Epoch: 13/152 Iteration: 660 Validation loss: 1.472712 Validation acc: 0.507500\n",
      "Epoch: 13/152 Iteration: 665 Train loss: 1.562958 Train acc: 0.470000\n",
      "Epoch: 13/152 Iteration: 670 Train loss: 1.606365 Train acc: 0.470000\n",
      "Epoch: 13/152 Iteration: 670 Validation loss: 1.460598 Validation acc: 0.505000\n",
      "Epoch: 13/152 Iteration: 675 Train loss: 1.565724 Train acc: 0.500000\n",
      "Epoch: 13/152 Iteration: 680 Train loss: 1.554561 Train acc: 0.480000\n",
      "Epoch: 13/152 Iteration: 680 Validation loss: 1.453687 Validation acc: 0.517500\n",
      "Epoch: 13/152 Iteration: 685 Train loss: 1.467199 Train acc: 0.540000\n",
      "Epoch: 13/152 Iteration: 690 Train loss: 1.424989 Train acc: 0.540000\n",
      "Epoch: 13/152 Iteration: 690 Validation loss: 1.447078 Validation acc: 0.510000\n",
      "Epoch: 13/152 Iteration: 695 Train loss: 1.409906 Train acc: 0.530000\n",
      "Epoch: 13/152 Iteration: 700 Train loss: 1.568892 Train acc: 0.460000\n",
      "Epoch: 13/152 Iteration: 700 Validation loss: 1.448380 Validation acc: 0.509167\n",
      "Epoch: 14/152 Iteration: 705 Train loss: 1.398139 Train acc: 0.530000\n",
      "Epoch: 14/152 Iteration: 710 Train loss: 1.524208 Train acc: 0.510000\n",
      "Epoch: 14/152 Iteration: 710 Validation loss: 1.439309 Validation acc: 0.527500\n",
      "Epoch: 14/152 Iteration: 715 Train loss: 1.493971 Train acc: 0.510000\n",
      "Epoch: 14/152 Iteration: 720 Train loss: 1.474745 Train acc: 0.480000\n",
      "Epoch: 14/152 Iteration: 720 Validation loss: 1.434992 Validation acc: 0.514167\n",
      "Epoch: 14/152 Iteration: 725 Train loss: 1.576229 Train acc: 0.470000\n",
      "Epoch: 14/152 Iteration: 730 Train loss: 1.549371 Train acc: 0.450000\n",
      "Epoch: 14/152 Iteration: 730 Validation loss: 1.426908 Validation acc: 0.531667\n",
      "Epoch: 14/152 Iteration: 735 Train loss: 1.433233 Train acc: 0.490000\n",
      "Epoch: 14/152 Iteration: 740 Train loss: 1.391093 Train acc: 0.520000\n",
      "Epoch: 14/152 Iteration: 740 Validation loss: 1.416350 Validation acc: 0.525000\n",
      "Epoch: 14/152 Iteration: 745 Train loss: 1.391298 Train acc: 0.550000\n",
      "Epoch: 14/152 Iteration: 750 Train loss: 1.513719 Train acc: 0.420000\n",
      "Epoch: 14/152 Iteration: 750 Validation loss: 1.424376 Validation acc: 0.514167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15/152 Iteration: 755 Train loss: 1.353023 Train acc: 0.510000\n",
      "Epoch: 15/152 Iteration: 760 Train loss: 1.449497 Train acc: 0.540000\n",
      "Epoch: 15/152 Iteration: 760 Validation loss: 1.424211 Validation acc: 0.534167\n",
      "Epoch: 15/152 Iteration: 765 Train loss: 1.610063 Train acc: 0.500000\n",
      "Epoch: 15/152 Iteration: 770 Train loss: 1.539069 Train acc: 0.480000\n",
      "Epoch: 15/152 Iteration: 770 Validation loss: 1.412173 Validation acc: 0.524167\n",
      "Epoch: 15/152 Iteration: 775 Train loss: 1.541016 Train acc: 0.470000\n",
      "Epoch: 15/152 Iteration: 780 Train loss: 1.581472 Train acc: 0.450000\n",
      "Epoch: 15/152 Iteration: 780 Validation loss: 1.397594 Validation acc: 0.536667\n",
      "Epoch: 15/152 Iteration: 785 Train loss: 1.448111 Train acc: 0.560000\n",
      "Epoch: 15/152 Iteration: 790 Train loss: 1.535914 Train acc: 0.540000\n",
      "Epoch: 15/152 Iteration: 790 Validation loss: 1.391610 Validation acc: 0.530833\n",
      "Epoch: 15/152 Iteration: 795 Train loss: 1.395375 Train acc: 0.540000\n",
      "Epoch: 15/152 Iteration: 800 Train loss: 1.517718 Train acc: 0.500000\n",
      "Epoch: 15/152 Iteration: 800 Validation loss: 1.387785 Validation acc: 0.529167\n",
      "Epoch: 16/152 Iteration: 805 Train loss: 1.339814 Train acc: 0.550000\n",
      "Epoch: 16/152 Iteration: 810 Train loss: 1.457672 Train acc: 0.530000\n",
      "Epoch: 16/152 Iteration: 810 Validation loss: 1.392859 Validation acc: 0.546667\n",
      "Epoch: 16/152 Iteration: 815 Train loss: 1.480610 Train acc: 0.500000\n",
      "Epoch: 16/152 Iteration: 820 Train loss: 1.540047 Train acc: 0.480000\n",
      "Epoch: 16/152 Iteration: 820 Validation loss: 1.381769 Validation acc: 0.533333\n",
      "Epoch: 16/152 Iteration: 825 Train loss: 1.511306 Train acc: 0.510000\n",
      "Epoch: 16/152 Iteration: 830 Train loss: 1.514701 Train acc: 0.490000\n",
      "Epoch: 16/152 Iteration: 830 Validation loss: 1.373103 Validation acc: 0.541667\n",
      "Epoch: 16/152 Iteration: 835 Train loss: 1.348532 Train acc: 0.570000\n",
      "Epoch: 16/152 Iteration: 840 Train loss: 1.363835 Train acc: 0.550000\n",
      "Epoch: 16/152 Iteration: 840 Validation loss: 1.362639 Validation acc: 0.537500\n",
      "Epoch: 16/152 Iteration: 845 Train loss: 1.320678 Train acc: 0.550000\n",
      "Epoch: 16/152 Iteration: 850 Train loss: 1.499789 Train acc: 0.430000\n",
      "Epoch: 16/152 Iteration: 850 Validation loss: 1.364555 Validation acc: 0.541667\n",
      "Epoch: 17/152 Iteration: 855 Train loss: 1.315906 Train acc: 0.550000\n",
      "Epoch: 17/152 Iteration: 860 Train loss: 1.424122 Train acc: 0.570000\n",
      "Epoch: 17/152 Iteration: 860 Validation loss: 1.371006 Validation acc: 0.555000\n",
      "Epoch: 17/152 Iteration: 865 Train loss: 1.495317 Train acc: 0.480000\n",
      "Epoch: 17/152 Iteration: 870 Train loss: 1.436572 Train acc: 0.490000\n",
      "Epoch: 17/152 Iteration: 870 Validation loss: 1.358606 Validation acc: 0.555000\n",
      "Epoch: 17/152 Iteration: 875 Train loss: 1.432939 Train acc: 0.530000\n",
      "Epoch: 17/152 Iteration: 880 Train loss: 1.418968 Train acc: 0.500000\n",
      "Epoch: 17/152 Iteration: 880 Validation loss: 1.348302 Validation acc: 0.549167\n",
      "Epoch: 17/152 Iteration: 885 Train loss: 1.311475 Train acc: 0.560000\n",
      "Epoch: 17/152 Iteration: 890 Train loss: 1.380871 Train acc: 0.570000\n",
      "Epoch: 17/152 Iteration: 890 Validation loss: 1.341849 Validation acc: 0.546667\n",
      "Epoch: 17/152 Iteration: 895 Train loss: 1.258289 Train acc: 0.600000\n",
      "Epoch: 17/152 Iteration: 900 Train loss: 1.528245 Train acc: 0.480000\n",
      "Epoch: 17/152 Iteration: 900 Validation loss: 1.344973 Validation acc: 0.546667\n",
      "Epoch: 18/152 Iteration: 905 Train loss: 1.304156 Train acc: 0.590000\n",
      "Epoch: 18/152 Iteration: 910 Train loss: 1.400176 Train acc: 0.540000\n",
      "Epoch: 18/152 Iteration: 910 Validation loss: 1.347005 Validation acc: 0.561667\n",
      "Epoch: 18/152 Iteration: 915 Train loss: 1.461669 Train acc: 0.480000\n",
      "Epoch: 18/152 Iteration: 920 Train loss: 1.472544 Train acc: 0.520000\n",
      "Epoch: 18/152 Iteration: 920 Validation loss: 1.343300 Validation acc: 0.558333\n",
      "Epoch: 18/152 Iteration: 925 Train loss: 1.485243 Train acc: 0.530000\n",
      "Epoch: 18/152 Iteration: 930 Train loss: 1.441989 Train acc: 0.490000\n",
      "Epoch: 18/152 Iteration: 930 Validation loss: 1.333867 Validation acc: 0.551667\n",
      "Epoch: 18/152 Iteration: 935 Train loss: 1.301526 Train acc: 0.570000\n",
      "Epoch: 18/152 Iteration: 940 Train loss: 1.372980 Train acc: 0.580000\n",
      "Epoch: 18/152 Iteration: 940 Validation loss: 1.330359 Validation acc: 0.539167\n",
      "Epoch: 18/152 Iteration: 945 Train loss: 1.256403 Train acc: 0.580000\n",
      "Epoch: 18/152 Iteration: 950 Train loss: 1.432465 Train acc: 0.490000\n",
      "Epoch: 18/152 Iteration: 950 Validation loss: 1.322857 Validation acc: 0.555833\n",
      "Epoch: 19/152 Iteration: 955 Train loss: 1.317336 Train acc: 0.560000\n",
      "Epoch: 19/152 Iteration: 960 Train loss: 1.386161 Train acc: 0.550000\n",
      "Epoch: 19/152 Iteration: 960 Validation loss: 1.320225 Validation acc: 0.563333\n",
      "Epoch: 19/152 Iteration: 965 Train loss: 1.321521 Train acc: 0.560000\n",
      "Epoch: 19/152 Iteration: 970 Train loss: 1.409310 Train acc: 0.540000\n",
      "Epoch: 19/152 Iteration: 970 Validation loss: 1.310199 Validation acc: 0.556667\n",
      "Epoch: 19/152 Iteration: 975 Train loss: 1.459113 Train acc: 0.500000\n",
      "Epoch: 19/152 Iteration: 980 Train loss: 1.377300 Train acc: 0.520000\n",
      "Epoch: 19/152 Iteration: 980 Validation loss: 1.305107 Validation acc: 0.568333\n",
      "Epoch: 19/152 Iteration: 985 Train loss: 1.252499 Train acc: 0.560000\n",
      "Epoch: 19/152 Iteration: 990 Train loss: 1.302591 Train acc: 0.570000\n",
      "Epoch: 19/152 Iteration: 990 Validation loss: 1.307559 Validation acc: 0.546667\n",
      "Epoch: 19/152 Iteration: 995 Train loss: 1.211688 Train acc: 0.590000\n",
      "Epoch: 19/152 Iteration: 1000 Train loss: 1.451387 Train acc: 0.520000\n",
      "Epoch: 19/152 Iteration: 1000 Validation loss: 1.304253 Validation acc: 0.560833\n",
      "Epoch: 20/152 Iteration: 1005 Train loss: 1.271714 Train acc: 0.570000\n",
      "Epoch: 20/152 Iteration: 1010 Train loss: 1.361149 Train acc: 0.540000\n",
      "Epoch: 20/152 Iteration: 1010 Validation loss: 1.301800 Validation acc: 0.569167\n",
      "Epoch: 20/152 Iteration: 1015 Train loss: 1.277933 Train acc: 0.580000\n",
      "Epoch: 20/152 Iteration: 1020 Train loss: 1.401334 Train acc: 0.520000\n",
      "Epoch: 20/152 Iteration: 1020 Validation loss: 1.288287 Validation acc: 0.563333\n",
      "Epoch: 20/152 Iteration: 1025 Train loss: 1.332872 Train acc: 0.580000\n",
      "Epoch: 20/152 Iteration: 1030 Train loss: 1.337649 Train acc: 0.540000\n",
      "Epoch: 20/152 Iteration: 1030 Validation loss: 1.283857 Validation acc: 0.575000\n",
      "Epoch: 20/152 Iteration: 1035 Train loss: 1.320064 Train acc: 0.560000\n",
      "Epoch: 20/152 Iteration: 1040 Train loss: 1.310933 Train acc: 0.560000\n",
      "Epoch: 20/152 Iteration: 1040 Validation loss: 1.286587 Validation acc: 0.561667\n",
      "Epoch: 20/152 Iteration: 1045 Train loss: 1.256882 Train acc: 0.560000\n",
      "Epoch: 20/152 Iteration: 1050 Train loss: 1.343853 Train acc: 0.520000\n",
      "Epoch: 20/152 Iteration: 1050 Validation loss: 1.284853 Validation acc: 0.569167\n",
      "Epoch: 21/152 Iteration: 1055 Train loss: 1.196948 Train acc: 0.580000\n",
      "Epoch: 21/152 Iteration: 1060 Train loss: 1.382651 Train acc: 0.590000\n",
      "Epoch: 21/152 Iteration: 1060 Validation loss: 1.292698 Validation acc: 0.583333\n",
      "Epoch: 21/152 Iteration: 1065 Train loss: 1.273665 Train acc: 0.570000\n",
      "Epoch: 21/152 Iteration: 1070 Train loss: 1.333896 Train acc: 0.500000\n",
      "Epoch: 21/152 Iteration: 1070 Validation loss: 1.279963 Validation acc: 0.573333\n",
      "Epoch: 21/152 Iteration: 1075 Train loss: 1.352955 Train acc: 0.570000\n",
      "Epoch: 21/152 Iteration: 1080 Train loss: 1.331870 Train acc: 0.510000\n",
      "Epoch: 21/152 Iteration: 1080 Validation loss: 1.269203 Validation acc: 0.579167\n",
      "Epoch: 21/152 Iteration: 1085 Train loss: 1.248243 Train acc: 0.580000\n",
      "Epoch: 21/152 Iteration: 1090 Train loss: 1.333819 Train acc: 0.570000\n",
      "Epoch: 21/152 Iteration: 1090 Validation loss: 1.263755 Validation acc: 0.569167\n",
      "Epoch: 21/152 Iteration: 1095 Train loss: 1.171758 Train acc: 0.550000\n",
      "Epoch: 21/152 Iteration: 1100 Train loss: 1.347949 Train acc: 0.540000\n",
      "Epoch: 21/152 Iteration: 1100 Validation loss: 1.263648 Validation acc: 0.580833\n",
      "Epoch: 22/152 Iteration: 1105 Train loss: 1.225222 Train acc: 0.590000\n",
      "Epoch: 22/152 Iteration: 1110 Train loss: 1.252180 Train acc: 0.580000\n",
      "Epoch: 22/152 Iteration: 1110 Validation loss: 1.259353 Validation acc: 0.578333\n",
      "Epoch: 22/152 Iteration: 1115 Train loss: 1.375147 Train acc: 0.510000\n",
      "Epoch: 22/152 Iteration: 1120 Train loss: 1.418878 Train acc: 0.490000\n",
      "Epoch: 22/152 Iteration: 1120 Validation loss: 1.265042 Validation acc: 0.579167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22/152 Iteration: 1125 Train loss: 1.390948 Train acc: 0.550000\n",
      "Epoch: 22/152 Iteration: 1130 Train loss: 1.361149 Train acc: 0.520000\n",
      "Epoch: 22/152 Iteration: 1130 Validation loss: 1.250450 Validation acc: 0.581667\n",
      "Epoch: 22/152 Iteration: 1135 Train loss: 1.257837 Train acc: 0.580000\n",
      "Epoch: 22/152 Iteration: 1140 Train loss: 1.216552 Train acc: 0.630000\n",
      "Epoch: 22/152 Iteration: 1140 Validation loss: 1.249125 Validation acc: 0.570833\n",
      "Epoch: 22/152 Iteration: 1145 Train loss: 1.131699 Train acc: 0.610000\n",
      "Epoch: 22/152 Iteration: 1150 Train loss: 1.289482 Train acc: 0.550000\n",
      "Epoch: 22/152 Iteration: 1150 Validation loss: 1.246874 Validation acc: 0.588333\n",
      "Epoch: 23/152 Iteration: 1155 Train loss: 1.243299 Train acc: 0.550000\n",
      "Epoch: 23/152 Iteration: 1160 Train loss: 1.234609 Train acc: 0.590000\n",
      "Epoch: 23/152 Iteration: 1160 Validation loss: 1.243663 Validation acc: 0.587500\n",
      "Epoch: 23/152 Iteration: 1165 Train loss: 1.273033 Train acc: 0.600000\n",
      "Epoch: 23/152 Iteration: 1170 Train loss: 1.360377 Train acc: 0.560000\n",
      "Epoch: 23/152 Iteration: 1170 Validation loss: 1.233788 Validation acc: 0.580833\n",
      "Epoch: 23/152 Iteration: 1175 Train loss: 1.293900 Train acc: 0.630000\n",
      "Epoch: 23/152 Iteration: 1180 Train loss: 1.322340 Train acc: 0.530000\n",
      "Epoch: 23/152 Iteration: 1180 Validation loss: 1.230742 Validation acc: 0.585000\n",
      "Epoch: 23/152 Iteration: 1185 Train loss: 1.220998 Train acc: 0.570000\n",
      "Epoch: 23/152 Iteration: 1190 Train loss: 1.238012 Train acc: 0.620000\n",
      "Epoch: 23/152 Iteration: 1190 Validation loss: 1.224199 Validation acc: 0.588333\n",
      "Epoch: 23/152 Iteration: 1195 Train loss: 1.206532 Train acc: 0.620000\n",
      "Epoch: 23/152 Iteration: 1200 Train loss: 1.273844 Train acc: 0.540000\n",
      "Epoch: 23/152 Iteration: 1200 Validation loss: 1.229140 Validation acc: 0.587500\n",
      "Epoch: 24/152 Iteration: 1205 Train loss: 1.242953 Train acc: 0.560000\n",
      "Epoch: 24/152 Iteration: 1210 Train loss: 1.157734 Train acc: 0.630000\n",
      "Epoch: 24/152 Iteration: 1210 Validation loss: 1.231307 Validation acc: 0.598333\n",
      "Epoch: 24/152 Iteration: 1215 Train loss: 1.243317 Train acc: 0.550000\n",
      "Epoch: 24/152 Iteration: 1220 Train loss: 1.274829 Train acc: 0.520000\n",
      "Epoch: 24/152 Iteration: 1220 Validation loss: 1.225177 Validation acc: 0.593333\n",
      "Epoch: 24/152 Iteration: 1225 Train loss: 1.272633 Train acc: 0.580000\n",
      "Epoch: 24/152 Iteration: 1230 Train loss: 1.275388 Train acc: 0.580000\n",
      "Epoch: 24/152 Iteration: 1230 Validation loss: 1.215266 Validation acc: 0.592500\n",
      "Epoch: 24/152 Iteration: 1235 Train loss: 1.169197 Train acc: 0.620000\n",
      "Epoch: 24/152 Iteration: 1240 Train loss: 1.217592 Train acc: 0.650000\n",
      "Epoch: 24/152 Iteration: 1240 Validation loss: 1.222571 Validation acc: 0.577500\n",
      "Epoch: 24/152 Iteration: 1245 Train loss: 1.107452 Train acc: 0.610000\n",
      "Epoch: 24/152 Iteration: 1250 Train loss: 1.298523 Train acc: 0.560000\n",
      "Epoch: 24/152 Iteration: 1250 Validation loss: 1.218691 Validation acc: 0.584167\n",
      "Epoch: 25/152 Iteration: 1255 Train loss: 1.242821 Train acc: 0.540000\n",
      "Epoch: 25/152 Iteration: 1260 Train loss: 1.182458 Train acc: 0.560000\n",
      "Epoch: 25/152 Iteration: 1260 Validation loss: 1.225385 Validation acc: 0.600833\n",
      "Epoch: 25/152 Iteration: 1265 Train loss: 1.297643 Train acc: 0.550000\n",
      "Epoch: 25/152 Iteration: 1270 Train loss: 1.250046 Train acc: 0.540000\n",
      "Epoch: 25/152 Iteration: 1270 Validation loss: 1.217719 Validation acc: 0.589167\n",
      "Epoch: 25/152 Iteration: 1275 Train loss: 1.343278 Train acc: 0.580000\n",
      "Epoch: 25/152 Iteration: 1280 Train loss: 1.254479 Train acc: 0.590000\n",
      "Epoch: 25/152 Iteration: 1280 Validation loss: 1.211805 Validation acc: 0.590000\n",
      "Epoch: 25/152 Iteration: 1285 Train loss: 1.161192 Train acc: 0.580000\n",
      "Epoch: 25/152 Iteration: 1290 Train loss: 1.308085 Train acc: 0.630000\n",
      "Epoch: 25/152 Iteration: 1290 Validation loss: 1.204497 Validation acc: 0.590833\n",
      "Epoch: 25/152 Iteration: 1295 Train loss: 1.128424 Train acc: 0.620000\n",
      "Epoch: 25/152 Iteration: 1300 Train loss: 1.365287 Train acc: 0.560000\n",
      "Epoch: 25/152 Iteration: 1300 Validation loss: 1.211142 Validation acc: 0.596667\n",
      "Epoch: 26/152 Iteration: 1305 Train loss: 1.205693 Train acc: 0.590000\n",
      "Epoch: 26/152 Iteration: 1310 Train loss: 1.157960 Train acc: 0.630000\n",
      "Epoch: 26/152 Iteration: 1310 Validation loss: 1.214931 Validation acc: 0.601667\n",
      "Epoch: 26/152 Iteration: 1315 Train loss: 1.234371 Train acc: 0.600000\n",
      "Epoch: 26/152 Iteration: 1320 Train loss: 1.211326 Train acc: 0.580000\n",
      "Epoch: 26/152 Iteration: 1320 Validation loss: 1.203115 Validation acc: 0.600000\n",
      "Epoch: 26/152 Iteration: 1325 Train loss: 1.274773 Train acc: 0.600000\n",
      "Epoch: 26/152 Iteration: 1330 Train loss: 1.210284 Train acc: 0.610000\n",
      "Epoch: 26/152 Iteration: 1330 Validation loss: 1.201174 Validation acc: 0.595000\n",
      "Epoch: 26/152 Iteration: 1335 Train loss: 1.160740 Train acc: 0.590000\n",
      "Epoch: 26/152 Iteration: 1340 Train loss: 1.303223 Train acc: 0.620000\n",
      "Epoch: 26/152 Iteration: 1340 Validation loss: 1.201362 Validation acc: 0.584167\n",
      "Epoch: 26/152 Iteration: 1345 Train loss: 1.121072 Train acc: 0.640000\n",
      "Epoch: 26/152 Iteration: 1350 Train loss: 1.347329 Train acc: 0.540000\n",
      "Epoch: 26/152 Iteration: 1350 Validation loss: 1.193905 Validation acc: 0.596667\n",
      "Epoch: 27/152 Iteration: 1355 Train loss: 1.248000 Train acc: 0.600000\n",
      "Epoch: 27/152 Iteration: 1360 Train loss: 1.245997 Train acc: 0.570000\n",
      "Epoch: 27/152 Iteration: 1360 Validation loss: 1.193450 Validation acc: 0.603333\n",
      "Epoch: 27/152 Iteration: 1365 Train loss: 1.255653 Train acc: 0.580000\n",
      "Epoch: 27/152 Iteration: 1370 Train loss: 1.197484 Train acc: 0.560000\n",
      "Epoch: 27/152 Iteration: 1370 Validation loss: 1.194868 Validation acc: 0.603333\n",
      "Epoch: 27/152 Iteration: 1375 Train loss: 1.293992 Train acc: 0.590000\n",
      "Epoch: 27/152 Iteration: 1380 Train loss: 1.316572 Train acc: 0.510000\n",
      "Epoch: 27/152 Iteration: 1380 Validation loss: 1.182998 Validation acc: 0.596667\n",
      "Epoch: 27/152 Iteration: 1385 Train loss: 1.132707 Train acc: 0.620000\n",
      "Epoch: 27/152 Iteration: 1390 Train loss: 1.214314 Train acc: 0.670000\n",
      "Epoch: 27/152 Iteration: 1390 Validation loss: 1.180030 Validation acc: 0.591667\n",
      "Epoch: 27/152 Iteration: 1395 Train loss: 1.132365 Train acc: 0.610000\n",
      "Epoch: 27/152 Iteration: 1400 Train loss: 1.276917 Train acc: 0.540000\n",
      "Epoch: 27/152 Iteration: 1400 Validation loss: 1.184666 Validation acc: 0.607500\n",
      "Epoch: 28/152 Iteration: 1405 Train loss: 1.189213 Train acc: 0.600000\n",
      "Epoch: 28/152 Iteration: 1410 Train loss: 1.146932 Train acc: 0.610000\n",
      "Epoch: 28/152 Iteration: 1410 Validation loss: 1.182126 Validation acc: 0.620000\n",
      "Epoch: 28/152 Iteration: 1415 Train loss: 1.143343 Train acc: 0.600000\n",
      "Epoch: 28/152 Iteration: 1420 Train loss: 1.260483 Train acc: 0.580000\n",
      "Epoch: 28/152 Iteration: 1420 Validation loss: 1.189418 Validation acc: 0.611667\n",
      "Epoch: 28/152 Iteration: 1425 Train loss: 1.282841 Train acc: 0.560000\n",
      "Epoch: 28/152 Iteration: 1430 Train loss: 1.227551 Train acc: 0.540000\n",
      "Epoch: 28/152 Iteration: 1430 Validation loss: 1.169998 Validation acc: 0.609167\n",
      "Epoch: 28/152 Iteration: 1435 Train loss: 1.068099 Train acc: 0.580000\n",
      "Epoch: 28/152 Iteration: 1440 Train loss: 1.154118 Train acc: 0.650000\n",
      "Epoch: 28/152 Iteration: 1440 Validation loss: 1.166368 Validation acc: 0.600833\n",
      "Epoch: 28/152 Iteration: 1445 Train loss: 1.062953 Train acc: 0.650000\n",
      "Epoch: 28/152 Iteration: 1450 Train loss: 1.205970 Train acc: 0.560000\n",
      "Epoch: 28/152 Iteration: 1450 Validation loss: 1.167830 Validation acc: 0.611667\n",
      "Epoch: 29/152 Iteration: 1455 Train loss: 1.163548 Train acc: 0.590000\n",
      "Epoch: 29/152 Iteration: 1460 Train loss: 1.135260 Train acc: 0.640000\n",
      "Epoch: 29/152 Iteration: 1460 Validation loss: 1.171899 Validation acc: 0.621667\n",
      "Epoch: 29/152 Iteration: 1465 Train loss: 1.131115 Train acc: 0.590000\n",
      "Epoch: 29/152 Iteration: 1470 Train loss: 1.254584 Train acc: 0.580000\n",
      "Epoch: 29/152 Iteration: 1470 Validation loss: 1.166696 Validation acc: 0.604167\n",
      "Epoch: 29/152 Iteration: 1475 Train loss: 1.279163 Train acc: 0.590000\n",
      "Epoch: 29/152 Iteration: 1480 Train loss: 1.178073 Train acc: 0.590000\n",
      "Epoch: 29/152 Iteration: 1480 Validation loss: 1.163669 Validation acc: 0.599167\n",
      "Epoch: 29/152 Iteration: 1485 Train loss: 1.107260 Train acc: 0.610000\n",
      "Epoch: 29/152 Iteration: 1490 Train loss: 1.215803 Train acc: 0.610000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29/152 Iteration: 1490 Validation loss: 1.159062 Validation acc: 0.608333\n",
      "Epoch: 29/152 Iteration: 1495 Train loss: 1.131486 Train acc: 0.610000\n",
      "Epoch: 29/152 Iteration: 1500 Train loss: 1.260255 Train acc: 0.570000\n",
      "Epoch: 29/152 Iteration: 1500 Validation loss: 1.157830 Validation acc: 0.605833\n",
      "Epoch: 30/152 Iteration: 1505 Train loss: 1.219576 Train acc: 0.570000\n",
      "Epoch: 30/152 Iteration: 1510 Train loss: 1.196010 Train acc: 0.590000\n",
      "Epoch: 30/152 Iteration: 1510 Validation loss: 1.161590 Validation acc: 0.610833\n",
      "Epoch: 30/152 Iteration: 1515 Train loss: 1.068187 Train acc: 0.670000\n",
      "Epoch: 30/152 Iteration: 1520 Train loss: 1.230283 Train acc: 0.550000\n",
      "Epoch: 30/152 Iteration: 1520 Validation loss: 1.159413 Validation acc: 0.610000\n",
      "Epoch: 30/152 Iteration: 1525 Train loss: 1.205862 Train acc: 0.620000\n",
      "Epoch: 30/152 Iteration: 1530 Train loss: 1.242278 Train acc: 0.560000\n",
      "Epoch: 30/152 Iteration: 1530 Validation loss: 1.154019 Validation acc: 0.610833\n",
      "Epoch: 30/152 Iteration: 1535 Train loss: 1.035957 Train acc: 0.580000\n",
      "Epoch: 30/152 Iteration: 1540 Train loss: 1.226566 Train acc: 0.630000\n",
      "Epoch: 30/152 Iteration: 1540 Validation loss: 1.149112 Validation acc: 0.605000\n",
      "Epoch: 30/152 Iteration: 1545 Train loss: 1.084976 Train acc: 0.600000\n",
      "Epoch: 30/152 Iteration: 1550 Train loss: 1.250329 Train acc: 0.590000\n",
      "Epoch: 30/152 Iteration: 1550 Validation loss: 1.150277 Validation acc: 0.610833\n",
      "Epoch: 31/152 Iteration: 1555 Train loss: 1.178433 Train acc: 0.560000\n",
      "Epoch: 31/152 Iteration: 1560 Train loss: 1.188884 Train acc: 0.650000\n",
      "Epoch: 31/152 Iteration: 1560 Validation loss: 1.156740 Validation acc: 0.619167\n",
      "Epoch: 31/152 Iteration: 1565 Train loss: 1.104525 Train acc: 0.600000\n",
      "Epoch: 31/152 Iteration: 1570 Train loss: 1.155537 Train acc: 0.580000\n",
      "Epoch: 31/152 Iteration: 1570 Validation loss: 1.150226 Validation acc: 0.618333\n",
      "Epoch: 31/152 Iteration: 1575 Train loss: 1.228230 Train acc: 0.590000\n",
      "Epoch: 31/152 Iteration: 1580 Train loss: 1.151615 Train acc: 0.610000\n",
      "Epoch: 31/152 Iteration: 1580 Validation loss: 1.141690 Validation acc: 0.605833\n",
      "Epoch: 31/152 Iteration: 1585 Train loss: 1.087665 Train acc: 0.630000\n",
      "Epoch: 31/152 Iteration: 1590 Train loss: 1.197267 Train acc: 0.620000\n",
      "Epoch: 31/152 Iteration: 1590 Validation loss: 1.138672 Validation acc: 0.610000\n",
      "Epoch: 31/152 Iteration: 1595 Train loss: 1.033251 Train acc: 0.640000\n",
      "Epoch: 31/152 Iteration: 1600 Train loss: 1.184349 Train acc: 0.610000\n",
      "Epoch: 31/152 Iteration: 1600 Validation loss: 1.142704 Validation acc: 0.615833\n",
      "Epoch: 32/152 Iteration: 1605 Train loss: 1.125612 Train acc: 0.570000\n",
      "Epoch: 32/152 Iteration: 1610 Train loss: 1.105797 Train acc: 0.680000\n",
      "Epoch: 32/152 Iteration: 1610 Validation loss: 1.150095 Validation acc: 0.625000\n",
      "Epoch: 32/152 Iteration: 1615 Train loss: 1.061730 Train acc: 0.600000\n",
      "Epoch: 32/152 Iteration: 1620 Train loss: 1.180485 Train acc: 0.630000\n",
      "Epoch: 32/152 Iteration: 1620 Validation loss: 1.144329 Validation acc: 0.616667\n",
      "Epoch: 32/152 Iteration: 1625 Train loss: 1.232887 Train acc: 0.590000\n",
      "Epoch: 32/152 Iteration: 1630 Train loss: 1.137603 Train acc: 0.600000\n",
      "Epoch: 32/152 Iteration: 1630 Validation loss: 1.135961 Validation acc: 0.619167\n",
      "Epoch: 32/152 Iteration: 1635 Train loss: 1.058835 Train acc: 0.630000\n",
      "Epoch: 32/152 Iteration: 1640 Train loss: 1.131774 Train acc: 0.650000\n",
      "Epoch: 32/152 Iteration: 1640 Validation loss: 1.134451 Validation acc: 0.609167\n",
      "Epoch: 32/152 Iteration: 1645 Train loss: 1.009403 Train acc: 0.670000\n",
      "Epoch: 32/152 Iteration: 1650 Train loss: 1.181908 Train acc: 0.610000\n",
      "Epoch: 32/152 Iteration: 1650 Validation loss: 1.134940 Validation acc: 0.618333\n",
      "Epoch: 33/152 Iteration: 1655 Train loss: 1.133641 Train acc: 0.560000\n",
      "Epoch: 33/152 Iteration: 1660 Train loss: 1.169503 Train acc: 0.640000\n",
      "Epoch: 33/152 Iteration: 1660 Validation loss: 1.147666 Validation acc: 0.629167\n",
      "Epoch: 33/152 Iteration: 1665 Train loss: 1.077438 Train acc: 0.600000\n",
      "Epoch: 33/152 Iteration: 1670 Train loss: 1.114652 Train acc: 0.600000\n",
      "Epoch: 33/152 Iteration: 1670 Validation loss: 1.139699 Validation acc: 0.622500\n",
      "Epoch: 33/152 Iteration: 1675 Train loss: 1.240962 Train acc: 0.580000\n",
      "Epoch: 33/152 Iteration: 1680 Train loss: 1.154186 Train acc: 0.580000\n",
      "Epoch: 33/152 Iteration: 1680 Validation loss: 1.135523 Validation acc: 0.616667\n",
      "Epoch: 33/152 Iteration: 1685 Train loss: 1.106169 Train acc: 0.610000\n",
      "Epoch: 33/152 Iteration: 1690 Train loss: 1.199128 Train acc: 0.660000\n",
      "Epoch: 33/152 Iteration: 1690 Validation loss: 1.132052 Validation acc: 0.610000\n",
      "Epoch: 33/152 Iteration: 1695 Train loss: 1.102628 Train acc: 0.660000\n",
      "Epoch: 33/152 Iteration: 1700 Train loss: 1.172809 Train acc: 0.600000\n",
      "Epoch: 33/152 Iteration: 1700 Validation loss: 1.129077 Validation acc: 0.631667\n",
      "Epoch: 34/152 Iteration: 1705 Train loss: 1.221335 Train acc: 0.580000\n",
      "Epoch: 34/152 Iteration: 1710 Train loss: 1.109169 Train acc: 0.640000\n",
      "Epoch: 34/152 Iteration: 1710 Validation loss: 1.130607 Validation acc: 0.627500\n",
      "Epoch: 34/152 Iteration: 1715 Train loss: 1.102820 Train acc: 0.640000\n",
      "Epoch: 34/152 Iteration: 1720 Train loss: 1.165939 Train acc: 0.590000\n",
      "Epoch: 34/152 Iteration: 1720 Validation loss: 1.127532 Validation acc: 0.623333\n",
      "Epoch: 34/152 Iteration: 1725 Train loss: 1.154693 Train acc: 0.630000\n",
      "Epoch: 34/152 Iteration: 1730 Train loss: 1.176881 Train acc: 0.590000\n",
      "Epoch: 34/152 Iteration: 1730 Validation loss: 1.124969 Validation acc: 0.624167\n",
      "Epoch: 34/152 Iteration: 1735 Train loss: 1.043711 Train acc: 0.610000\n",
      "Epoch: 34/152 Iteration: 1740 Train loss: 1.131274 Train acc: 0.690000\n",
      "Epoch: 34/152 Iteration: 1740 Validation loss: 1.127241 Validation acc: 0.614167\n",
      "Epoch: 34/152 Iteration: 1745 Train loss: 1.081650 Train acc: 0.590000\n",
      "Epoch: 34/152 Iteration: 1750 Train loss: 1.185391 Train acc: 0.610000\n",
      "Epoch: 34/152 Iteration: 1750 Validation loss: 1.122121 Validation acc: 0.627500\n",
      "Epoch: 35/152 Iteration: 1755 Train loss: 1.123084 Train acc: 0.630000\n",
      "Epoch: 35/152 Iteration: 1760 Train loss: 1.126606 Train acc: 0.650000\n",
      "Epoch: 35/152 Iteration: 1760 Validation loss: 1.123871 Validation acc: 0.636667\n",
      "Epoch: 35/152 Iteration: 1765 Train loss: 1.077097 Train acc: 0.640000\n",
      "Epoch: 35/152 Iteration: 1770 Train loss: 1.085290 Train acc: 0.650000\n",
      "Epoch: 35/152 Iteration: 1770 Validation loss: 1.126146 Validation acc: 0.628333\n",
      "Epoch: 35/152 Iteration: 1775 Train loss: 1.252904 Train acc: 0.580000\n",
      "Epoch: 35/152 Iteration: 1780 Train loss: 1.217570 Train acc: 0.580000\n",
      "Epoch: 35/152 Iteration: 1780 Validation loss: 1.122679 Validation acc: 0.622500\n",
      "Epoch: 35/152 Iteration: 1785 Train loss: 0.985728 Train acc: 0.650000\n",
      "Epoch: 35/152 Iteration: 1790 Train loss: 1.181500 Train acc: 0.630000\n",
      "Epoch: 35/152 Iteration: 1790 Validation loss: 1.110574 Validation acc: 0.625000\n",
      "Epoch: 35/152 Iteration: 1795 Train loss: 1.119483 Train acc: 0.620000\n",
      "Epoch: 35/152 Iteration: 1800 Train loss: 1.124202 Train acc: 0.590000\n",
      "Epoch: 35/152 Iteration: 1800 Validation loss: 1.111433 Validation acc: 0.625000\n",
      "Epoch: 36/152 Iteration: 1805 Train loss: 1.103272 Train acc: 0.600000\n",
      "Epoch: 36/152 Iteration: 1810 Train loss: 1.051165 Train acc: 0.650000\n",
      "Epoch: 36/152 Iteration: 1810 Validation loss: 1.113830 Validation acc: 0.635833\n",
      "Epoch: 36/152 Iteration: 1815 Train loss: 1.086662 Train acc: 0.630000\n",
      "Epoch: 36/152 Iteration: 1820 Train loss: 1.242947 Train acc: 0.590000\n",
      "Epoch: 36/152 Iteration: 1820 Validation loss: 1.115288 Validation acc: 0.630000\n",
      "Epoch: 36/152 Iteration: 1825 Train loss: 1.215225 Train acc: 0.630000\n",
      "Epoch: 36/152 Iteration: 1830 Train loss: 1.131872 Train acc: 0.590000\n",
      "Epoch: 36/152 Iteration: 1830 Validation loss: 1.111568 Validation acc: 0.629167\n",
      "Epoch: 36/152 Iteration: 1835 Train loss: 1.022332 Train acc: 0.680000\n",
      "Epoch: 36/152 Iteration: 1840 Train loss: 1.134576 Train acc: 0.650000\n",
      "Epoch: 36/152 Iteration: 1840 Validation loss: 1.110431 Validation acc: 0.615833\n",
      "Epoch: 36/152 Iteration: 1845 Train loss: 1.056348 Train acc: 0.650000\n",
      "Epoch: 36/152 Iteration: 1850 Train loss: 1.140150 Train acc: 0.600000\n",
      "Epoch: 36/152 Iteration: 1850 Validation loss: 1.115313 Validation acc: 0.628333\n",
      "Epoch: 37/152 Iteration: 1855 Train loss: 1.138082 Train acc: 0.590000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37/152 Iteration: 1860 Train loss: 0.992705 Train acc: 0.640000\n",
      "Epoch: 37/152 Iteration: 1860 Validation loss: 1.114795 Validation acc: 0.644167\n",
      "Epoch: 37/152 Iteration: 1865 Train loss: 1.002233 Train acc: 0.660000\n",
      "Epoch: 37/152 Iteration: 1870 Train loss: 1.167841 Train acc: 0.600000\n",
      "Epoch: 37/152 Iteration: 1870 Validation loss: 1.108837 Validation acc: 0.632500\n",
      "Epoch: 37/152 Iteration: 1875 Train loss: 1.269806 Train acc: 0.560000\n",
      "Epoch: 37/152 Iteration: 1880 Train loss: 1.183206 Train acc: 0.600000\n",
      "Epoch: 37/152 Iteration: 1880 Validation loss: 1.115307 Validation acc: 0.627500\n",
      "Epoch: 37/152 Iteration: 1885 Train loss: 1.094749 Train acc: 0.640000\n",
      "Epoch: 37/152 Iteration: 1890 Train loss: 1.174722 Train acc: 0.660000\n",
      "Epoch: 37/152 Iteration: 1890 Validation loss: 1.110662 Validation acc: 0.628333\n",
      "Epoch: 37/152 Iteration: 1895 Train loss: 1.051229 Train acc: 0.630000\n",
      "Epoch: 37/152 Iteration: 1900 Train loss: 1.167509 Train acc: 0.580000\n",
      "Epoch: 37/152 Iteration: 1900 Validation loss: 1.105624 Validation acc: 0.635000\n",
      "Epoch: 38/152 Iteration: 1905 Train loss: 1.103886 Train acc: 0.610000\n",
      "Epoch: 38/152 Iteration: 1910 Train loss: 1.060500 Train acc: 0.620000\n",
      "Epoch: 38/152 Iteration: 1910 Validation loss: 1.115339 Validation acc: 0.652500\n",
      "Epoch: 38/152 Iteration: 1915 Train loss: 1.083999 Train acc: 0.640000\n",
      "Epoch: 38/152 Iteration: 1920 Train loss: 1.073920 Train acc: 0.670000\n",
      "Epoch: 38/152 Iteration: 1920 Validation loss: 1.107506 Validation acc: 0.626667\n",
      "Epoch: 38/152 Iteration: 1925 Train loss: 1.144529 Train acc: 0.650000\n",
      "Epoch: 38/152 Iteration: 1930 Train loss: 1.071569 Train acc: 0.620000\n",
      "Epoch: 38/152 Iteration: 1930 Validation loss: 1.104004 Validation acc: 0.632500\n",
      "Epoch: 38/152 Iteration: 1935 Train loss: 1.072223 Train acc: 0.600000\n",
      "Epoch: 38/152 Iteration: 1940 Train loss: 1.128892 Train acc: 0.690000\n",
      "Epoch: 38/152 Iteration: 1940 Validation loss: 1.102271 Validation acc: 0.631667\n",
      "Epoch: 38/152 Iteration: 1945 Train loss: 1.022317 Train acc: 0.660000\n",
      "Epoch: 38/152 Iteration: 1950 Train loss: 1.054106 Train acc: 0.660000\n",
      "Epoch: 38/152 Iteration: 1950 Validation loss: 1.105183 Validation acc: 0.635833\n",
      "Epoch: 39/152 Iteration: 1955 Train loss: 1.078526 Train acc: 0.620000\n",
      "Epoch: 39/152 Iteration: 1960 Train loss: 1.052701 Train acc: 0.660000\n",
      "Epoch: 39/152 Iteration: 1960 Validation loss: 1.112616 Validation acc: 0.642500\n",
      "Epoch: 39/152 Iteration: 1965 Train loss: 1.045666 Train acc: 0.660000\n",
      "Epoch: 39/152 Iteration: 1970 Train loss: 1.118546 Train acc: 0.630000\n",
      "Epoch: 39/152 Iteration: 1970 Validation loss: 1.105573 Validation acc: 0.645833\n",
      "Epoch: 39/152 Iteration: 1975 Train loss: 1.196908 Train acc: 0.600000\n",
      "Epoch: 39/152 Iteration: 1980 Train loss: 1.070429 Train acc: 0.630000\n",
      "Epoch: 39/152 Iteration: 1980 Validation loss: 1.103554 Validation acc: 0.630000\n",
      "Epoch: 39/152 Iteration: 1985 Train loss: 0.960567 Train acc: 0.650000\n",
      "Epoch: 39/152 Iteration: 1990 Train loss: 1.159440 Train acc: 0.640000\n",
      "Epoch: 39/152 Iteration: 1990 Validation loss: 1.095219 Validation acc: 0.635833\n",
      "Epoch: 39/152 Iteration: 1995 Train loss: 0.978243 Train acc: 0.680000\n",
      "Epoch: 39/152 Iteration: 2000 Train loss: 1.122685 Train acc: 0.580000\n",
      "Epoch: 39/152 Iteration: 2000 Validation loss: 1.095110 Validation acc: 0.640000\n",
      "Epoch: 40/152 Iteration: 2005 Train loss: 1.064617 Train acc: 0.560000\n",
      "Epoch: 40/152 Iteration: 2010 Train loss: 1.064691 Train acc: 0.640000\n",
      "Epoch: 40/152 Iteration: 2010 Validation loss: 1.099452 Validation acc: 0.643333\n",
      "Epoch: 40/152 Iteration: 2015 Train loss: 0.965852 Train acc: 0.700000\n",
      "Epoch: 40/152 Iteration: 2020 Train loss: 1.073807 Train acc: 0.600000\n",
      "Epoch: 40/152 Iteration: 2020 Validation loss: 1.098663 Validation acc: 0.632500\n",
      "Epoch: 40/152 Iteration: 2025 Train loss: 1.186412 Train acc: 0.600000\n",
      "Epoch: 40/152 Iteration: 2030 Train loss: 1.108447 Train acc: 0.610000\n",
      "Epoch: 40/152 Iteration: 2030 Validation loss: 1.104271 Validation acc: 0.624167\n",
      "Epoch: 40/152 Iteration: 2035 Train loss: 0.928158 Train acc: 0.680000\n",
      "Epoch: 40/152 Iteration: 2040 Train loss: 1.076387 Train acc: 0.680000\n",
      "Epoch: 40/152 Iteration: 2040 Validation loss: 1.093507 Validation acc: 0.639167\n",
      "Epoch: 40/152 Iteration: 2045 Train loss: 0.977862 Train acc: 0.670000\n",
      "Epoch: 40/152 Iteration: 2050 Train loss: 1.154464 Train acc: 0.640000\n",
      "Epoch: 40/152 Iteration: 2050 Validation loss: 1.093843 Validation acc: 0.639167\n",
      "Epoch: 41/152 Iteration: 2055 Train loss: 1.059811 Train acc: 0.610000\n",
      "Epoch: 41/152 Iteration: 2060 Train loss: 1.009444 Train acc: 0.690000\n",
      "Epoch: 41/152 Iteration: 2060 Validation loss: 1.102971 Validation acc: 0.651667\n",
      "Epoch: 41/152 Iteration: 2065 Train loss: 1.067058 Train acc: 0.630000\n",
      "Epoch: 41/152 Iteration: 2070 Train loss: 1.069813 Train acc: 0.660000\n",
      "Epoch: 41/152 Iteration: 2070 Validation loss: 1.098901 Validation acc: 0.638333\n",
      "Epoch: 41/152 Iteration: 2075 Train loss: 1.133115 Train acc: 0.640000\n",
      "Epoch: 41/152 Iteration: 2080 Train loss: 1.038148 Train acc: 0.630000\n",
      "Epoch: 41/152 Iteration: 2080 Validation loss: 1.095104 Validation acc: 0.631667\n",
      "Epoch: 41/152 Iteration: 2085 Train loss: 1.037930 Train acc: 0.580000\n",
      "Epoch: 41/152 Iteration: 2090 Train loss: 1.080292 Train acc: 0.680000\n",
      "Epoch: 41/152 Iteration: 2090 Validation loss: 1.091530 Validation acc: 0.638333\n",
      "Epoch: 41/152 Iteration: 2095 Train loss: 0.981321 Train acc: 0.650000\n",
      "Epoch: 41/152 Iteration: 2100 Train loss: 1.196179 Train acc: 0.620000\n",
      "Epoch: 41/152 Iteration: 2100 Validation loss: 1.091259 Validation acc: 0.640833\n",
      "Epoch: 42/152 Iteration: 2105 Train loss: 1.134982 Train acc: 0.580000\n",
      "Epoch: 42/152 Iteration: 2110 Train loss: 0.986780 Train acc: 0.650000\n",
      "Epoch: 42/152 Iteration: 2110 Validation loss: 1.089730 Validation acc: 0.650833\n",
      "Epoch: 42/152 Iteration: 2115 Train loss: 0.971188 Train acc: 0.670000\n",
      "Epoch: 42/152 Iteration: 2120 Train loss: 1.048180 Train acc: 0.650000\n",
      "Epoch: 42/152 Iteration: 2120 Validation loss: 1.078588 Validation acc: 0.645833\n",
      "Epoch: 42/152 Iteration: 2125 Train loss: 1.079592 Train acc: 0.630000\n",
      "Epoch: 42/152 Iteration: 2130 Train loss: 1.095951 Train acc: 0.640000\n",
      "Epoch: 42/152 Iteration: 2130 Validation loss: 1.078542 Validation acc: 0.642500\n",
      "Epoch: 42/152 Iteration: 2135 Train loss: 0.980020 Train acc: 0.640000\n",
      "Epoch: 42/152 Iteration: 2140 Train loss: 1.111417 Train acc: 0.650000\n",
      "Epoch: 42/152 Iteration: 2140 Validation loss: 1.082884 Validation acc: 0.640833\n",
      "Epoch: 42/152 Iteration: 2145 Train loss: 1.012520 Train acc: 0.640000\n",
      "Epoch: 42/152 Iteration: 2150 Train loss: 1.155975 Train acc: 0.600000\n",
      "Epoch: 42/152 Iteration: 2150 Validation loss: 1.083099 Validation acc: 0.640833\n",
      "Epoch: 43/152 Iteration: 2155 Train loss: 1.070572 Train acc: 0.610000\n",
      "Epoch: 43/152 Iteration: 2160 Train loss: 1.004037 Train acc: 0.670000\n",
      "Epoch: 43/152 Iteration: 2160 Validation loss: 1.077131 Validation acc: 0.649167\n",
      "Epoch: 43/152 Iteration: 2165 Train loss: 1.057856 Train acc: 0.630000\n",
      "Epoch: 43/152 Iteration: 2170 Train loss: 1.059410 Train acc: 0.660000\n",
      "Epoch: 43/152 Iteration: 2170 Validation loss: 1.077669 Validation acc: 0.650833\n",
      "Epoch: 43/152 Iteration: 2175 Train loss: 1.039945 Train acc: 0.650000\n",
      "Epoch: 43/152 Iteration: 2180 Train loss: 1.146346 Train acc: 0.580000\n",
      "Epoch: 43/152 Iteration: 2180 Validation loss: 1.081858 Validation acc: 0.636667\n",
      "Epoch: 43/152 Iteration: 2185 Train loss: 1.028014 Train acc: 0.630000\n",
      "Epoch: 43/152 Iteration: 2190 Train loss: 1.070180 Train acc: 0.700000\n",
      "Epoch: 43/152 Iteration: 2190 Validation loss: 1.079061 Validation acc: 0.643333\n",
      "Epoch: 43/152 Iteration: 2195 Train loss: 1.009388 Train acc: 0.660000\n",
      "Epoch: 43/152 Iteration: 2200 Train loss: 1.145623 Train acc: 0.590000\n",
      "Epoch: 43/152 Iteration: 2200 Validation loss: 1.077776 Validation acc: 0.643333\n",
      "Epoch: 44/152 Iteration: 2205 Train loss: 1.082643 Train acc: 0.610000\n",
      "Epoch: 44/152 Iteration: 2210 Train loss: 1.039705 Train acc: 0.630000\n",
      "Epoch: 44/152 Iteration: 2210 Validation loss: 1.084220 Validation acc: 0.650833\n",
      "Epoch: 44/152 Iteration: 2215 Train loss: 1.004861 Train acc: 0.650000\n",
      "Epoch: 44/152 Iteration: 2220 Train loss: 1.091844 Train acc: 0.630000\n",
      "Epoch: 44/152 Iteration: 2220 Validation loss: 1.088627 Validation acc: 0.644167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44/152 Iteration: 2225 Train loss: 1.055087 Train acc: 0.670000\n",
      "Epoch: 44/152 Iteration: 2230 Train loss: 1.137962 Train acc: 0.590000\n",
      "Epoch: 44/152 Iteration: 2230 Validation loss: 1.077628 Validation acc: 0.643333\n",
      "Epoch: 44/152 Iteration: 2235 Train loss: 0.873026 Train acc: 0.680000\n",
      "Epoch: 44/152 Iteration: 2240 Train loss: 1.083756 Train acc: 0.660000\n",
      "Epoch: 44/152 Iteration: 2240 Validation loss: 1.076438 Validation acc: 0.634167\n",
      "Epoch: 44/152 Iteration: 2245 Train loss: 0.974730 Train acc: 0.680000\n",
      "Epoch: 44/152 Iteration: 2250 Train loss: 1.058519 Train acc: 0.680000\n",
      "Epoch: 44/152 Iteration: 2250 Validation loss: 1.068374 Validation acc: 0.649167\n",
      "Epoch: 45/152 Iteration: 2255 Train loss: 1.018987 Train acc: 0.620000\n",
      "Epoch: 45/152 Iteration: 2260 Train loss: 0.969461 Train acc: 0.700000\n",
      "Epoch: 45/152 Iteration: 2260 Validation loss: 1.075535 Validation acc: 0.649167\n",
      "Epoch: 45/152 Iteration: 2265 Train loss: 1.026520 Train acc: 0.680000\n",
      "Epoch: 45/152 Iteration: 2270 Train loss: 1.045510 Train acc: 0.630000\n",
      "Epoch: 45/152 Iteration: 2270 Validation loss: 1.069446 Validation acc: 0.646667\n",
      "Epoch: 45/152 Iteration: 2275 Train loss: 1.098122 Train acc: 0.640000\n",
      "Epoch: 45/152 Iteration: 2280 Train loss: 1.074182 Train acc: 0.650000\n",
      "Epoch: 45/152 Iteration: 2280 Validation loss: 1.068417 Validation acc: 0.647500\n",
      "Epoch: 45/152 Iteration: 2285 Train loss: 0.961239 Train acc: 0.640000\n",
      "Epoch: 45/152 Iteration: 2290 Train loss: 1.081555 Train acc: 0.680000\n",
      "Epoch: 45/152 Iteration: 2290 Validation loss: 1.068088 Validation acc: 0.644167\n",
      "Epoch: 45/152 Iteration: 2295 Train loss: 0.977890 Train acc: 0.650000\n",
      "Epoch: 45/152 Iteration: 2300 Train loss: 1.114172 Train acc: 0.630000\n",
      "Epoch: 45/152 Iteration: 2300 Validation loss: 1.068928 Validation acc: 0.648333\n",
      "Epoch: 46/152 Iteration: 2305 Train loss: 1.022720 Train acc: 0.570000\n",
      "Epoch: 46/152 Iteration: 2310 Train loss: 1.027821 Train acc: 0.610000\n",
      "Epoch: 46/152 Iteration: 2310 Validation loss: 1.068785 Validation acc: 0.655000\n",
      "Epoch: 46/152 Iteration: 2315 Train loss: 1.000189 Train acc: 0.640000\n",
      "Epoch: 46/152 Iteration: 2320 Train loss: 1.104718 Train acc: 0.610000\n",
      "Epoch: 46/152 Iteration: 2320 Validation loss: 1.076980 Validation acc: 0.647500\n",
      "Epoch: 46/152 Iteration: 2325 Train loss: 1.091181 Train acc: 0.610000\n",
      "Epoch: 46/152 Iteration: 2330 Train loss: 1.097538 Train acc: 0.640000\n",
      "Epoch: 46/152 Iteration: 2330 Validation loss: 1.078160 Validation acc: 0.636667\n",
      "Epoch: 46/152 Iteration: 2335 Train loss: 1.012302 Train acc: 0.670000\n",
      "Epoch: 46/152 Iteration: 2340 Train loss: 1.048290 Train acc: 0.680000\n",
      "Epoch: 46/152 Iteration: 2340 Validation loss: 1.068628 Validation acc: 0.635833\n",
      "Epoch: 46/152 Iteration: 2345 Train loss: 0.963550 Train acc: 0.660000\n",
      "Epoch: 46/152 Iteration: 2350 Train loss: 1.022447 Train acc: 0.640000\n",
      "Epoch: 46/152 Iteration: 2350 Validation loss: 1.069380 Validation acc: 0.645833\n",
      "Epoch: 47/152 Iteration: 2355 Train loss: 1.073184 Train acc: 0.620000\n",
      "Epoch: 47/152 Iteration: 2360 Train loss: 0.931409 Train acc: 0.700000\n",
      "Epoch: 47/152 Iteration: 2360 Validation loss: 1.079856 Validation acc: 0.654167\n",
      "Epoch: 47/152 Iteration: 2365 Train loss: 1.006879 Train acc: 0.670000\n",
      "Epoch: 47/152 Iteration: 2370 Train loss: 1.109347 Train acc: 0.660000\n",
      "Epoch: 47/152 Iteration: 2370 Validation loss: 1.068636 Validation acc: 0.655833\n",
      "Epoch: 47/152 Iteration: 2375 Train loss: 1.073230 Train acc: 0.630000\n",
      "Epoch: 47/152 Iteration: 2380 Train loss: 1.080686 Train acc: 0.610000\n",
      "Epoch: 47/152 Iteration: 2380 Validation loss: 1.065181 Validation acc: 0.650833\n",
      "Epoch: 47/152 Iteration: 2385 Train loss: 0.933577 Train acc: 0.690000\n",
      "Epoch: 47/152 Iteration: 2390 Train loss: 1.084298 Train acc: 0.690000\n",
      "Epoch: 47/152 Iteration: 2390 Validation loss: 1.062655 Validation acc: 0.646667\n",
      "Epoch: 47/152 Iteration: 2395 Train loss: 0.960798 Train acc: 0.640000\n",
      "Epoch: 47/152 Iteration: 2400 Train loss: 1.134999 Train acc: 0.650000\n",
      "Epoch: 47/152 Iteration: 2400 Validation loss: 1.057896 Validation acc: 0.648333\n",
      "Epoch: 48/152 Iteration: 2405 Train loss: 1.038178 Train acc: 0.600000\n",
      "Epoch: 48/152 Iteration: 2410 Train loss: 0.947935 Train acc: 0.710000\n",
      "Epoch: 48/152 Iteration: 2410 Validation loss: 1.067996 Validation acc: 0.663333\n",
      "Epoch: 48/152 Iteration: 2415 Train loss: 0.989968 Train acc: 0.690000\n",
      "Epoch: 48/152 Iteration: 2420 Train loss: 1.032279 Train acc: 0.630000\n",
      "Epoch: 48/152 Iteration: 2420 Validation loss: 1.053941 Validation acc: 0.647500\n",
      "Epoch: 48/152 Iteration: 2425 Train loss: 1.080200 Train acc: 0.600000\n",
      "Epoch: 48/152 Iteration: 2430 Train loss: 1.099449 Train acc: 0.580000\n",
      "Epoch: 48/152 Iteration: 2430 Validation loss: 1.058146 Validation acc: 0.642500\n",
      "Epoch: 48/152 Iteration: 2435 Train loss: 0.884648 Train acc: 0.660000\n",
      "Epoch: 48/152 Iteration: 2440 Train loss: 1.043912 Train acc: 0.720000\n",
      "Epoch: 48/152 Iteration: 2440 Validation loss: 1.056588 Validation acc: 0.645833\n",
      "Epoch: 48/152 Iteration: 2445 Train loss: 0.940647 Train acc: 0.710000\n",
      "Epoch: 48/152 Iteration: 2450 Train loss: 1.055413 Train acc: 0.640000\n",
      "Epoch: 48/152 Iteration: 2450 Validation loss: 1.058190 Validation acc: 0.647500\n",
      "Epoch: 49/152 Iteration: 2455 Train loss: 1.081941 Train acc: 0.630000\n",
      "Epoch: 49/152 Iteration: 2460 Train loss: 0.919578 Train acc: 0.680000\n",
      "Epoch: 49/152 Iteration: 2460 Validation loss: 1.065593 Validation acc: 0.655833\n",
      "Epoch: 49/152 Iteration: 2465 Train loss: 1.024067 Train acc: 0.640000\n",
      "Epoch: 49/152 Iteration: 2470 Train loss: 0.951676 Train acc: 0.680000\n",
      "Epoch: 49/152 Iteration: 2470 Validation loss: 1.061760 Validation acc: 0.654167\n",
      "Epoch: 49/152 Iteration: 2475 Train loss: 1.029302 Train acc: 0.680000\n",
      "Epoch: 49/152 Iteration: 2480 Train loss: 1.120450 Train acc: 0.620000\n",
      "Epoch: 49/152 Iteration: 2480 Validation loss: 1.075892 Validation acc: 0.636667\n",
      "Epoch: 49/152 Iteration: 2485 Train loss: 0.945731 Train acc: 0.690000\n",
      "Epoch: 49/152 Iteration: 2490 Train loss: 1.037748 Train acc: 0.650000\n",
      "Epoch: 49/152 Iteration: 2490 Validation loss: 1.065539 Validation acc: 0.644167\n",
      "Epoch: 49/152 Iteration: 2495 Train loss: 0.925599 Train acc: 0.680000\n",
      "Epoch: 49/152 Iteration: 2500 Train loss: 1.048343 Train acc: 0.640000\n",
      "Epoch: 49/152 Iteration: 2500 Validation loss: 1.061595 Validation acc: 0.652500\n",
      "Epoch: 50/152 Iteration: 2505 Train loss: 1.001500 Train acc: 0.620000\n",
      "Epoch: 50/152 Iteration: 2510 Train loss: 0.946089 Train acc: 0.700000\n",
      "Epoch: 50/152 Iteration: 2510 Validation loss: 1.058198 Validation acc: 0.663333\n",
      "Epoch: 50/152 Iteration: 2515 Train loss: 1.022042 Train acc: 0.630000\n",
      "Epoch: 50/152 Iteration: 2520 Train loss: 0.994668 Train acc: 0.660000\n",
      "Epoch: 50/152 Iteration: 2520 Validation loss: 1.049747 Validation acc: 0.654167\n",
      "Epoch: 50/152 Iteration: 2525 Train loss: 1.016572 Train acc: 0.670000\n",
      "Epoch: 50/152 Iteration: 2530 Train loss: 1.065263 Train acc: 0.590000\n",
      "Epoch: 50/152 Iteration: 2530 Validation loss: 1.054620 Validation acc: 0.640000\n",
      "Epoch: 50/152 Iteration: 2535 Train loss: 0.922848 Train acc: 0.700000\n",
      "Epoch: 50/152 Iteration: 2540 Train loss: 1.053020 Train acc: 0.700000\n",
      "Epoch: 50/152 Iteration: 2540 Validation loss: 1.058054 Validation acc: 0.655000\n",
      "Epoch: 50/152 Iteration: 2545 Train loss: 0.934197 Train acc: 0.700000\n",
      "Epoch: 50/152 Iteration: 2550 Train loss: 1.120438 Train acc: 0.650000\n",
      "Epoch: 50/152 Iteration: 2550 Validation loss: 1.061913 Validation acc: 0.642500\n",
      "Epoch: 51/152 Iteration: 2555 Train loss: 0.986974 Train acc: 0.620000\n",
      "Epoch: 51/152 Iteration: 2560 Train loss: 0.899210 Train acc: 0.710000\n",
      "Epoch: 51/152 Iteration: 2560 Validation loss: 1.056749 Validation acc: 0.665833\n",
      "Epoch: 51/152 Iteration: 2565 Train loss: 0.959885 Train acc: 0.650000\n",
      "Epoch: 51/152 Iteration: 2570 Train loss: 1.066703 Train acc: 0.670000\n",
      "Epoch: 51/152 Iteration: 2570 Validation loss: 1.047536 Validation acc: 0.656667\n",
      "Epoch: 51/152 Iteration: 2575 Train loss: 0.980443 Train acc: 0.680000\n",
      "Epoch: 51/152 Iteration: 2580 Train loss: 1.046090 Train acc: 0.630000\n",
      "Epoch: 51/152 Iteration: 2580 Validation loss: 1.049325 Validation acc: 0.642500\n",
      "Epoch: 51/152 Iteration: 2585 Train loss: 0.975753 Train acc: 0.620000\n",
      "Epoch: 51/152 Iteration: 2590 Train loss: 1.072064 Train acc: 0.680000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 51/152 Iteration: 2590 Validation loss: 1.050613 Validation acc: 0.643333\n",
      "Epoch: 51/152 Iteration: 2595 Train loss: 0.962207 Train acc: 0.670000\n",
      "Epoch: 51/152 Iteration: 2600 Train loss: 1.043042 Train acc: 0.650000\n",
      "Epoch: 51/152 Iteration: 2600 Validation loss: 1.057864 Validation acc: 0.646667\n",
      "Epoch: 52/152 Iteration: 2605 Train loss: 1.082608 Train acc: 0.620000\n",
      "Epoch: 52/152 Iteration: 2610 Train loss: 0.895692 Train acc: 0.700000\n",
      "Epoch: 52/152 Iteration: 2610 Validation loss: 1.063967 Validation acc: 0.666667\n",
      "Epoch: 52/152 Iteration: 2615 Train loss: 0.857072 Train acc: 0.720000\n",
      "Epoch: 52/152 Iteration: 2620 Train loss: 1.045457 Train acc: 0.660000\n",
      "Epoch: 52/152 Iteration: 2620 Validation loss: 1.046602 Validation acc: 0.647500\n",
      "Epoch: 52/152 Iteration: 2625 Train loss: 1.035878 Train acc: 0.650000\n",
      "Epoch: 52/152 Iteration: 2630 Train loss: 1.105051 Train acc: 0.590000\n",
      "Epoch: 52/152 Iteration: 2630 Validation loss: 1.045761 Validation acc: 0.650833\n",
      "Epoch: 52/152 Iteration: 2635 Train loss: 1.033126 Train acc: 0.650000\n",
      "Epoch: 52/152 Iteration: 2640 Train loss: 1.049806 Train acc: 0.700000\n",
      "Epoch: 52/152 Iteration: 2640 Validation loss: 1.055635 Validation acc: 0.650833\n",
      "Epoch: 52/152 Iteration: 2645 Train loss: 0.948170 Train acc: 0.630000\n",
      "Epoch: 52/152 Iteration: 2650 Train loss: 1.075857 Train acc: 0.610000\n",
      "Epoch: 52/152 Iteration: 2650 Validation loss: 1.054056 Validation acc: 0.654167\n",
      "Epoch: 53/152 Iteration: 2655 Train loss: 1.080468 Train acc: 0.630000\n",
      "Epoch: 53/152 Iteration: 2660 Train loss: 0.862927 Train acc: 0.730000\n",
      "Epoch: 53/152 Iteration: 2660 Validation loss: 1.050206 Validation acc: 0.660833\n",
      "Epoch: 53/152 Iteration: 2665 Train loss: 0.915505 Train acc: 0.720000\n",
      "Epoch: 53/152 Iteration: 2670 Train loss: 1.044464 Train acc: 0.640000\n",
      "Epoch: 53/152 Iteration: 2670 Validation loss: 1.049258 Validation acc: 0.665833\n",
      "Epoch: 53/152 Iteration: 2675 Train loss: 1.143983 Train acc: 0.630000\n",
      "Epoch: 53/152 Iteration: 2680 Train loss: 1.028874 Train acc: 0.620000\n",
      "Epoch: 53/152 Iteration: 2680 Validation loss: 1.055010 Validation acc: 0.646667\n",
      "Epoch: 53/152 Iteration: 2685 Train loss: 0.977818 Train acc: 0.670000\n",
      "Epoch: 53/152 Iteration: 2690 Train loss: 1.069263 Train acc: 0.670000\n",
      "Epoch: 53/152 Iteration: 2690 Validation loss: 1.049630 Validation acc: 0.660000\n",
      "Epoch: 53/152 Iteration: 2695 Train loss: 0.954912 Train acc: 0.680000\n",
      "Epoch: 53/152 Iteration: 2700 Train loss: 1.095437 Train acc: 0.630000\n",
      "Epoch: 53/152 Iteration: 2700 Validation loss: 1.045672 Validation acc: 0.655833\n",
      "Epoch: 54/152 Iteration: 2705 Train loss: 1.037770 Train acc: 0.700000\n",
      "Epoch: 54/152 Iteration: 2710 Train loss: 0.964351 Train acc: 0.680000\n",
      "Epoch: 54/152 Iteration: 2710 Validation loss: 1.045547 Validation acc: 0.659167\n",
      "Epoch: 54/152 Iteration: 2715 Train loss: 0.914697 Train acc: 0.700000\n",
      "Epoch: 54/152 Iteration: 2720 Train loss: 1.054507 Train acc: 0.660000\n",
      "Epoch: 54/152 Iteration: 2720 Validation loss: 1.046368 Validation acc: 0.658333\n",
      "Epoch: 54/152 Iteration: 2725 Train loss: 1.013303 Train acc: 0.640000\n",
      "Epoch: 54/152 Iteration: 2730 Train loss: 1.070366 Train acc: 0.630000\n",
      "Epoch: 54/152 Iteration: 2730 Validation loss: 1.054913 Validation acc: 0.647500\n",
      "Epoch: 54/152 Iteration: 2735 Train loss: 0.991187 Train acc: 0.640000\n",
      "Epoch: 54/152 Iteration: 2740 Train loss: 0.989966 Train acc: 0.670000\n",
      "Epoch: 54/152 Iteration: 2740 Validation loss: 1.053784 Validation acc: 0.645000\n",
      "Epoch: 54/152 Iteration: 2745 Train loss: 0.898823 Train acc: 0.700000\n",
      "Epoch: 54/152 Iteration: 2750 Train loss: 1.029544 Train acc: 0.640000\n",
      "Epoch: 54/152 Iteration: 2750 Validation loss: 1.050590 Validation acc: 0.650833\n",
      "Epoch: 55/152 Iteration: 2755 Train loss: 1.014206 Train acc: 0.600000\n",
      "Epoch: 55/152 Iteration: 2760 Train loss: 0.962956 Train acc: 0.700000\n",
      "Epoch: 55/152 Iteration: 2760 Validation loss: 1.044176 Validation acc: 0.663333\n",
      "Epoch: 55/152 Iteration: 2765 Train loss: 0.912506 Train acc: 0.710000\n",
      "Epoch: 55/152 Iteration: 2770 Train loss: 0.977778 Train acc: 0.670000\n",
      "Epoch: 55/152 Iteration: 2770 Validation loss: 1.034202 Validation acc: 0.660833\n",
      "Epoch: 55/152 Iteration: 2775 Train loss: 1.094447 Train acc: 0.640000\n",
      "Epoch: 55/152 Iteration: 2780 Train loss: 1.034525 Train acc: 0.600000\n",
      "Epoch: 55/152 Iteration: 2780 Validation loss: 1.037808 Validation acc: 0.655833\n",
      "Epoch: 55/152 Iteration: 2785 Train loss: 0.870883 Train acc: 0.700000\n",
      "Epoch: 55/152 Iteration: 2790 Train loss: 1.009375 Train acc: 0.700000\n",
      "Epoch: 55/152 Iteration: 2790 Validation loss: 1.036788 Validation acc: 0.652500\n",
      "Epoch: 55/152 Iteration: 2795 Train loss: 0.929209 Train acc: 0.690000\n",
      "Epoch: 55/152 Iteration: 2800 Train loss: 1.086772 Train acc: 0.660000\n",
      "Epoch: 55/152 Iteration: 2800 Validation loss: 1.043411 Validation acc: 0.650833\n",
      "Epoch: 56/152 Iteration: 2805 Train loss: 1.016279 Train acc: 0.640000\n",
      "Epoch: 56/152 Iteration: 2810 Train loss: 0.841667 Train acc: 0.740000\n",
      "Epoch: 56/152 Iteration: 2810 Validation loss: 1.050632 Validation acc: 0.665000\n",
      "Epoch: 56/152 Iteration: 2815 Train loss: 0.939127 Train acc: 0.710000\n",
      "Epoch: 56/152 Iteration: 2820 Train loss: 1.029811 Train acc: 0.690000\n",
      "Epoch: 56/152 Iteration: 2820 Validation loss: 1.037609 Validation acc: 0.645833\n",
      "Epoch: 56/152 Iteration: 2825 Train loss: 1.013264 Train acc: 0.630000\n",
      "Epoch: 56/152 Iteration: 2830 Train loss: 1.086040 Train acc: 0.640000\n",
      "Epoch: 56/152 Iteration: 2830 Validation loss: 1.037910 Validation acc: 0.655000\n",
      "Epoch: 56/152 Iteration: 2835 Train loss: 0.882249 Train acc: 0.700000\n",
      "Epoch: 56/152 Iteration: 2840 Train loss: 1.032240 Train acc: 0.710000\n",
      "Epoch: 56/152 Iteration: 2840 Validation loss: 1.043446 Validation acc: 0.648333\n",
      "Epoch: 56/152 Iteration: 2845 Train loss: 0.904256 Train acc: 0.680000\n",
      "Epoch: 56/152 Iteration: 2850 Train loss: 1.022033 Train acc: 0.710000\n",
      "Epoch: 56/152 Iteration: 2850 Validation loss: 1.046025 Validation acc: 0.652500\n",
      "Epoch: 57/152 Iteration: 2855 Train loss: 0.990002 Train acc: 0.630000\n",
      "Epoch: 57/152 Iteration: 2860 Train loss: 0.925038 Train acc: 0.670000\n",
      "Epoch: 57/152 Iteration: 2860 Validation loss: 1.041910 Validation acc: 0.670000\n",
      "Epoch: 57/152 Iteration: 2865 Train loss: 0.925482 Train acc: 0.680000\n",
      "Epoch: 57/152 Iteration: 2870 Train loss: 0.957926 Train acc: 0.700000\n",
      "Epoch: 57/152 Iteration: 2870 Validation loss: 1.030959 Validation acc: 0.657500\n",
      "Epoch: 57/152 Iteration: 2875 Train loss: 1.011823 Train acc: 0.650000\n",
      "Epoch: 57/152 Iteration: 2880 Train loss: 0.971647 Train acc: 0.650000\n",
      "Epoch: 57/152 Iteration: 2880 Validation loss: 1.033899 Validation acc: 0.664167\n",
      "Epoch: 57/152 Iteration: 2885 Train loss: 0.930101 Train acc: 0.680000\n",
      "Epoch: 57/152 Iteration: 2890 Train loss: 1.000296 Train acc: 0.700000\n",
      "Epoch: 57/152 Iteration: 2890 Validation loss: 1.035467 Validation acc: 0.665000\n",
      "Epoch: 57/152 Iteration: 2895 Train loss: 0.886573 Train acc: 0.670000\n",
      "Epoch: 57/152 Iteration: 2900 Train loss: 1.043549 Train acc: 0.640000\n",
      "Epoch: 57/152 Iteration: 2900 Validation loss: 1.038104 Validation acc: 0.658333\n",
      "Epoch: 58/152 Iteration: 2905 Train loss: 1.030658 Train acc: 0.640000\n",
      "Epoch: 58/152 Iteration: 2910 Train loss: 0.878225 Train acc: 0.690000\n",
      "Epoch: 58/152 Iteration: 2910 Validation loss: 1.052662 Validation acc: 0.672500\n",
      "Epoch: 58/152 Iteration: 2915 Train loss: 0.915073 Train acc: 0.700000\n",
      "Epoch: 58/152 Iteration: 2920 Train loss: 0.978166 Train acc: 0.710000\n",
      "Epoch: 58/152 Iteration: 2920 Validation loss: 1.030858 Validation acc: 0.668333\n",
      "Epoch: 58/152 Iteration: 2925 Train loss: 1.036941 Train acc: 0.640000\n",
      "Epoch: 58/152 Iteration: 2930 Train loss: 0.967047 Train acc: 0.660000\n",
      "Epoch: 58/152 Iteration: 2930 Validation loss: 1.041069 Validation acc: 0.651667\n",
      "Epoch: 58/152 Iteration: 2935 Train loss: 0.881238 Train acc: 0.710000\n",
      "Epoch: 58/152 Iteration: 2940 Train loss: 1.032964 Train acc: 0.680000\n",
      "Epoch: 58/152 Iteration: 2940 Validation loss: 1.042426 Validation acc: 0.665000\n",
      "Epoch: 58/152 Iteration: 2945 Train loss: 0.943076 Train acc: 0.680000\n",
      "Epoch: 58/152 Iteration: 2950 Train loss: 0.939808 Train acc: 0.680000\n",
      "Epoch: 58/152 Iteration: 2950 Validation loss: 1.035677 Validation acc: 0.653333\n",
      "Epoch: 59/152 Iteration: 2955 Train loss: 0.993961 Train acc: 0.640000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 59/152 Iteration: 2960 Train loss: 0.882175 Train acc: 0.710000\n",
      "Epoch: 59/152 Iteration: 2960 Validation loss: 1.048583 Validation acc: 0.667500\n",
      "Epoch: 59/152 Iteration: 2965 Train loss: 0.955988 Train acc: 0.710000\n",
      "Epoch: 59/152 Iteration: 2970 Train loss: 1.038671 Train acc: 0.660000\n",
      "Epoch: 59/152 Iteration: 2970 Validation loss: 1.035597 Validation acc: 0.669167\n",
      "Epoch: 59/152 Iteration: 2975 Train loss: 0.980207 Train acc: 0.680000\n",
      "Epoch: 59/152 Iteration: 2980 Train loss: 0.946143 Train acc: 0.650000\n",
      "Epoch: 59/152 Iteration: 2980 Validation loss: 1.044035 Validation acc: 0.650833\n",
      "Epoch: 59/152 Iteration: 2985 Train loss: 0.848592 Train acc: 0.700000\n",
      "Epoch: 59/152 Iteration: 2990 Train loss: 0.966775 Train acc: 0.730000\n",
      "Epoch: 59/152 Iteration: 2990 Validation loss: 1.038913 Validation acc: 0.654167\n",
      "Epoch: 59/152 Iteration: 2995 Train loss: 0.916880 Train acc: 0.690000\n",
      "Epoch: 59/152 Iteration: 3000 Train loss: 1.036089 Train acc: 0.650000\n",
      "Epoch: 59/152 Iteration: 3000 Validation loss: 1.037029 Validation acc: 0.660000\n",
      "Epoch: 60/152 Iteration: 3005 Train loss: 0.974356 Train acc: 0.670000\n",
      "Epoch: 60/152 Iteration: 3010 Train loss: 0.977181 Train acc: 0.680000\n",
      "Epoch: 60/152 Iteration: 3010 Validation loss: 1.040530 Validation acc: 0.670000\n",
      "Epoch: 60/152 Iteration: 3015 Train loss: 0.931529 Train acc: 0.690000\n",
      "Epoch: 60/152 Iteration: 3020 Train loss: 0.993206 Train acc: 0.640000\n",
      "Epoch: 60/152 Iteration: 3020 Validation loss: 1.022473 Validation acc: 0.666667\n",
      "Epoch: 60/152 Iteration: 3025 Train loss: 0.990622 Train acc: 0.680000\n",
      "Epoch: 60/152 Iteration: 3030 Train loss: 1.015436 Train acc: 0.640000\n",
      "Epoch: 60/152 Iteration: 3030 Validation loss: 1.033590 Validation acc: 0.655000\n",
      "Epoch: 60/152 Iteration: 3035 Train loss: 0.907240 Train acc: 0.660000\n",
      "Epoch: 60/152 Iteration: 3040 Train loss: 1.042411 Train acc: 0.680000\n",
      "Epoch: 60/152 Iteration: 3040 Validation loss: 1.036699 Validation acc: 0.653333\n",
      "Epoch: 60/152 Iteration: 3045 Train loss: 0.898257 Train acc: 0.670000\n",
      "Epoch: 60/152 Iteration: 3050 Train loss: 1.026884 Train acc: 0.650000\n",
      "Epoch: 60/152 Iteration: 3050 Validation loss: 1.029412 Validation acc: 0.658333\n",
      "Epoch: 61/152 Iteration: 3055 Train loss: 1.036902 Train acc: 0.670000\n",
      "Epoch: 61/152 Iteration: 3060 Train loss: 0.810180 Train acc: 0.770000\n",
      "Epoch: 61/152 Iteration: 3060 Validation loss: 1.036577 Validation acc: 0.672500\n",
      "Epoch: 61/152 Iteration: 3065 Train loss: 0.938820 Train acc: 0.670000\n",
      "Epoch: 61/152 Iteration: 3070 Train loss: 0.981871 Train acc: 0.670000\n",
      "Epoch: 61/152 Iteration: 3070 Validation loss: 1.020916 Validation acc: 0.671667\n",
      "Epoch: 61/152 Iteration: 3075 Train loss: 1.059383 Train acc: 0.630000\n",
      "Epoch: 61/152 Iteration: 3080 Train loss: 1.082925 Train acc: 0.620000\n",
      "Epoch: 61/152 Iteration: 3080 Validation loss: 1.024753 Validation acc: 0.665000\n",
      "Epoch: 61/152 Iteration: 3085 Train loss: 0.833364 Train acc: 0.710000\n",
      "Epoch: 61/152 Iteration: 3090 Train loss: 0.986074 Train acc: 0.690000\n",
      "Epoch: 61/152 Iteration: 3090 Validation loss: 1.029831 Validation acc: 0.663333\n",
      "Epoch: 61/152 Iteration: 3095 Train loss: 0.966948 Train acc: 0.650000\n",
      "Epoch: 61/152 Iteration: 3100 Train loss: 0.991776 Train acc: 0.720000\n",
      "Epoch: 61/152 Iteration: 3100 Validation loss: 1.031737 Validation acc: 0.660833\n",
      "Epoch: 62/152 Iteration: 3105 Train loss: 1.036818 Train acc: 0.620000\n",
      "Epoch: 62/152 Iteration: 3110 Train loss: 0.929575 Train acc: 0.640000\n",
      "Epoch: 62/152 Iteration: 3110 Validation loss: 1.043014 Validation acc: 0.666667\n",
      "Epoch: 62/152 Iteration: 3115 Train loss: 0.964679 Train acc: 0.660000\n",
      "Epoch: 62/152 Iteration: 3120 Train loss: 0.960864 Train acc: 0.680000\n",
      "Epoch: 62/152 Iteration: 3120 Validation loss: 1.025152 Validation acc: 0.669167\n",
      "Epoch: 62/152 Iteration: 3125 Train loss: 1.008102 Train acc: 0.630000\n",
      "Epoch: 62/152 Iteration: 3130 Train loss: 1.030592 Train acc: 0.600000\n",
      "Epoch: 62/152 Iteration: 3130 Validation loss: 1.038202 Validation acc: 0.646667\n",
      "Epoch: 62/152 Iteration: 3135 Train loss: 0.843248 Train acc: 0.720000\n",
      "Epoch: 62/152 Iteration: 3140 Train loss: 1.016475 Train acc: 0.700000\n",
      "Epoch: 62/152 Iteration: 3140 Validation loss: 1.033904 Validation acc: 0.664167\n",
      "Epoch: 62/152 Iteration: 3145 Train loss: 0.885442 Train acc: 0.690000\n",
      "Epoch: 62/152 Iteration: 3150 Train loss: 1.040243 Train acc: 0.700000\n",
      "Epoch: 62/152 Iteration: 3150 Validation loss: 1.030939 Validation acc: 0.660000\n",
      "Epoch: 63/152 Iteration: 3155 Train loss: 0.978990 Train acc: 0.650000\n",
      "Epoch: 63/152 Iteration: 3160 Train loss: 0.851813 Train acc: 0.720000\n",
      "Epoch: 63/152 Iteration: 3160 Validation loss: 1.028134 Validation acc: 0.668333\n",
      "Epoch: 63/152 Iteration: 3165 Train loss: 0.899822 Train acc: 0.730000\n",
      "Epoch: 63/152 Iteration: 3170 Train loss: 0.886004 Train acc: 0.690000\n",
      "Epoch: 63/152 Iteration: 3170 Validation loss: 1.017400 Validation acc: 0.666667\n",
      "Epoch: 63/152 Iteration: 3175 Train loss: 0.956405 Train acc: 0.660000\n",
      "Epoch: 63/152 Iteration: 3180 Train loss: 0.990113 Train acc: 0.650000\n",
      "Epoch: 63/152 Iteration: 3180 Validation loss: 1.021609 Validation acc: 0.656667\n",
      "Epoch: 63/152 Iteration: 3185 Train loss: 0.846449 Train acc: 0.710000\n",
      "Epoch: 63/152 Iteration: 3190 Train loss: 0.994811 Train acc: 0.700000\n",
      "Epoch: 63/152 Iteration: 3190 Validation loss: 1.019962 Validation acc: 0.657500\n",
      "Epoch: 63/152 Iteration: 3195 Train loss: 0.926752 Train acc: 0.680000\n",
      "Epoch: 63/152 Iteration: 3200 Train loss: 0.981118 Train acc: 0.700000\n",
      "Epoch: 63/152 Iteration: 3200 Validation loss: 1.024472 Validation acc: 0.665000\n",
      "Epoch: 64/152 Iteration: 3205 Train loss: 0.996174 Train acc: 0.630000\n",
      "Epoch: 64/152 Iteration: 3210 Train loss: 0.911339 Train acc: 0.680000\n",
      "Epoch: 64/152 Iteration: 3210 Validation loss: 1.035539 Validation acc: 0.672500\n",
      "Epoch: 64/152 Iteration: 3215 Train loss: 0.972999 Train acc: 0.700000\n",
      "Epoch: 64/152 Iteration: 3220 Train loss: 0.973027 Train acc: 0.650000\n",
      "Epoch: 64/152 Iteration: 3220 Validation loss: 1.014665 Validation acc: 0.683333\n",
      "Epoch: 64/152 Iteration: 3225 Train loss: 0.958004 Train acc: 0.650000\n",
      "Epoch: 64/152 Iteration: 3230 Train loss: 1.011865 Train acc: 0.680000\n",
      "Epoch: 64/152 Iteration: 3230 Validation loss: 1.025239 Validation acc: 0.655000\n",
      "Epoch: 64/152 Iteration: 3235 Train loss: 0.992347 Train acc: 0.700000\n",
      "Epoch: 64/152 Iteration: 3240 Train loss: 1.005026 Train acc: 0.700000\n",
      "Epoch: 64/152 Iteration: 3240 Validation loss: 1.013368 Validation acc: 0.673333\n",
      "Epoch: 64/152 Iteration: 3245 Train loss: 0.846724 Train acc: 0.720000\n",
      "Epoch: 64/152 Iteration: 3250 Train loss: 1.024216 Train acc: 0.660000\n",
      "Epoch: 64/152 Iteration: 3250 Validation loss: 1.018870 Validation acc: 0.667500\n",
      "Epoch: 65/152 Iteration: 3255 Train loss: 0.907821 Train acc: 0.660000\n",
      "Epoch: 65/152 Iteration: 3260 Train loss: 0.821418 Train acc: 0.710000\n",
      "Epoch: 65/152 Iteration: 3260 Validation loss: 1.022036 Validation acc: 0.674167\n",
      "Epoch: 65/152 Iteration: 3265 Train loss: 0.914833 Train acc: 0.690000\n",
      "Epoch: 65/152 Iteration: 3270 Train loss: 1.026173 Train acc: 0.670000\n",
      "Epoch: 65/152 Iteration: 3270 Validation loss: 1.012472 Validation acc: 0.665000\n",
      "Epoch: 65/152 Iteration: 3275 Train loss: 1.013701 Train acc: 0.680000\n",
      "Epoch: 65/152 Iteration: 3280 Train loss: 0.989304 Train acc: 0.650000\n",
      "Epoch: 65/152 Iteration: 3280 Validation loss: 1.013718 Validation acc: 0.665000\n",
      "Epoch: 65/152 Iteration: 3285 Train loss: 0.921779 Train acc: 0.710000\n",
      "Epoch: 65/152 Iteration: 3290 Train loss: 1.004328 Train acc: 0.710000\n",
      "Epoch: 65/152 Iteration: 3290 Validation loss: 1.027701 Validation acc: 0.670000\n",
      "Epoch: 65/152 Iteration: 3295 Train loss: 0.885026 Train acc: 0.710000\n",
      "Epoch: 65/152 Iteration: 3300 Train loss: 1.024704 Train acc: 0.660000\n",
      "Epoch: 65/152 Iteration: 3300 Validation loss: 1.018387 Validation acc: 0.662500\n",
      "Epoch: 66/152 Iteration: 3305 Train loss: 0.981053 Train acc: 0.630000\n",
      "Epoch: 66/152 Iteration: 3310 Train loss: 0.823588 Train acc: 0.760000\n",
      "Epoch: 66/152 Iteration: 3310 Validation loss: 1.024496 Validation acc: 0.678333\n",
      "Epoch: 66/152 Iteration: 3315 Train loss: 0.974357 Train acc: 0.700000\n",
      "Epoch: 66/152 Iteration: 3320 Train loss: 0.922469 Train acc: 0.710000\n",
      "Epoch: 66/152 Iteration: 3320 Validation loss: 1.002197 Validation acc: 0.670000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 66/152 Iteration: 3325 Train loss: 0.934042 Train acc: 0.710000\n",
      "Epoch: 66/152 Iteration: 3330 Train loss: 0.994946 Train acc: 0.600000\n",
      "Epoch: 66/152 Iteration: 3330 Validation loss: 1.008020 Validation acc: 0.664167\n",
      "Epoch: 66/152 Iteration: 3335 Train loss: 0.809523 Train acc: 0.680000\n",
      "Epoch: 66/152 Iteration: 3340 Train loss: 1.001461 Train acc: 0.710000\n",
      "Epoch: 66/152 Iteration: 3340 Validation loss: 1.010950 Validation acc: 0.672500\n",
      "Epoch: 66/152 Iteration: 3345 Train loss: 0.861283 Train acc: 0.680000\n",
      "Epoch: 66/152 Iteration: 3350 Train loss: 1.015091 Train acc: 0.620000\n",
      "Epoch: 66/152 Iteration: 3350 Validation loss: 1.011411 Validation acc: 0.666667\n",
      "Epoch: 67/152 Iteration: 3355 Train loss: 0.950622 Train acc: 0.640000\n",
      "Epoch: 67/152 Iteration: 3360 Train loss: 0.801349 Train acc: 0.750000\n",
      "Epoch: 67/152 Iteration: 3360 Validation loss: 1.020079 Validation acc: 0.679167\n",
      "Epoch: 67/152 Iteration: 3365 Train loss: 0.868828 Train acc: 0.670000\n",
      "Epoch: 67/152 Iteration: 3370 Train loss: 0.964595 Train acc: 0.670000\n",
      "Epoch: 67/152 Iteration: 3370 Validation loss: 1.000802 Validation acc: 0.673333\n",
      "Epoch: 67/152 Iteration: 3375 Train loss: 0.980558 Train acc: 0.650000\n",
      "Epoch: 67/152 Iteration: 3380 Train loss: 0.995309 Train acc: 0.650000\n",
      "Epoch: 67/152 Iteration: 3380 Validation loss: 1.008203 Validation acc: 0.664167\n",
      "Epoch: 67/152 Iteration: 3385 Train loss: 0.810426 Train acc: 0.710000\n",
      "Epoch: 67/152 Iteration: 3390 Train loss: 0.983771 Train acc: 0.680000\n",
      "Epoch: 67/152 Iteration: 3390 Validation loss: 1.009259 Validation acc: 0.678333\n",
      "Epoch: 67/152 Iteration: 3395 Train loss: 0.861569 Train acc: 0.690000\n",
      "Epoch: 67/152 Iteration: 3400 Train loss: 1.026839 Train acc: 0.630000\n",
      "Epoch: 67/152 Iteration: 3400 Validation loss: 1.004128 Validation acc: 0.666667\n",
      "Epoch: 68/152 Iteration: 3405 Train loss: 0.960337 Train acc: 0.630000\n",
      "Epoch: 68/152 Iteration: 3410 Train loss: 0.895893 Train acc: 0.720000\n",
      "Epoch: 68/152 Iteration: 3410 Validation loss: 1.017287 Validation acc: 0.675000\n",
      "Epoch: 68/152 Iteration: 3415 Train loss: 0.906162 Train acc: 0.710000\n",
      "Epoch: 68/152 Iteration: 3420 Train loss: 1.022655 Train acc: 0.690000\n",
      "Epoch: 68/152 Iteration: 3420 Validation loss: 1.012633 Validation acc: 0.675833\n",
      "Epoch: 68/152 Iteration: 3425 Train loss: 1.003469 Train acc: 0.620000\n",
      "Epoch: 68/152 Iteration: 3430 Train loss: 0.940318 Train acc: 0.660000\n",
      "Epoch: 68/152 Iteration: 3430 Validation loss: 1.012914 Validation acc: 0.662500\n",
      "Epoch: 68/152 Iteration: 3435 Train loss: 0.805430 Train acc: 0.730000\n",
      "Epoch: 68/152 Iteration: 3440 Train loss: 0.981982 Train acc: 0.720000\n",
      "Epoch: 68/152 Iteration: 3440 Validation loss: 1.014616 Validation acc: 0.675000\n",
      "Epoch: 68/152 Iteration: 3445 Train loss: 0.818774 Train acc: 0.710000\n",
      "Epoch: 68/152 Iteration: 3450 Train loss: 1.034629 Train acc: 0.650000\n",
      "Epoch: 68/152 Iteration: 3450 Validation loss: 1.013576 Validation acc: 0.671667\n",
      "Epoch: 69/152 Iteration: 3455 Train loss: 0.954976 Train acc: 0.670000\n",
      "Epoch: 69/152 Iteration: 3460 Train loss: 0.794227 Train acc: 0.740000\n",
      "Epoch: 69/152 Iteration: 3460 Validation loss: 1.029032 Validation acc: 0.677500\n",
      "Epoch: 69/152 Iteration: 3465 Train loss: 0.854373 Train acc: 0.740000\n",
      "Epoch: 69/152 Iteration: 3470 Train loss: 0.938250 Train acc: 0.670000\n",
      "Epoch: 69/152 Iteration: 3470 Validation loss: 0.999609 Validation acc: 0.679167\n",
      "Epoch: 69/152 Iteration: 3475 Train loss: 0.957527 Train acc: 0.670000\n",
      "Epoch: 69/152 Iteration: 3480 Train loss: 0.958324 Train acc: 0.690000\n",
      "Epoch: 69/152 Iteration: 3480 Validation loss: 1.003513 Validation acc: 0.670000\n",
      "Epoch: 69/152 Iteration: 3485 Train loss: 0.831405 Train acc: 0.710000\n",
      "Epoch: 69/152 Iteration: 3490 Train loss: 0.997696 Train acc: 0.680000\n",
      "Epoch: 69/152 Iteration: 3490 Validation loss: 1.001432 Validation acc: 0.685833\n",
      "Epoch: 69/152 Iteration: 3495 Train loss: 0.863579 Train acc: 0.720000\n",
      "Epoch: 69/152 Iteration: 3500 Train loss: 0.937741 Train acc: 0.660000\n",
      "Epoch: 69/152 Iteration: 3500 Validation loss: 1.005840 Validation acc: 0.678333\n",
      "Epoch: 70/152 Iteration: 3505 Train loss: 1.001878 Train acc: 0.630000\n",
      "Epoch: 70/152 Iteration: 3510 Train loss: 0.784871 Train acc: 0.770000\n",
      "Epoch: 70/152 Iteration: 3510 Validation loss: 1.019770 Validation acc: 0.686667\n",
      "Epoch: 70/152 Iteration: 3515 Train loss: 0.790546 Train acc: 0.750000\n",
      "Epoch: 70/152 Iteration: 3520 Train loss: 0.914699 Train acc: 0.710000\n",
      "Epoch: 70/152 Iteration: 3520 Validation loss: 1.002069 Validation acc: 0.681667\n",
      "Epoch: 70/152 Iteration: 3525 Train loss: 0.966900 Train acc: 0.640000\n",
      "Epoch: 70/152 Iteration: 3530 Train loss: 0.978014 Train acc: 0.610000\n",
      "Epoch: 70/152 Iteration: 3530 Validation loss: 1.003369 Validation acc: 0.670000\n",
      "Epoch: 70/152 Iteration: 3535 Train loss: 0.820316 Train acc: 0.720000\n",
      "Epoch: 70/152 Iteration: 3540 Train loss: 0.987901 Train acc: 0.710000\n",
      "Epoch: 70/152 Iteration: 3540 Validation loss: 1.016863 Validation acc: 0.676667\n",
      "Epoch: 70/152 Iteration: 3545 Train loss: 0.827624 Train acc: 0.750000\n",
      "Epoch: 70/152 Iteration: 3550 Train loss: 0.970357 Train acc: 0.700000\n",
      "Epoch: 70/152 Iteration: 3550 Validation loss: 1.015976 Validation acc: 0.667500\n",
      "Epoch: 71/152 Iteration: 3555 Train loss: 0.959875 Train acc: 0.650000\n",
      "Epoch: 71/152 Iteration: 3560 Train loss: 0.798886 Train acc: 0.750000\n",
      "Epoch: 71/152 Iteration: 3560 Validation loss: 1.020362 Validation acc: 0.679167\n",
      "Epoch: 71/152 Iteration: 3565 Train loss: 0.928493 Train acc: 0.690000\n",
      "Epoch: 71/152 Iteration: 3570 Train loss: 0.925465 Train acc: 0.670000\n",
      "Epoch: 71/152 Iteration: 3570 Validation loss: 1.008204 Validation acc: 0.670000\n",
      "Epoch: 71/152 Iteration: 3575 Train loss: 0.991782 Train acc: 0.660000\n",
      "Epoch: 71/152 Iteration: 3580 Train loss: 0.966276 Train acc: 0.650000\n",
      "Epoch: 71/152 Iteration: 3580 Validation loss: 1.017196 Validation acc: 0.665000\n",
      "Epoch: 71/152 Iteration: 3585 Train loss: 0.834604 Train acc: 0.700000\n",
      "Epoch: 71/152 Iteration: 3590 Train loss: 0.968362 Train acc: 0.690000\n",
      "Epoch: 71/152 Iteration: 3590 Validation loss: 1.008646 Validation acc: 0.670000\n",
      "Epoch: 71/152 Iteration: 3595 Train loss: 0.857869 Train acc: 0.710000\n",
      "Epoch: 71/152 Iteration: 3600 Train loss: 0.925022 Train acc: 0.680000\n",
      "Epoch: 71/152 Iteration: 3600 Validation loss: 1.005939 Validation acc: 0.671667\n",
      "Epoch: 72/152 Iteration: 3605 Train loss: 0.918616 Train acc: 0.680000\n",
      "Epoch: 72/152 Iteration: 3610 Train loss: 0.789260 Train acc: 0.750000\n",
      "Epoch: 72/152 Iteration: 3610 Validation loss: 1.011620 Validation acc: 0.676667\n",
      "Epoch: 72/152 Iteration: 3615 Train loss: 0.870665 Train acc: 0.730000\n",
      "Epoch: 72/152 Iteration: 3620 Train loss: 0.839579 Train acc: 0.730000\n",
      "Epoch: 72/152 Iteration: 3620 Validation loss: 0.996527 Validation acc: 0.674167\n",
      "Epoch: 72/152 Iteration: 3625 Train loss: 0.849650 Train acc: 0.730000\n",
      "Epoch: 72/152 Iteration: 3630 Train loss: 0.920835 Train acc: 0.640000\n",
      "Epoch: 72/152 Iteration: 3630 Validation loss: 0.998466 Validation acc: 0.670833\n",
      "Epoch: 72/152 Iteration: 3635 Train loss: 0.771187 Train acc: 0.750000\n",
      "Epoch: 72/152 Iteration: 3640 Train loss: 0.988688 Train acc: 0.700000\n",
      "Epoch: 72/152 Iteration: 3640 Validation loss: 0.997684 Validation acc: 0.681667\n",
      "Epoch: 72/152 Iteration: 3645 Train loss: 0.848731 Train acc: 0.730000\n",
      "Epoch: 72/152 Iteration: 3650 Train loss: 0.959938 Train acc: 0.660000\n",
      "Epoch: 72/152 Iteration: 3650 Validation loss: 1.000445 Validation acc: 0.667500\n",
      "Epoch: 73/152 Iteration: 3655 Train loss: 0.916200 Train acc: 0.660000\n",
      "Epoch: 73/152 Iteration: 3660 Train loss: 0.928730 Train acc: 0.660000\n",
      "Epoch: 73/152 Iteration: 3660 Validation loss: 1.019221 Validation acc: 0.675000\n",
      "Epoch: 73/152 Iteration: 3665 Train loss: 0.946817 Train acc: 0.690000\n",
      "Epoch: 73/152 Iteration: 3670 Train loss: 0.858133 Train acc: 0.740000\n",
      "Epoch: 73/152 Iteration: 3670 Validation loss: 0.997600 Validation acc: 0.680833\n",
      "Epoch: 73/152 Iteration: 3675 Train loss: 0.953496 Train acc: 0.680000\n",
      "Epoch: 73/152 Iteration: 3680 Train loss: 0.883707 Train acc: 0.670000\n",
      "Epoch: 73/152 Iteration: 3680 Validation loss: 1.000081 Validation acc: 0.669167\n",
      "Epoch: 73/152 Iteration: 3685 Train loss: 0.808133 Train acc: 0.710000\n",
      "Epoch: 73/152 Iteration: 3690 Train loss: 0.965249 Train acc: 0.700000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 73/152 Iteration: 3690 Validation loss: 1.006335 Validation acc: 0.675000\n",
      "Epoch: 73/152 Iteration: 3695 Train loss: 1.006864 Train acc: 0.620000\n",
      "Epoch: 73/152 Iteration: 3700 Train loss: 0.961076 Train acc: 0.640000\n",
      "Epoch: 73/152 Iteration: 3700 Validation loss: 1.013224 Validation acc: 0.666667\n",
      "Epoch: 74/152 Iteration: 3705 Train loss: 0.943962 Train acc: 0.660000\n",
      "Epoch: 74/152 Iteration: 3710 Train loss: 0.831035 Train acc: 0.710000\n",
      "Epoch: 74/152 Iteration: 3710 Validation loss: 1.008589 Validation acc: 0.678333\n",
      "Epoch: 74/152 Iteration: 3715 Train loss: 0.859018 Train acc: 0.700000\n",
      "Epoch: 74/152 Iteration: 3720 Train loss: 0.928813 Train acc: 0.700000\n",
      "Epoch: 74/152 Iteration: 3720 Validation loss: 0.997013 Validation acc: 0.678333\n",
      "Epoch: 74/152 Iteration: 3725 Train loss: 0.939721 Train acc: 0.670000\n",
      "Epoch: 74/152 Iteration: 3730 Train loss: 0.929935 Train acc: 0.690000\n",
      "Epoch: 74/152 Iteration: 3730 Validation loss: 1.001518 Validation acc: 0.673333\n",
      "Epoch: 74/152 Iteration: 3735 Train loss: 0.815818 Train acc: 0.700000\n",
      "Epoch: 74/152 Iteration: 3740 Train loss: 0.946011 Train acc: 0.710000\n",
      "Epoch: 74/152 Iteration: 3740 Validation loss: 0.997226 Validation acc: 0.681667\n",
      "Epoch: 74/152 Iteration: 3745 Train loss: 0.899705 Train acc: 0.720000\n",
      "Epoch: 74/152 Iteration: 3750 Train loss: 0.961616 Train acc: 0.700000\n",
      "Epoch: 74/152 Iteration: 3750 Validation loss: 0.990778 Validation acc: 0.680000\n",
      "Epoch: 75/152 Iteration: 3755 Train loss: 0.907175 Train acc: 0.690000\n",
      "Epoch: 75/152 Iteration: 3760 Train loss: 0.858528 Train acc: 0.740000\n",
      "Epoch: 75/152 Iteration: 3760 Validation loss: 1.014823 Validation acc: 0.686667\n",
      "Epoch: 75/152 Iteration: 3765 Train loss: 0.799988 Train acc: 0.740000\n",
      "Epoch: 75/152 Iteration: 3770 Train loss: 0.839587 Train acc: 0.730000\n",
      "Epoch: 75/152 Iteration: 3770 Validation loss: 0.992696 Validation acc: 0.680000\n",
      "Epoch: 75/152 Iteration: 3775 Train loss: 0.865085 Train acc: 0.690000\n",
      "Epoch: 75/152 Iteration: 3780 Train loss: 0.952973 Train acc: 0.650000\n",
      "Epoch: 75/152 Iteration: 3780 Validation loss: 0.997224 Validation acc: 0.675000\n",
      "Epoch: 75/152 Iteration: 3785 Train loss: 0.761755 Train acc: 0.740000\n",
      "Epoch: 75/152 Iteration: 3790 Train loss: 0.933370 Train acc: 0.710000\n",
      "Epoch: 75/152 Iteration: 3790 Validation loss: 0.994961 Validation acc: 0.685833\n",
      "Epoch: 75/152 Iteration: 3795 Train loss: 0.860079 Train acc: 0.680000\n",
      "Epoch: 75/152 Iteration: 3800 Train loss: 0.900777 Train acc: 0.750000\n",
      "Epoch: 75/152 Iteration: 3800 Validation loss: 0.996571 Validation acc: 0.675833\n",
      "Epoch: 76/152 Iteration: 3805 Train loss: 0.960102 Train acc: 0.660000\n",
      "Epoch: 76/152 Iteration: 3810 Train loss: 0.747733 Train acc: 0.730000\n",
      "Epoch: 76/152 Iteration: 3810 Validation loss: 1.005200 Validation acc: 0.684167\n",
      "Epoch: 76/152 Iteration: 3815 Train loss: 0.890399 Train acc: 0.710000\n",
      "Epoch: 76/152 Iteration: 3820 Train loss: 0.894134 Train acc: 0.690000\n",
      "Epoch: 76/152 Iteration: 3820 Validation loss: 0.986420 Validation acc: 0.687500\n",
      "Epoch: 76/152 Iteration: 3825 Train loss: 0.898959 Train acc: 0.680000\n",
      "Epoch: 76/152 Iteration: 3830 Train loss: 0.981713 Train acc: 0.590000\n",
      "Epoch: 76/152 Iteration: 3830 Validation loss: 0.991619 Validation acc: 0.670000\n",
      "Epoch: 76/152 Iteration: 3835 Train loss: 0.744589 Train acc: 0.720000\n",
      "Epoch: 76/152 Iteration: 3840 Train loss: 0.928998 Train acc: 0.700000\n",
      "Epoch: 76/152 Iteration: 3840 Validation loss: 0.997536 Validation acc: 0.681667\n",
      "Epoch: 76/152 Iteration: 3845 Train loss: 0.874947 Train acc: 0.700000\n",
      "Epoch: 76/152 Iteration: 3850 Train loss: 0.920138 Train acc: 0.700000\n",
      "Epoch: 76/152 Iteration: 3850 Validation loss: 0.998230 Validation acc: 0.675833\n",
      "Epoch: 77/152 Iteration: 3855 Train loss: 1.012495 Train acc: 0.640000\n",
      "Epoch: 77/152 Iteration: 3860 Train loss: 0.771541 Train acc: 0.780000\n",
      "Epoch: 77/152 Iteration: 3860 Validation loss: 1.021411 Validation acc: 0.676667\n",
      "Epoch: 77/152 Iteration: 3865 Train loss: 0.856257 Train acc: 0.710000\n",
      "Epoch: 77/152 Iteration: 3870 Train loss: 0.825582 Train acc: 0.680000\n",
      "Epoch: 77/152 Iteration: 3870 Validation loss: 0.993373 Validation acc: 0.683333\n",
      "Epoch: 77/152 Iteration: 3875 Train loss: 0.814563 Train acc: 0.720000\n",
      "Epoch: 77/152 Iteration: 3880 Train loss: 0.883425 Train acc: 0.650000\n",
      "Epoch: 77/152 Iteration: 3880 Validation loss: 0.998038 Validation acc: 0.669167\n",
      "Epoch: 77/152 Iteration: 3885 Train loss: 0.803492 Train acc: 0.710000\n",
      "Epoch: 77/152 Iteration: 3890 Train loss: 0.943837 Train acc: 0.710000\n",
      "Epoch: 77/152 Iteration: 3890 Validation loss: 0.999749 Validation acc: 0.680000\n",
      "Epoch: 77/152 Iteration: 3895 Train loss: 0.819129 Train acc: 0.680000\n",
      "Epoch: 77/152 Iteration: 3900 Train loss: 0.967390 Train acc: 0.680000\n",
      "Epoch: 77/152 Iteration: 3900 Validation loss: 0.996558 Validation acc: 0.678333\n",
      "Epoch: 78/152 Iteration: 3905 Train loss: 0.992765 Train acc: 0.590000\n",
      "Epoch: 78/152 Iteration: 3910 Train loss: 0.808764 Train acc: 0.690000\n",
      "Epoch: 78/152 Iteration: 3910 Validation loss: 0.996695 Validation acc: 0.687500\n",
      "Epoch: 78/152 Iteration: 3915 Train loss: 0.826930 Train acc: 0.730000\n",
      "Epoch: 78/152 Iteration: 3920 Train loss: 0.919349 Train acc: 0.700000\n",
      "Epoch: 78/152 Iteration: 3920 Validation loss: 0.981750 Validation acc: 0.689167\n",
      "Epoch: 78/152 Iteration: 3925 Train loss: 0.845972 Train acc: 0.700000\n",
      "Epoch: 78/152 Iteration: 3930 Train loss: 0.925300 Train acc: 0.670000\n",
      "Epoch: 78/152 Iteration: 3930 Validation loss: 0.989170 Validation acc: 0.680000\n",
      "Epoch: 78/152 Iteration: 3935 Train loss: 0.722101 Train acc: 0.720000\n",
      "Epoch: 78/152 Iteration: 3940 Train loss: 0.927337 Train acc: 0.730000\n",
      "Epoch: 78/152 Iteration: 3940 Validation loss: 0.989666 Validation acc: 0.687500\n",
      "Epoch: 78/152 Iteration: 3945 Train loss: 0.790840 Train acc: 0.700000\n",
      "Epoch: 78/152 Iteration: 3950 Train loss: 0.899437 Train acc: 0.690000\n",
      "Epoch: 78/152 Iteration: 3950 Validation loss: 0.990170 Validation acc: 0.678333\n",
      "Epoch: 79/152 Iteration: 3955 Train loss: 0.897379 Train acc: 0.640000\n",
      "Epoch: 79/152 Iteration: 3960 Train loss: 0.713835 Train acc: 0.760000\n",
      "Epoch: 79/152 Iteration: 3960 Validation loss: 1.008629 Validation acc: 0.689167\n",
      "Epoch: 79/152 Iteration: 3965 Train loss: 0.818850 Train acc: 0.710000\n",
      "Epoch: 79/152 Iteration: 3970 Train loss: 0.840141 Train acc: 0.710000\n",
      "Epoch: 79/152 Iteration: 3970 Validation loss: 0.988861 Validation acc: 0.691667\n",
      "Epoch: 79/152 Iteration: 3975 Train loss: 0.867829 Train acc: 0.640000\n",
      "Epoch: 79/152 Iteration: 3980 Train loss: 0.939478 Train acc: 0.660000\n",
      "Epoch: 79/152 Iteration: 3980 Validation loss: 0.986260 Validation acc: 0.681667\n",
      "Epoch: 79/152 Iteration: 3985 Train loss: 0.781478 Train acc: 0.730000\n",
      "Epoch: 79/152 Iteration: 3990 Train loss: 0.957336 Train acc: 0.690000\n",
      "Epoch: 79/152 Iteration: 3990 Validation loss: 0.988214 Validation acc: 0.690000\n",
      "Epoch: 79/152 Iteration: 3995 Train loss: 0.838094 Train acc: 0.690000\n",
      "Epoch: 79/152 Iteration: 4000 Train loss: 0.937814 Train acc: 0.710000\n",
      "Epoch: 79/152 Iteration: 4000 Validation loss: 0.990857 Validation acc: 0.678333\n",
      "Epoch: 80/152 Iteration: 4005 Train loss: 0.901066 Train acc: 0.680000\n",
      "Epoch: 80/152 Iteration: 4010 Train loss: 0.795175 Train acc: 0.710000\n",
      "Epoch: 80/152 Iteration: 4010 Validation loss: 1.006418 Validation acc: 0.681667\n",
      "Epoch: 80/152 Iteration: 4015 Train loss: 0.771956 Train acc: 0.750000\n",
      "Epoch: 80/152 Iteration: 4020 Train loss: 0.815473 Train acc: 0.680000\n",
      "Epoch: 80/152 Iteration: 4020 Validation loss: 0.984701 Validation acc: 0.685000\n",
      "Epoch: 80/152 Iteration: 4025 Train loss: 0.861867 Train acc: 0.650000\n",
      "Epoch: 80/152 Iteration: 4030 Train loss: 0.890866 Train acc: 0.700000\n",
      "Epoch: 80/152 Iteration: 4030 Validation loss: 0.989641 Validation acc: 0.675833\n",
      "Epoch: 80/152 Iteration: 4035 Train loss: 0.768358 Train acc: 0.730000\n",
      "Epoch: 80/152 Iteration: 4040 Train loss: 0.920204 Train acc: 0.710000\n",
      "Epoch: 80/152 Iteration: 4040 Validation loss: 0.987998 Validation acc: 0.680833\n",
      "Epoch: 80/152 Iteration: 4045 Train loss: 0.905754 Train acc: 0.690000\n",
      "Epoch: 80/152 Iteration: 4050 Train loss: 0.961539 Train acc: 0.680000\n",
      "Epoch: 80/152 Iteration: 4050 Validation loss: 1.002864 Validation acc: 0.672500\n",
      "Epoch: 81/152 Iteration: 4055 Train loss: 0.882482 Train acc: 0.670000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 81/152 Iteration: 4060 Train loss: 0.754643 Train acc: 0.720000\n",
      "Epoch: 81/152 Iteration: 4060 Validation loss: 1.006721 Validation acc: 0.695833\n",
      "Epoch: 81/152 Iteration: 4065 Train loss: 0.747202 Train acc: 0.770000\n",
      "Epoch: 81/152 Iteration: 4070 Train loss: 0.869296 Train acc: 0.700000\n",
      "Epoch: 81/152 Iteration: 4070 Validation loss: 0.986662 Validation acc: 0.685000\n",
      "Epoch: 81/152 Iteration: 4075 Train loss: 0.860340 Train acc: 0.700000\n",
      "Epoch: 81/152 Iteration: 4080 Train loss: 0.894761 Train acc: 0.690000\n",
      "Epoch: 81/152 Iteration: 4080 Validation loss: 0.980687 Validation acc: 0.681667\n",
      "Epoch: 81/152 Iteration: 4085 Train loss: 0.819859 Train acc: 0.710000\n",
      "Epoch: 81/152 Iteration: 4090 Train loss: 0.890431 Train acc: 0.730000\n",
      "Epoch: 81/152 Iteration: 4090 Validation loss: 0.979843 Validation acc: 0.695000\n",
      "Epoch: 81/152 Iteration: 4095 Train loss: 0.758513 Train acc: 0.710000\n",
      "Epoch: 81/152 Iteration: 4100 Train loss: 0.940019 Train acc: 0.670000\n",
      "Epoch: 81/152 Iteration: 4100 Validation loss: 0.988736 Validation acc: 0.681667\n",
      "Epoch: 82/152 Iteration: 4105 Train loss: 0.875670 Train acc: 0.690000\n",
      "Epoch: 82/152 Iteration: 4110 Train loss: 0.799437 Train acc: 0.730000\n",
      "Epoch: 82/152 Iteration: 4110 Validation loss: 1.012267 Validation acc: 0.677500\n",
      "Epoch: 82/152 Iteration: 4115 Train loss: 0.846182 Train acc: 0.720000\n",
      "Epoch: 82/152 Iteration: 4120 Train loss: 0.811141 Train acc: 0.730000\n",
      "Epoch: 82/152 Iteration: 4120 Validation loss: 0.982645 Validation acc: 0.689167\n",
      "Epoch: 82/152 Iteration: 4125 Train loss: 0.855497 Train acc: 0.670000\n",
      "Epoch: 82/152 Iteration: 4130 Train loss: 0.871410 Train acc: 0.660000\n",
      "Epoch: 82/152 Iteration: 4130 Validation loss: 0.979721 Validation acc: 0.691667\n",
      "Epoch: 82/152 Iteration: 4135 Train loss: 0.721691 Train acc: 0.760000\n",
      "Epoch: 82/152 Iteration: 4140 Train loss: 0.952618 Train acc: 0.720000\n",
      "Epoch: 82/152 Iteration: 4140 Validation loss: 0.986156 Validation acc: 0.680000\n",
      "Epoch: 82/152 Iteration: 4145 Train loss: 0.822523 Train acc: 0.700000\n",
      "Epoch: 82/152 Iteration: 4150 Train loss: 0.926768 Train acc: 0.670000\n",
      "Epoch: 82/152 Iteration: 4150 Validation loss: 0.991564 Validation acc: 0.676667\n",
      "Epoch: 83/152 Iteration: 4155 Train loss: 0.867879 Train acc: 0.680000\n",
      "Epoch: 83/152 Iteration: 4160 Train loss: 0.798324 Train acc: 0.760000\n",
      "Epoch: 83/152 Iteration: 4160 Validation loss: 1.009104 Validation acc: 0.682500\n",
      "Epoch: 83/152 Iteration: 4165 Train loss: 0.779626 Train acc: 0.730000\n",
      "Epoch: 83/152 Iteration: 4170 Train loss: 0.870521 Train acc: 0.720000\n",
      "Epoch: 83/152 Iteration: 4170 Validation loss: 0.982473 Validation acc: 0.692500\n",
      "Epoch: 83/152 Iteration: 4175 Train loss: 0.836072 Train acc: 0.690000\n",
      "Epoch: 83/152 Iteration: 4180 Train loss: 0.973300 Train acc: 0.640000\n",
      "Epoch: 83/152 Iteration: 4180 Validation loss: 0.987788 Validation acc: 0.684167\n",
      "Epoch: 83/152 Iteration: 4185 Train loss: 0.734239 Train acc: 0.730000\n",
      "Epoch: 83/152 Iteration: 4190 Train loss: 0.907538 Train acc: 0.710000\n",
      "Epoch: 83/152 Iteration: 4190 Validation loss: 0.988488 Validation acc: 0.686667\n",
      "Epoch: 83/152 Iteration: 4195 Train loss: 0.841262 Train acc: 0.690000\n",
      "Epoch: 83/152 Iteration: 4200 Train loss: 0.938815 Train acc: 0.690000\n",
      "Epoch: 83/152 Iteration: 4200 Validation loss: 0.991705 Validation acc: 0.679167\n",
      "Epoch: 84/152 Iteration: 4205 Train loss: 0.863117 Train acc: 0.680000\n",
      "Epoch: 84/152 Iteration: 4210 Train loss: 0.731603 Train acc: 0.780000\n",
      "Epoch: 84/152 Iteration: 4210 Validation loss: 0.993996 Validation acc: 0.695000\n",
      "Epoch: 84/152 Iteration: 4215 Train loss: 0.845392 Train acc: 0.730000\n",
      "Epoch: 84/152 Iteration: 4220 Train loss: 0.875657 Train acc: 0.740000\n",
      "Epoch: 84/152 Iteration: 4220 Validation loss: 0.974847 Validation acc: 0.690833\n",
      "Epoch: 84/152 Iteration: 4225 Train loss: 0.852017 Train acc: 0.690000\n",
      "Epoch: 84/152 Iteration: 4230 Train loss: 0.878524 Train acc: 0.680000\n",
      "Epoch: 84/152 Iteration: 4230 Validation loss: 0.977843 Validation acc: 0.690000\n",
      "Epoch: 84/152 Iteration: 4235 Train loss: 0.737630 Train acc: 0.740000\n",
      "Epoch: 84/152 Iteration: 4240 Train loss: 0.873487 Train acc: 0.720000\n",
      "Epoch: 84/152 Iteration: 4240 Validation loss: 0.971649 Validation acc: 0.691667\n",
      "Epoch: 84/152 Iteration: 4245 Train loss: 0.807480 Train acc: 0.740000\n",
      "Epoch: 84/152 Iteration: 4250 Train loss: 0.951883 Train acc: 0.660000\n",
      "Epoch: 84/152 Iteration: 4250 Validation loss: 0.975639 Validation acc: 0.682500\n",
      "Epoch: 85/152 Iteration: 4255 Train loss: 0.880580 Train acc: 0.660000\n",
      "Epoch: 85/152 Iteration: 4260 Train loss: 0.769273 Train acc: 0.720000\n",
      "Epoch: 85/152 Iteration: 4260 Validation loss: 1.000611 Validation acc: 0.683333\n",
      "Epoch: 85/152 Iteration: 4265 Train loss: 0.849645 Train acc: 0.740000\n",
      "Epoch: 85/152 Iteration: 4270 Train loss: 0.824199 Train acc: 0.750000\n",
      "Epoch: 85/152 Iteration: 4270 Validation loss: 0.976809 Validation acc: 0.691667\n",
      "Epoch: 85/152 Iteration: 4275 Train loss: 0.793219 Train acc: 0.720000\n",
      "Epoch: 85/152 Iteration: 4280 Train loss: 0.911058 Train acc: 0.650000\n",
      "Epoch: 85/152 Iteration: 4280 Validation loss: 0.974178 Validation acc: 0.688333\n",
      "Epoch: 85/152 Iteration: 4285 Train loss: 0.794638 Train acc: 0.710000\n",
      "Epoch: 85/152 Iteration: 4290 Train loss: 0.903903 Train acc: 0.690000\n",
      "Epoch: 85/152 Iteration: 4290 Validation loss: 0.970738 Validation acc: 0.698333\n",
      "Epoch: 85/152 Iteration: 4295 Train loss: 0.870082 Train acc: 0.730000\n",
      "Epoch: 85/152 Iteration: 4300 Train loss: 0.910726 Train acc: 0.710000\n",
      "Epoch: 85/152 Iteration: 4300 Validation loss: 0.981123 Validation acc: 0.674167\n",
      "Epoch: 86/152 Iteration: 4305 Train loss: 0.895300 Train acc: 0.650000\n",
      "Epoch: 86/152 Iteration: 4310 Train loss: 0.755478 Train acc: 0.740000\n",
      "Epoch: 86/152 Iteration: 4310 Validation loss: 1.003622 Validation acc: 0.681667\n",
      "Epoch: 86/152 Iteration: 4315 Train loss: 0.780072 Train acc: 0.750000\n",
      "Epoch: 86/152 Iteration: 4320 Train loss: 0.869572 Train acc: 0.710000\n",
      "Epoch: 86/152 Iteration: 4320 Validation loss: 0.978773 Validation acc: 0.682500\n",
      "Epoch: 86/152 Iteration: 4325 Train loss: 0.872125 Train acc: 0.690000\n",
      "Epoch: 86/152 Iteration: 4330 Train loss: 0.932659 Train acc: 0.650000\n",
      "Epoch: 86/152 Iteration: 4330 Validation loss: 0.972462 Validation acc: 0.690833\n",
      "Epoch: 86/152 Iteration: 4335 Train loss: 0.740532 Train acc: 0.720000\n",
      "Epoch: 86/152 Iteration: 4340 Train loss: 0.920267 Train acc: 0.740000\n",
      "Epoch: 86/152 Iteration: 4340 Validation loss: 0.973243 Validation acc: 0.688333\n",
      "Epoch: 86/152 Iteration: 4345 Train loss: 0.803926 Train acc: 0.710000\n",
      "Epoch: 86/152 Iteration: 4350 Train loss: 0.901858 Train acc: 0.720000\n",
      "Epoch: 86/152 Iteration: 4350 Validation loss: 0.972498 Validation acc: 0.688333\n",
      "Epoch: 87/152 Iteration: 4355 Train loss: 0.850007 Train acc: 0.700000\n",
      "Epoch: 87/152 Iteration: 4360 Train loss: 0.727439 Train acc: 0.760000\n",
      "Epoch: 87/152 Iteration: 4360 Validation loss: 0.989199 Validation acc: 0.685000\n",
      "Epoch: 87/152 Iteration: 4365 Train loss: 0.762752 Train acc: 0.750000\n",
      "Epoch: 87/152 Iteration: 4370 Train loss: 0.819241 Train acc: 0.730000\n",
      "Epoch: 87/152 Iteration: 4370 Validation loss: 0.973400 Validation acc: 0.695000\n",
      "Epoch: 87/152 Iteration: 4375 Train loss: 0.797431 Train acc: 0.690000\n",
      "Epoch: 87/152 Iteration: 4380 Train loss: 0.834474 Train acc: 0.710000\n",
      "Epoch: 87/152 Iteration: 4380 Validation loss: 0.966430 Validation acc: 0.688333\n",
      "Epoch: 87/152 Iteration: 4385 Train loss: 0.718016 Train acc: 0.750000\n",
      "Epoch: 87/152 Iteration: 4390 Train loss: 0.913728 Train acc: 0.710000\n",
      "Epoch: 87/152 Iteration: 4390 Validation loss: 0.972327 Validation acc: 0.690000\n",
      "Epoch: 87/152 Iteration: 4395 Train loss: 0.895147 Train acc: 0.660000\n",
      "Epoch: 87/152 Iteration: 4400 Train loss: 0.872078 Train acc: 0.700000\n",
      "Epoch: 87/152 Iteration: 4400 Validation loss: 0.973778 Validation acc: 0.687500\n",
      "Epoch: 88/152 Iteration: 4405 Train loss: 0.894525 Train acc: 0.650000\n",
      "Epoch: 88/152 Iteration: 4410 Train loss: 0.699760 Train acc: 0.760000\n",
      "Epoch: 88/152 Iteration: 4410 Validation loss: 0.987389 Validation acc: 0.693333\n",
      "Epoch: 88/152 Iteration: 4415 Train loss: 0.806711 Train acc: 0.760000\n",
      "Epoch: 88/152 Iteration: 4420 Train loss: 0.782266 Train acc: 0.730000\n",
      "Epoch: 88/152 Iteration: 4420 Validation loss: 0.973875 Validation acc: 0.687500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 88/152 Iteration: 4425 Train loss: 0.799144 Train acc: 0.710000\n",
      "Epoch: 88/152 Iteration: 4430 Train loss: 0.902758 Train acc: 0.620000\n",
      "Epoch: 88/152 Iteration: 4430 Validation loss: 0.979335 Validation acc: 0.697500\n",
      "Epoch: 88/152 Iteration: 4435 Train loss: 0.748997 Train acc: 0.710000\n",
      "Epoch: 88/152 Iteration: 4440 Train loss: 0.882127 Train acc: 0.750000\n",
      "Epoch: 88/152 Iteration: 4440 Validation loss: 0.972965 Validation acc: 0.687500\n",
      "Epoch: 88/152 Iteration: 4445 Train loss: 0.748188 Train acc: 0.730000\n",
      "Epoch: 88/152 Iteration: 4450 Train loss: 0.940267 Train acc: 0.660000\n",
      "Epoch: 88/152 Iteration: 4450 Validation loss: 0.971162 Validation acc: 0.683333\n",
      "Epoch: 89/152 Iteration: 4455 Train loss: 0.841693 Train acc: 0.670000\n",
      "Epoch: 89/152 Iteration: 4460 Train loss: 0.702047 Train acc: 0.790000\n",
      "Epoch: 89/152 Iteration: 4460 Validation loss: 0.988759 Validation acc: 0.692500\n",
      "Epoch: 89/152 Iteration: 4465 Train loss: 0.777588 Train acc: 0.770000\n",
      "Epoch: 89/152 Iteration: 4470 Train loss: 0.816205 Train acc: 0.710000\n",
      "Epoch: 89/152 Iteration: 4470 Validation loss: 0.965642 Validation acc: 0.699167\n",
      "Epoch: 89/152 Iteration: 4475 Train loss: 0.848212 Train acc: 0.730000\n",
      "Epoch: 89/152 Iteration: 4480 Train loss: 0.816932 Train acc: 0.720000\n",
      "Epoch: 89/152 Iteration: 4480 Validation loss: 0.970519 Validation acc: 0.690000\n",
      "Epoch: 89/152 Iteration: 4485 Train loss: 0.810169 Train acc: 0.700000\n",
      "Epoch: 89/152 Iteration: 4490 Train loss: 0.912823 Train acc: 0.700000\n",
      "Epoch: 89/152 Iteration: 4490 Validation loss: 0.980278 Validation acc: 0.691667\n",
      "Epoch: 89/152 Iteration: 4495 Train loss: 0.869764 Train acc: 0.690000\n",
      "Epoch: 89/152 Iteration: 4500 Train loss: 0.926360 Train acc: 0.730000\n",
      "Epoch: 89/152 Iteration: 4500 Validation loss: 1.006685 Validation acc: 0.668333\n",
      "Epoch: 90/152 Iteration: 4505 Train loss: 0.879170 Train acc: 0.660000\n",
      "Epoch: 90/152 Iteration: 4510 Train loss: 0.737120 Train acc: 0.730000\n",
      "Epoch: 90/152 Iteration: 4510 Validation loss: 1.021223 Validation acc: 0.691667\n",
      "Epoch: 90/152 Iteration: 4515 Train loss: 0.774505 Train acc: 0.720000\n",
      "Epoch: 90/152 Iteration: 4520 Train loss: 0.851295 Train acc: 0.730000\n",
      "Epoch: 90/152 Iteration: 4520 Validation loss: 0.966671 Validation acc: 0.693333\n",
      "Epoch: 90/152 Iteration: 4525 Train loss: 0.775346 Train acc: 0.720000\n",
      "Epoch: 90/152 Iteration: 4530 Train loss: 0.865969 Train acc: 0.670000\n",
      "Epoch: 90/152 Iteration: 4530 Validation loss: 0.970776 Validation acc: 0.699167\n",
      "Epoch: 90/152 Iteration: 4535 Train loss: 0.754233 Train acc: 0.740000\n",
      "Epoch: 90/152 Iteration: 4540 Train loss: 0.934035 Train acc: 0.710000\n",
      "Epoch: 90/152 Iteration: 4540 Validation loss: 0.963785 Validation acc: 0.694167\n",
      "Epoch: 90/152 Iteration: 4545 Train loss: 0.840217 Train acc: 0.700000\n",
      "Epoch: 90/152 Iteration: 4550 Train loss: 0.908096 Train acc: 0.700000\n",
      "Epoch: 90/152 Iteration: 4550 Validation loss: 0.969162 Validation acc: 0.687500\n",
      "Epoch: 91/152 Iteration: 4555 Train loss: 0.854388 Train acc: 0.670000\n",
      "Epoch: 91/152 Iteration: 4560 Train loss: 0.721991 Train acc: 0.770000\n",
      "Epoch: 91/152 Iteration: 4560 Validation loss: 0.979536 Validation acc: 0.695833\n",
      "Epoch: 91/152 Iteration: 4565 Train loss: 0.825353 Train acc: 0.700000\n",
      "Epoch: 91/152 Iteration: 4570 Train loss: 0.760144 Train acc: 0.790000\n",
      "Epoch: 91/152 Iteration: 4570 Validation loss: 0.970293 Validation acc: 0.690833\n",
      "Epoch: 91/152 Iteration: 4575 Train loss: 0.781686 Train acc: 0.720000\n",
      "Epoch: 91/152 Iteration: 4580 Train loss: 0.837248 Train acc: 0.650000\n",
      "Epoch: 91/152 Iteration: 4580 Validation loss: 0.970282 Validation acc: 0.690833\n",
      "Epoch: 91/152 Iteration: 4585 Train loss: 0.812962 Train acc: 0.720000\n",
      "Epoch: 91/152 Iteration: 4590 Train loss: 0.908600 Train acc: 0.720000\n",
      "Epoch: 91/152 Iteration: 4590 Validation loss: 0.963594 Validation acc: 0.699167\n",
      "Epoch: 91/152 Iteration: 4595 Train loss: 0.725987 Train acc: 0.750000\n",
      "Epoch: 91/152 Iteration: 4600 Train loss: 0.942595 Train acc: 0.700000\n",
      "Epoch: 91/152 Iteration: 4600 Validation loss: 0.972261 Validation acc: 0.680833\n",
      "Epoch: 92/152 Iteration: 4605 Train loss: 0.903823 Train acc: 0.700000\n",
      "Epoch: 92/152 Iteration: 4610 Train loss: 0.717713 Train acc: 0.790000\n",
      "Epoch: 92/152 Iteration: 4610 Validation loss: 0.977994 Validation acc: 0.702500\n",
      "Epoch: 92/152 Iteration: 4615 Train loss: 0.760989 Train acc: 0.770000\n",
      "Epoch: 92/152 Iteration: 4620 Train loss: 0.871073 Train acc: 0.720000\n",
      "Epoch: 92/152 Iteration: 4620 Validation loss: 0.958688 Validation acc: 0.702500\n",
      "Epoch: 92/152 Iteration: 4625 Train loss: 0.751830 Train acc: 0.720000\n",
      "Epoch: 92/152 Iteration: 4630 Train loss: 0.827521 Train acc: 0.670000\n",
      "Epoch: 92/152 Iteration: 4630 Validation loss: 0.960852 Validation acc: 0.695000\n",
      "Epoch: 92/152 Iteration: 4635 Train loss: 0.681477 Train acc: 0.760000\n",
      "Epoch: 92/152 Iteration: 4640 Train loss: 0.863862 Train acc: 0.750000\n",
      "Epoch: 92/152 Iteration: 4640 Validation loss: 0.958486 Validation acc: 0.700833\n",
      "Epoch: 92/152 Iteration: 4645 Train loss: 0.757196 Train acc: 0.730000\n",
      "Epoch: 92/152 Iteration: 4650 Train loss: 0.916181 Train acc: 0.690000\n",
      "Epoch: 92/152 Iteration: 4650 Validation loss: 0.953199 Validation acc: 0.697500\n",
      "Epoch: 93/152 Iteration: 4655 Train loss: 0.822663 Train acc: 0.680000\n",
      "Epoch: 93/152 Iteration: 4660 Train loss: 0.713609 Train acc: 0.800000\n",
      "Epoch: 93/152 Iteration: 4660 Validation loss: 0.984657 Validation acc: 0.690000\n",
      "Epoch: 93/152 Iteration: 4665 Train loss: 0.801833 Train acc: 0.730000\n",
      "Epoch: 93/152 Iteration: 4670 Train loss: 0.785027 Train acc: 0.730000\n",
      "Epoch: 93/152 Iteration: 4670 Validation loss: 0.967790 Validation acc: 0.694167\n",
      "Epoch: 93/152 Iteration: 4675 Train loss: 0.770850 Train acc: 0.760000\n",
      "Epoch: 93/152 Iteration: 4680 Train loss: 0.855478 Train acc: 0.710000\n",
      "Epoch: 93/152 Iteration: 4680 Validation loss: 0.972925 Validation acc: 0.690833\n",
      "Epoch: 93/152 Iteration: 4685 Train loss: 0.787845 Train acc: 0.730000\n",
      "Epoch: 93/152 Iteration: 4690 Train loss: 0.866500 Train acc: 0.740000\n",
      "Epoch: 93/152 Iteration: 4690 Validation loss: 0.957772 Validation acc: 0.695833\n",
      "Epoch: 93/152 Iteration: 4695 Train loss: 0.851449 Train acc: 0.710000\n",
      "Epoch: 93/152 Iteration: 4700 Train loss: 0.863747 Train acc: 0.700000\n",
      "Epoch: 93/152 Iteration: 4700 Validation loss: 0.968769 Validation acc: 0.689167\n",
      "Epoch: 94/152 Iteration: 4705 Train loss: 0.833004 Train acc: 0.670000\n",
      "Epoch: 94/152 Iteration: 4710 Train loss: 0.754437 Train acc: 0.770000\n",
      "Epoch: 94/152 Iteration: 4710 Validation loss: 0.994424 Validation acc: 0.689167\n",
      "Epoch: 94/152 Iteration: 4715 Train loss: 0.888092 Train acc: 0.710000\n",
      "Epoch: 94/152 Iteration: 4720 Train loss: 0.849133 Train acc: 0.710000\n",
      "Epoch: 94/152 Iteration: 4720 Validation loss: 0.966546 Validation acc: 0.696667\n",
      "Epoch: 94/152 Iteration: 4725 Train loss: 0.854471 Train acc: 0.690000\n",
      "Epoch: 94/152 Iteration: 4730 Train loss: 0.811924 Train acc: 0.700000\n",
      "Epoch: 94/152 Iteration: 4730 Validation loss: 0.973977 Validation acc: 0.685833\n",
      "Epoch: 94/152 Iteration: 4735 Train loss: 0.737564 Train acc: 0.760000\n",
      "Epoch: 94/152 Iteration: 4740 Train loss: 0.880174 Train acc: 0.710000\n",
      "Epoch: 94/152 Iteration: 4740 Validation loss: 0.963919 Validation acc: 0.695000\n",
      "Epoch: 94/152 Iteration: 4745 Train loss: 0.776115 Train acc: 0.710000\n",
      "Epoch: 94/152 Iteration: 4750 Train loss: 0.858799 Train acc: 0.700000\n",
      "Epoch: 94/152 Iteration: 4750 Validation loss: 0.968882 Validation acc: 0.690833\n",
      "Epoch: 95/152 Iteration: 4755 Train loss: 0.873541 Train acc: 0.660000\n",
      "Epoch: 95/152 Iteration: 4760 Train loss: 0.704603 Train acc: 0.780000\n",
      "Epoch: 95/152 Iteration: 4760 Validation loss: 0.989037 Validation acc: 0.700000\n",
      "Epoch: 95/152 Iteration: 4765 Train loss: 0.846291 Train acc: 0.720000\n",
      "Epoch: 95/152 Iteration: 4770 Train loss: 0.721655 Train acc: 0.770000\n",
      "Epoch: 95/152 Iteration: 4770 Validation loss: 0.965541 Validation acc: 0.695000\n",
      "Epoch: 95/152 Iteration: 4775 Train loss: 0.796563 Train acc: 0.730000\n",
      "Epoch: 95/152 Iteration: 4780 Train loss: 0.824579 Train acc: 0.710000\n",
      "Epoch: 95/152 Iteration: 4780 Validation loss: 0.975129 Validation acc: 0.693333\n",
      "Epoch: 95/152 Iteration: 4785 Train loss: 0.737210 Train acc: 0.750000\n",
      "Epoch: 95/152 Iteration: 4790 Train loss: 0.912247 Train acc: 0.730000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 95/152 Iteration: 4790 Validation loss: 0.971247 Validation acc: 0.692500\n",
      "Epoch: 95/152 Iteration: 4795 Train loss: 0.792491 Train acc: 0.700000\n",
      "Epoch: 95/152 Iteration: 4800 Train loss: 0.917200 Train acc: 0.680000\n",
      "Epoch: 95/152 Iteration: 4800 Validation loss: 0.969200 Validation acc: 0.695000\n",
      "Epoch: 96/152 Iteration: 4805 Train loss: 0.857145 Train acc: 0.680000\n",
      "Epoch: 96/152 Iteration: 4810 Train loss: 0.697906 Train acc: 0.790000\n",
      "Epoch: 96/152 Iteration: 4810 Validation loss: 0.987062 Validation acc: 0.695833\n",
      "Epoch: 96/152 Iteration: 4815 Train loss: 0.808529 Train acc: 0.680000\n",
      "Epoch: 96/152 Iteration: 4820 Train loss: 0.783679 Train acc: 0.750000\n",
      "Epoch: 96/152 Iteration: 4820 Validation loss: 0.967227 Validation acc: 0.680833\n",
      "Epoch: 96/152 Iteration: 4825 Train loss: 0.722939 Train acc: 0.730000\n",
      "Epoch: 96/152 Iteration: 4830 Train loss: 0.817401 Train acc: 0.710000\n",
      "Epoch: 96/152 Iteration: 4830 Validation loss: 0.966265 Validation acc: 0.702500\n",
      "Epoch: 96/152 Iteration: 4835 Train loss: 0.723116 Train acc: 0.760000\n",
      "Epoch: 96/152 Iteration: 4840 Train loss: 0.902264 Train acc: 0.680000\n",
      "Epoch: 96/152 Iteration: 4840 Validation loss: 0.959105 Validation acc: 0.694167\n",
      "Epoch: 96/152 Iteration: 4845 Train loss: 0.784606 Train acc: 0.710000\n",
      "Epoch: 96/152 Iteration: 4850 Train loss: 0.893363 Train acc: 0.680000\n",
      "Epoch: 96/152 Iteration: 4850 Validation loss: 0.965430 Validation acc: 0.691667\n",
      "Epoch: 97/152 Iteration: 4855 Train loss: 0.817291 Train acc: 0.680000\n",
      "Epoch: 97/152 Iteration: 4860 Train loss: 0.695012 Train acc: 0.780000\n",
      "Epoch: 97/152 Iteration: 4860 Validation loss: 0.994129 Validation acc: 0.693333\n",
      "Epoch: 97/152 Iteration: 4865 Train loss: 0.780496 Train acc: 0.740000\n",
      "Epoch: 97/152 Iteration: 4870 Train loss: 0.763526 Train acc: 0.760000\n",
      "Epoch: 97/152 Iteration: 4870 Validation loss: 0.960418 Validation acc: 0.688333\n",
      "Epoch: 97/152 Iteration: 4875 Train loss: 0.761992 Train acc: 0.720000\n",
      "Epoch: 97/152 Iteration: 4880 Train loss: 0.778429 Train acc: 0.730000\n",
      "Epoch: 97/152 Iteration: 4880 Validation loss: 0.976789 Validation acc: 0.700000\n",
      "Epoch: 97/152 Iteration: 4885 Train loss: 0.681153 Train acc: 0.730000\n",
      "Epoch: 97/152 Iteration: 4890 Train loss: 0.937904 Train acc: 0.670000\n",
      "Epoch: 97/152 Iteration: 4890 Validation loss: 0.963340 Validation acc: 0.694167\n",
      "Epoch: 97/152 Iteration: 4895 Train loss: 0.842910 Train acc: 0.720000\n",
      "Epoch: 97/152 Iteration: 4900 Train loss: 0.848649 Train acc: 0.730000\n",
      "Epoch: 97/152 Iteration: 4900 Validation loss: 0.957545 Validation acc: 0.692500\n",
      "Epoch: 98/152 Iteration: 4905 Train loss: 0.827504 Train acc: 0.680000\n",
      "Epoch: 98/152 Iteration: 4910 Train loss: 0.640417 Train acc: 0.800000\n",
      "Epoch: 98/152 Iteration: 4910 Validation loss: 0.979140 Validation acc: 0.695833\n",
      "Epoch: 98/152 Iteration: 4915 Train loss: 0.807389 Train acc: 0.730000\n",
      "Epoch: 98/152 Iteration: 4920 Train loss: 0.851676 Train acc: 0.710000\n",
      "Epoch: 98/152 Iteration: 4920 Validation loss: 0.958871 Validation acc: 0.695833\n",
      "Epoch: 98/152 Iteration: 4925 Train loss: 0.779565 Train acc: 0.690000\n",
      "Epoch: 98/152 Iteration: 4930 Train loss: 0.831216 Train acc: 0.720000\n",
      "Epoch: 98/152 Iteration: 4930 Validation loss: 0.968112 Validation acc: 0.691667\n",
      "Epoch: 98/152 Iteration: 4935 Train loss: 0.720903 Train acc: 0.760000\n",
      "Epoch: 98/152 Iteration: 4940 Train loss: 0.920284 Train acc: 0.710000\n",
      "Epoch: 98/152 Iteration: 4940 Validation loss: 0.964140 Validation acc: 0.698333\n",
      "Epoch: 98/152 Iteration: 4945 Train loss: 0.737842 Train acc: 0.750000\n",
      "Epoch: 98/152 Iteration: 4950 Train loss: 0.846354 Train acc: 0.700000\n",
      "Epoch: 98/152 Iteration: 4950 Validation loss: 0.964682 Validation acc: 0.690000\n",
      "Epoch: 99/152 Iteration: 4955 Train loss: 0.800976 Train acc: 0.720000\n",
      "Epoch: 99/152 Iteration: 4960 Train loss: 0.693652 Train acc: 0.780000\n",
      "Epoch: 99/152 Iteration: 4960 Validation loss: 0.969688 Validation acc: 0.708333\n",
      "Epoch: 99/152 Iteration: 4965 Train loss: 0.672837 Train acc: 0.770000\n",
      "Epoch: 99/152 Iteration: 4970 Train loss: 0.695543 Train acc: 0.750000\n",
      "Epoch: 99/152 Iteration: 4970 Validation loss: 0.955192 Validation acc: 0.697500\n",
      "Epoch: 99/152 Iteration: 4975 Train loss: 0.730235 Train acc: 0.710000\n",
      "Epoch: 99/152 Iteration: 4980 Train loss: 0.814297 Train acc: 0.700000\n",
      "Epoch: 99/152 Iteration: 4980 Validation loss: 0.960015 Validation acc: 0.696667\n",
      "Epoch: 99/152 Iteration: 4985 Train loss: 0.711484 Train acc: 0.740000\n",
      "Epoch: 99/152 Iteration: 4990 Train loss: 0.891045 Train acc: 0.740000\n",
      "Epoch: 99/152 Iteration: 4990 Validation loss: 0.953341 Validation acc: 0.700000\n",
      "Epoch: 99/152 Iteration: 4995 Train loss: 0.757791 Train acc: 0.720000\n",
      "Epoch: 99/152 Iteration: 5000 Train loss: 0.872123 Train acc: 0.720000\n",
      "Epoch: 99/152 Iteration: 5000 Validation loss: 0.967475 Validation acc: 0.695000\n",
      "Epoch: 100/152 Iteration: 5005 Train loss: 0.847046 Train acc: 0.650000\n",
      "Epoch: 100/152 Iteration: 5010 Train loss: 0.691241 Train acc: 0.790000\n",
      "Epoch: 100/152 Iteration: 5010 Validation loss: 1.000478 Validation acc: 0.694167\n",
      "Epoch: 100/152 Iteration: 5015 Train loss: 0.734133 Train acc: 0.750000\n",
      "Epoch: 100/152 Iteration: 5020 Train loss: 0.734385 Train acc: 0.810000\n",
      "Epoch: 100/152 Iteration: 5020 Validation loss: 0.964987 Validation acc: 0.688333\n",
      "Epoch: 100/152 Iteration: 5025 Train loss: 0.703080 Train acc: 0.740000\n",
      "Epoch: 100/152 Iteration: 5030 Train loss: 0.817741 Train acc: 0.720000\n",
      "Epoch: 100/152 Iteration: 5030 Validation loss: 0.969984 Validation acc: 0.700833\n",
      "Epoch: 100/152 Iteration: 5035 Train loss: 0.777849 Train acc: 0.770000\n",
      "Epoch: 100/152 Iteration: 5040 Train loss: 0.909333 Train acc: 0.690000\n",
      "Epoch: 100/152 Iteration: 5040 Validation loss: 0.957513 Validation acc: 0.693333\n",
      "Epoch: 100/152 Iteration: 5045 Train loss: 0.754815 Train acc: 0.720000\n",
      "Epoch: 100/152 Iteration: 5050 Train loss: 0.869003 Train acc: 0.680000\n",
      "Epoch: 100/152 Iteration: 5050 Validation loss: 0.956495 Validation acc: 0.696667\n",
      "Epoch: 101/152 Iteration: 5055 Train loss: 0.832624 Train acc: 0.680000\n",
      "Epoch: 101/152 Iteration: 5060 Train loss: 0.665610 Train acc: 0.790000\n",
      "Epoch: 101/152 Iteration: 5060 Validation loss: 0.980660 Validation acc: 0.700000\n",
      "Epoch: 101/152 Iteration: 5065 Train loss: 0.743617 Train acc: 0.750000\n",
      "Epoch: 101/152 Iteration: 5070 Train loss: 0.781120 Train acc: 0.720000\n",
      "Epoch: 101/152 Iteration: 5070 Validation loss: 0.952732 Validation acc: 0.704167\n",
      "Epoch: 101/152 Iteration: 5075 Train loss: 0.756918 Train acc: 0.730000\n",
      "Epoch: 101/152 Iteration: 5080 Train loss: 0.814508 Train acc: 0.740000\n",
      "Epoch: 101/152 Iteration: 5080 Validation loss: 0.959659 Validation acc: 0.691667\n",
      "Epoch: 101/152 Iteration: 5085 Train loss: 0.729898 Train acc: 0.740000\n",
      "Epoch: 101/152 Iteration: 5090 Train loss: 0.945804 Train acc: 0.690000\n",
      "Epoch: 101/152 Iteration: 5090 Validation loss: 0.959407 Validation acc: 0.694167\n",
      "Epoch: 101/152 Iteration: 5095 Train loss: 0.732989 Train acc: 0.750000\n",
      "Epoch: 101/152 Iteration: 5100 Train loss: 0.834653 Train acc: 0.770000\n",
      "Epoch: 101/152 Iteration: 5100 Validation loss: 0.961567 Validation acc: 0.695833\n",
      "Epoch: 102/152 Iteration: 5105 Train loss: 0.824070 Train acc: 0.700000\n",
      "Epoch: 102/152 Iteration: 5110 Train loss: 0.671857 Train acc: 0.800000\n",
      "Epoch: 102/152 Iteration: 5110 Validation loss: 0.975773 Validation acc: 0.697500\n",
      "Epoch: 102/152 Iteration: 5115 Train loss: 0.796731 Train acc: 0.760000\n",
      "Epoch: 102/152 Iteration: 5120 Train loss: 0.734883 Train acc: 0.750000\n",
      "Epoch: 102/152 Iteration: 5120 Validation loss: 0.957381 Validation acc: 0.698333\n",
      "Epoch: 102/152 Iteration: 5125 Train loss: 0.745066 Train acc: 0.760000\n",
      "Epoch: 102/152 Iteration: 5130 Train loss: 0.851945 Train acc: 0.710000\n",
      "Epoch: 102/152 Iteration: 5130 Validation loss: 0.972187 Validation acc: 0.695833\n",
      "Epoch: 102/152 Iteration: 5135 Train loss: 0.692647 Train acc: 0.770000\n",
      "Epoch: 102/152 Iteration: 5140 Train loss: 0.852037 Train acc: 0.740000\n",
      "Epoch: 102/152 Iteration: 5140 Validation loss: 0.959183 Validation acc: 0.687500\n",
      "Epoch: 102/152 Iteration: 5145 Train loss: 0.813500 Train acc: 0.740000\n",
      "Epoch: 102/152 Iteration: 5150 Train loss: 0.871562 Train acc: 0.730000\n",
      "Epoch: 102/152 Iteration: 5150 Validation loss: 0.957374 Validation acc: 0.696667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 103/152 Iteration: 5155 Train loss: 0.829991 Train acc: 0.690000\n",
      "Epoch: 103/152 Iteration: 5160 Train loss: 0.709644 Train acc: 0.780000\n",
      "Epoch: 103/152 Iteration: 5160 Validation loss: 0.993314 Validation acc: 0.688333\n",
      "Epoch: 103/152 Iteration: 5165 Train loss: 0.749731 Train acc: 0.760000\n",
      "Epoch: 103/152 Iteration: 5170 Train loss: 0.785266 Train acc: 0.720000\n",
      "Epoch: 103/152 Iteration: 5170 Validation loss: 0.979123 Validation acc: 0.684167\n",
      "Epoch: 103/152 Iteration: 5175 Train loss: 0.680099 Train acc: 0.730000\n",
      "Epoch: 103/152 Iteration: 5180 Train loss: 0.819270 Train acc: 0.690000\n",
      "Epoch: 103/152 Iteration: 5180 Validation loss: 0.977983 Validation acc: 0.689167\n",
      "Epoch: 103/152 Iteration: 5185 Train loss: 0.728495 Train acc: 0.760000\n",
      "Epoch: 103/152 Iteration: 5190 Train loss: 0.906834 Train acc: 0.720000\n",
      "Epoch: 103/152 Iteration: 5190 Validation loss: 0.961006 Validation acc: 0.693333\n",
      "Epoch: 103/152 Iteration: 5195 Train loss: 0.827288 Train acc: 0.740000\n",
      "Epoch: 103/152 Iteration: 5200 Train loss: 0.896230 Train acc: 0.730000\n",
      "Epoch: 103/152 Iteration: 5200 Validation loss: 0.958401 Validation acc: 0.681667\n",
      "Epoch: 104/152 Iteration: 5205 Train loss: 0.821434 Train acc: 0.670000\n",
      "Epoch: 104/152 Iteration: 5210 Train loss: 0.703888 Train acc: 0.760000\n",
      "Epoch: 104/152 Iteration: 5210 Validation loss: 0.962525 Validation acc: 0.708333\n",
      "Epoch: 104/152 Iteration: 5215 Train loss: 0.782279 Train acc: 0.760000\n",
      "Epoch: 104/152 Iteration: 5220 Train loss: 0.773427 Train acc: 0.730000\n",
      "Epoch: 104/152 Iteration: 5220 Validation loss: 0.952972 Validation acc: 0.705000\n",
      "Epoch: 104/152 Iteration: 5225 Train loss: 0.724233 Train acc: 0.720000\n",
      "Epoch: 104/152 Iteration: 5230 Train loss: 0.815239 Train acc: 0.750000\n",
      "Epoch: 104/152 Iteration: 5230 Validation loss: 0.948174 Validation acc: 0.705000\n",
      "Epoch: 104/152 Iteration: 5235 Train loss: 0.698103 Train acc: 0.750000\n",
      "Epoch: 104/152 Iteration: 5240 Train loss: 0.879119 Train acc: 0.760000\n",
      "Epoch: 104/152 Iteration: 5240 Validation loss: 0.947969 Validation acc: 0.705833\n",
      "Epoch: 104/152 Iteration: 5245 Train loss: 0.770645 Train acc: 0.690000\n",
      "Epoch: 104/152 Iteration: 5250 Train loss: 0.926675 Train acc: 0.630000\n",
      "Epoch: 104/152 Iteration: 5250 Validation loss: 0.948415 Validation acc: 0.697500\n",
      "Epoch: 105/152 Iteration: 5255 Train loss: 0.808897 Train acc: 0.720000\n",
      "Epoch: 105/152 Iteration: 5260 Train loss: 0.667577 Train acc: 0.790000\n",
      "Epoch: 105/152 Iteration: 5260 Validation loss: 0.971753 Validation acc: 0.698333\n",
      "Epoch: 105/152 Iteration: 5265 Train loss: 0.744936 Train acc: 0.760000\n",
      "Epoch: 105/152 Iteration: 5270 Train loss: 0.801812 Train acc: 0.750000\n",
      "Epoch: 105/152 Iteration: 5270 Validation loss: 0.953929 Validation acc: 0.703333\n",
      "Epoch: 105/152 Iteration: 5275 Train loss: 0.823979 Train acc: 0.720000\n",
      "Epoch: 105/152 Iteration: 5280 Train loss: 0.768741 Train acc: 0.760000\n",
      "Epoch: 105/152 Iteration: 5280 Validation loss: 0.962221 Validation acc: 0.703333\n",
      "Epoch: 105/152 Iteration: 5285 Train loss: 0.727202 Train acc: 0.760000\n",
      "Epoch: 105/152 Iteration: 5290 Train loss: 0.839620 Train acc: 0.770000\n",
      "Epoch: 105/152 Iteration: 5290 Validation loss: 0.953982 Validation acc: 0.697500\n",
      "Epoch: 105/152 Iteration: 5295 Train loss: 0.787796 Train acc: 0.730000\n",
      "Epoch: 105/152 Iteration: 5300 Train loss: 0.843744 Train acc: 0.730000\n",
      "Epoch: 105/152 Iteration: 5300 Validation loss: 0.950283 Validation acc: 0.696667\n",
      "Epoch: 106/152 Iteration: 5305 Train loss: 0.788406 Train acc: 0.720000\n",
      "Epoch: 106/152 Iteration: 5310 Train loss: 0.665645 Train acc: 0.790000\n",
      "Epoch: 106/152 Iteration: 5310 Validation loss: 0.983982 Validation acc: 0.696667\n",
      "Epoch: 106/152 Iteration: 5315 Train loss: 0.693758 Train acc: 0.780000\n",
      "Epoch: 106/152 Iteration: 5320 Train loss: 0.721927 Train acc: 0.760000\n",
      "Epoch: 106/152 Iteration: 5320 Validation loss: 0.958494 Validation acc: 0.694167\n",
      "Epoch: 106/152 Iteration: 5325 Train loss: 0.706442 Train acc: 0.740000\n",
      "Epoch: 106/152 Iteration: 5330 Train loss: 0.844979 Train acc: 0.700000\n",
      "Epoch: 106/152 Iteration: 5330 Validation loss: 0.960180 Validation acc: 0.704167\n",
      "Epoch: 106/152 Iteration: 5335 Train loss: 0.724664 Train acc: 0.770000\n",
      "Epoch: 106/152 Iteration: 5340 Train loss: 0.825921 Train acc: 0.790000\n",
      "Epoch: 106/152 Iteration: 5340 Validation loss: 0.953677 Validation acc: 0.703333\n",
      "Epoch: 106/152 Iteration: 5345 Train loss: 0.763438 Train acc: 0.740000\n",
      "Epoch: 106/152 Iteration: 5350 Train loss: 0.907109 Train acc: 0.730000\n",
      "Epoch: 106/152 Iteration: 5350 Validation loss: 0.952310 Validation acc: 0.703333\n",
      "Epoch: 107/152 Iteration: 5355 Train loss: 0.817983 Train acc: 0.670000\n",
      "Epoch: 107/152 Iteration: 5360 Train loss: 0.672646 Train acc: 0.730000\n",
      "Epoch: 107/152 Iteration: 5360 Validation loss: 0.975645 Validation acc: 0.700000\n",
      "Epoch: 107/152 Iteration: 5365 Train loss: 0.778376 Train acc: 0.790000\n",
      "Epoch: 107/152 Iteration: 5370 Train loss: 0.796017 Train acc: 0.720000\n",
      "Epoch: 107/152 Iteration: 5370 Validation loss: 0.948287 Validation acc: 0.698333\n",
      "Epoch: 107/152 Iteration: 5375 Train loss: 0.734071 Train acc: 0.720000\n",
      "Epoch: 107/152 Iteration: 5380 Train loss: 0.826475 Train acc: 0.720000\n",
      "Epoch: 107/152 Iteration: 5380 Validation loss: 0.962607 Validation acc: 0.699167\n",
      "Epoch: 107/152 Iteration: 5385 Train loss: 0.650200 Train acc: 0.760000\n",
      "Epoch: 107/152 Iteration: 5390 Train loss: 0.802292 Train acc: 0.750000\n",
      "Epoch: 107/152 Iteration: 5390 Validation loss: 0.951351 Validation acc: 0.695000\n",
      "Epoch: 107/152 Iteration: 5395 Train loss: 0.809661 Train acc: 0.730000\n",
      "Epoch: 107/152 Iteration: 5400 Train loss: 0.814306 Train acc: 0.720000\n",
      "Epoch: 107/152 Iteration: 5400 Validation loss: 0.950214 Validation acc: 0.705833\n",
      "Epoch: 108/152 Iteration: 5405 Train loss: 0.811974 Train acc: 0.680000\n",
      "Epoch: 108/152 Iteration: 5410 Train loss: 0.705285 Train acc: 0.770000\n",
      "Epoch: 108/152 Iteration: 5410 Validation loss: 0.976826 Validation acc: 0.698333\n",
      "Epoch: 108/152 Iteration: 5415 Train loss: 0.713034 Train acc: 0.760000\n",
      "Epoch: 108/152 Iteration: 5420 Train loss: 0.767336 Train acc: 0.760000\n",
      "Epoch: 108/152 Iteration: 5420 Validation loss: 0.953425 Validation acc: 0.695000\n",
      "Epoch: 108/152 Iteration: 5425 Train loss: 0.763913 Train acc: 0.680000\n",
      "Epoch: 108/152 Iteration: 5430 Train loss: 0.759567 Train acc: 0.730000\n",
      "Epoch: 108/152 Iteration: 5430 Validation loss: 0.958403 Validation acc: 0.703333\n",
      "Epoch: 108/152 Iteration: 5435 Train loss: 0.694507 Train acc: 0.750000\n",
      "Epoch: 108/152 Iteration: 5440 Train loss: 0.883868 Train acc: 0.740000\n",
      "Epoch: 108/152 Iteration: 5440 Validation loss: 0.945126 Validation acc: 0.699167\n",
      "Epoch: 108/152 Iteration: 5445 Train loss: 0.735697 Train acc: 0.750000\n",
      "Epoch: 108/152 Iteration: 5450 Train loss: 0.812430 Train acc: 0.740000\n",
      "Epoch: 108/152 Iteration: 5450 Validation loss: 0.954465 Validation acc: 0.703333\n",
      "Epoch: 109/152 Iteration: 5455 Train loss: 0.762484 Train acc: 0.700000\n",
      "Epoch: 109/152 Iteration: 5460 Train loss: 0.675525 Train acc: 0.780000\n",
      "Epoch: 109/152 Iteration: 5460 Validation loss: 0.979588 Validation acc: 0.703333\n",
      "Epoch: 109/152 Iteration: 5465 Train loss: 0.737688 Train acc: 0.730000\n",
      "Epoch: 109/152 Iteration: 5470 Train loss: 0.808138 Train acc: 0.730000\n",
      "Epoch: 109/152 Iteration: 5470 Validation loss: 0.954333 Validation acc: 0.705000\n",
      "Epoch: 109/152 Iteration: 5475 Train loss: 0.728233 Train acc: 0.730000\n",
      "Epoch: 109/152 Iteration: 5480 Train loss: 0.850726 Train acc: 0.720000\n",
      "Epoch: 109/152 Iteration: 5480 Validation loss: 0.969514 Validation acc: 0.702500\n",
      "Epoch: 109/152 Iteration: 5485 Train loss: 0.698878 Train acc: 0.760000\n",
      "Epoch: 109/152 Iteration: 5490 Train loss: 0.853215 Train acc: 0.760000\n",
      "Epoch: 109/152 Iteration: 5490 Validation loss: 0.958578 Validation acc: 0.699167\n",
      "Epoch: 109/152 Iteration: 5495 Train loss: 0.750890 Train acc: 0.740000\n",
      "Epoch: 109/152 Iteration: 5500 Train loss: 0.840843 Train acc: 0.700000\n",
      "Epoch: 109/152 Iteration: 5500 Validation loss: 0.956414 Validation acc: 0.705000\n",
      "Epoch: 110/152 Iteration: 5505 Train loss: 0.781911 Train acc: 0.700000\n",
      "Epoch: 110/152 Iteration: 5510 Train loss: 0.644632 Train acc: 0.810000\n",
      "Epoch: 110/152 Iteration: 5510 Validation loss: 0.969982 Validation acc: 0.704167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 110/152 Iteration: 5515 Train loss: 0.697296 Train acc: 0.780000\n",
      "Epoch: 110/152 Iteration: 5520 Train loss: 0.741804 Train acc: 0.770000\n",
      "Epoch: 110/152 Iteration: 5520 Validation loss: 0.957125 Validation acc: 0.695833\n",
      "Epoch: 110/152 Iteration: 5525 Train loss: 0.702239 Train acc: 0.740000\n",
      "Epoch: 110/152 Iteration: 5530 Train loss: 0.823722 Train acc: 0.710000\n",
      "Epoch: 110/152 Iteration: 5530 Validation loss: 0.969331 Validation acc: 0.705833\n",
      "Epoch: 110/152 Iteration: 5535 Train loss: 0.745596 Train acc: 0.720000\n",
      "Epoch: 110/152 Iteration: 5540 Train loss: 0.835702 Train acc: 0.710000\n",
      "Epoch: 110/152 Iteration: 5540 Validation loss: 0.946818 Validation acc: 0.700000\n",
      "Epoch: 110/152 Iteration: 5545 Train loss: 0.737101 Train acc: 0.750000\n",
      "Epoch: 110/152 Iteration: 5550 Train loss: 0.801191 Train acc: 0.750000\n",
      "Epoch: 110/152 Iteration: 5550 Validation loss: 0.952579 Validation acc: 0.694167\n",
      "Epoch: 111/152 Iteration: 5555 Train loss: 0.788234 Train acc: 0.720000\n",
      "Epoch: 111/152 Iteration: 5560 Train loss: 0.643141 Train acc: 0.760000\n",
      "Epoch: 111/152 Iteration: 5560 Validation loss: 0.960180 Validation acc: 0.708333\n",
      "Epoch: 111/152 Iteration: 5565 Train loss: 0.733509 Train acc: 0.760000\n",
      "Epoch: 111/152 Iteration: 5570 Train loss: 0.677950 Train acc: 0.810000\n",
      "Epoch: 111/152 Iteration: 5570 Validation loss: 0.949797 Validation acc: 0.698333\n",
      "Epoch: 111/152 Iteration: 5575 Train loss: 0.671168 Train acc: 0.760000\n",
      "Epoch: 111/152 Iteration: 5580 Train loss: 0.844922 Train acc: 0.670000\n",
      "Epoch: 111/152 Iteration: 5580 Validation loss: 0.957350 Validation acc: 0.704167\n",
      "Epoch: 111/152 Iteration: 5585 Train loss: 0.636768 Train acc: 0.800000\n",
      "Epoch: 111/152 Iteration: 5590 Train loss: 0.789966 Train acc: 0.760000\n",
      "Epoch: 111/152 Iteration: 5590 Validation loss: 0.954750 Validation acc: 0.692500\n",
      "Epoch: 111/152 Iteration: 5595 Train loss: 0.761694 Train acc: 0.750000\n",
      "Epoch: 111/152 Iteration: 5600 Train loss: 0.852310 Train acc: 0.710000\n",
      "Epoch: 111/152 Iteration: 5600 Validation loss: 0.961124 Validation acc: 0.690833\n",
      "Epoch: 112/152 Iteration: 5605 Train loss: 0.732400 Train acc: 0.720000\n",
      "Epoch: 112/152 Iteration: 5610 Train loss: 0.666403 Train acc: 0.770000\n",
      "Epoch: 112/152 Iteration: 5610 Validation loss: 0.974933 Validation acc: 0.707500\n",
      "Epoch: 112/152 Iteration: 5615 Train loss: 0.679005 Train acc: 0.780000\n",
      "Epoch: 112/152 Iteration: 5620 Train loss: 0.754943 Train acc: 0.780000\n",
      "Epoch: 112/152 Iteration: 5620 Validation loss: 0.948004 Validation acc: 0.702500\n",
      "Epoch: 112/152 Iteration: 5625 Train loss: 0.704887 Train acc: 0.760000\n",
      "Epoch: 112/152 Iteration: 5630 Train loss: 0.821344 Train acc: 0.660000\n",
      "Epoch: 112/152 Iteration: 5630 Validation loss: 0.953726 Validation acc: 0.706667\n",
      "Epoch: 112/152 Iteration: 5635 Train loss: 0.627603 Train acc: 0.810000\n",
      "Epoch: 112/152 Iteration: 5640 Train loss: 0.825321 Train acc: 0.740000\n",
      "Epoch: 112/152 Iteration: 5640 Validation loss: 0.947856 Validation acc: 0.700000\n",
      "Epoch: 112/152 Iteration: 5645 Train loss: 0.777341 Train acc: 0.720000\n",
      "Epoch: 112/152 Iteration: 5650 Train loss: 0.839279 Train acc: 0.710000\n",
      "Epoch: 112/152 Iteration: 5650 Validation loss: 0.947314 Validation acc: 0.703333\n",
      "Epoch: 113/152 Iteration: 5655 Train loss: 0.818674 Train acc: 0.680000\n",
      "Epoch: 113/152 Iteration: 5660 Train loss: 0.653394 Train acc: 0.810000\n",
      "Epoch: 113/152 Iteration: 5660 Validation loss: 0.966197 Validation acc: 0.706667\n",
      "Epoch: 113/152 Iteration: 5665 Train loss: 0.767492 Train acc: 0.720000\n",
      "Epoch: 113/152 Iteration: 5670 Train loss: 0.727231 Train acc: 0.770000\n",
      "Epoch: 113/152 Iteration: 5670 Validation loss: 0.952196 Validation acc: 0.697500\n",
      "Epoch: 113/152 Iteration: 5675 Train loss: 0.759832 Train acc: 0.770000\n",
      "Epoch: 113/152 Iteration: 5680 Train loss: 0.771511 Train acc: 0.770000\n",
      "Epoch: 113/152 Iteration: 5680 Validation loss: 0.956457 Validation acc: 0.704167\n",
      "Epoch: 113/152 Iteration: 5685 Train loss: 0.657736 Train acc: 0.800000\n",
      "Epoch: 113/152 Iteration: 5690 Train loss: 0.816986 Train acc: 0.730000\n",
      "Epoch: 113/152 Iteration: 5690 Validation loss: 0.945466 Validation acc: 0.695000\n",
      "Epoch: 113/152 Iteration: 5695 Train loss: 0.771019 Train acc: 0.730000\n",
      "Epoch: 113/152 Iteration: 5700 Train loss: 0.782542 Train acc: 0.750000\n",
      "Epoch: 113/152 Iteration: 5700 Validation loss: 0.946466 Validation acc: 0.699167\n",
      "Epoch: 114/152 Iteration: 5705 Train loss: 0.747636 Train acc: 0.710000\n",
      "Epoch: 114/152 Iteration: 5710 Train loss: 0.700808 Train acc: 0.780000\n",
      "Epoch: 114/152 Iteration: 5710 Validation loss: 0.978619 Validation acc: 0.700833\n",
      "Epoch: 114/152 Iteration: 5715 Train loss: 0.723130 Train acc: 0.710000\n",
      "Epoch: 114/152 Iteration: 5720 Train loss: 0.727579 Train acc: 0.760000\n",
      "Epoch: 114/152 Iteration: 5720 Validation loss: 0.959869 Validation acc: 0.703333\n",
      "Epoch: 114/152 Iteration: 5725 Train loss: 0.707373 Train acc: 0.730000\n",
      "Epoch: 114/152 Iteration: 5730 Train loss: 0.775078 Train acc: 0.700000\n",
      "Epoch: 114/152 Iteration: 5730 Validation loss: 0.957052 Validation acc: 0.705833\n",
      "Epoch: 114/152 Iteration: 5735 Train loss: 0.627775 Train acc: 0.770000\n",
      "Epoch: 114/152 Iteration: 5740 Train loss: 0.816342 Train acc: 0.730000\n",
      "Epoch: 114/152 Iteration: 5740 Validation loss: 0.951239 Validation acc: 0.710000\n",
      "Epoch: 114/152 Iteration: 5745 Train loss: 0.659729 Train acc: 0.770000\n",
      "Epoch: 114/152 Iteration: 5750 Train loss: 0.897856 Train acc: 0.690000\n",
      "Epoch: 114/152 Iteration: 5750 Validation loss: 0.947943 Validation acc: 0.703333\n",
      "Epoch: 115/152 Iteration: 5755 Train loss: 0.804712 Train acc: 0.680000\n",
      "Epoch: 115/152 Iteration: 5760 Train loss: 0.613515 Train acc: 0.780000\n",
      "Epoch: 115/152 Iteration: 5760 Validation loss: 0.970735 Validation acc: 0.705833\n",
      "Epoch: 115/152 Iteration: 5765 Train loss: 0.758897 Train acc: 0.750000\n",
      "Epoch: 115/152 Iteration: 5770 Train loss: 0.653066 Train acc: 0.770000\n",
      "Epoch: 115/152 Iteration: 5770 Validation loss: 0.953450 Validation acc: 0.705833\n",
      "Epoch: 115/152 Iteration: 5775 Train loss: 0.732575 Train acc: 0.740000\n",
      "Epoch: 115/152 Iteration: 5780 Train loss: 0.744435 Train acc: 0.730000\n",
      "Epoch: 115/152 Iteration: 5780 Validation loss: 0.955240 Validation acc: 0.710833\n",
      "Epoch: 115/152 Iteration: 5785 Train loss: 0.726210 Train acc: 0.760000\n",
      "Epoch: 115/152 Iteration: 5790 Train loss: 0.800124 Train acc: 0.720000\n",
      "Epoch: 115/152 Iteration: 5790 Validation loss: 0.951571 Validation acc: 0.695833\n",
      "Epoch: 115/152 Iteration: 5795 Train loss: 0.792917 Train acc: 0.750000\n",
      "Epoch: 115/152 Iteration: 5800 Train loss: 0.837964 Train acc: 0.720000\n",
      "Epoch: 115/152 Iteration: 5800 Validation loss: 0.938856 Validation acc: 0.705000\n",
      "Epoch: 116/152 Iteration: 5805 Train loss: 0.789911 Train acc: 0.670000\n",
      "Epoch: 116/152 Iteration: 5810 Train loss: 0.593466 Train acc: 0.790000\n",
      "Epoch: 116/152 Iteration: 5810 Validation loss: 0.962578 Validation acc: 0.703333\n",
      "Epoch: 116/152 Iteration: 5815 Train loss: 0.725940 Train acc: 0.770000\n",
      "Epoch: 116/152 Iteration: 5820 Train loss: 0.701725 Train acc: 0.780000\n",
      "Epoch: 116/152 Iteration: 5820 Validation loss: 0.948962 Validation acc: 0.703333\n",
      "Epoch: 116/152 Iteration: 5825 Train loss: 0.733685 Train acc: 0.700000\n",
      "Epoch: 116/152 Iteration: 5830 Train loss: 0.712755 Train acc: 0.730000\n",
      "Epoch: 116/152 Iteration: 5830 Validation loss: 0.959496 Validation acc: 0.712500\n",
      "Epoch: 116/152 Iteration: 5835 Train loss: 0.735622 Train acc: 0.720000\n",
      "Epoch: 116/152 Iteration: 5840 Train loss: 0.834977 Train acc: 0.750000\n",
      "Epoch: 116/152 Iteration: 5840 Validation loss: 0.948920 Validation acc: 0.695833\n",
      "Epoch: 116/152 Iteration: 5845 Train loss: 0.760194 Train acc: 0.720000\n",
      "Epoch: 116/152 Iteration: 5850 Train loss: 0.848072 Train acc: 0.730000\n",
      "Epoch: 116/152 Iteration: 5850 Validation loss: 0.939028 Validation acc: 0.705000\n",
      "Epoch: 117/152 Iteration: 5855 Train loss: 0.785263 Train acc: 0.710000\n",
      "Epoch: 117/152 Iteration: 5860 Train loss: 0.704455 Train acc: 0.740000\n",
      "Epoch: 117/152 Iteration: 5860 Validation loss: 0.969176 Validation acc: 0.702500\n",
      "Epoch: 117/152 Iteration: 5865 Train loss: 0.718801 Train acc: 0.780000\n",
      "Epoch: 117/152 Iteration: 5870 Train loss: 0.716124 Train acc: 0.770000\n",
      "Epoch: 117/152 Iteration: 5870 Validation loss: 0.949529 Validation acc: 0.705000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 117/152 Iteration: 5875 Train loss: 0.721878 Train acc: 0.750000\n",
      "Epoch: 117/152 Iteration: 5880 Train loss: 0.748638 Train acc: 0.730000\n",
      "Epoch: 117/152 Iteration: 5880 Validation loss: 0.964109 Validation acc: 0.709167\n",
      "Epoch: 117/152 Iteration: 5885 Train loss: 0.624490 Train acc: 0.790000\n",
      "Epoch: 117/152 Iteration: 5890 Train loss: 0.880906 Train acc: 0.730000\n",
      "Epoch: 117/152 Iteration: 5890 Validation loss: 0.950976 Validation acc: 0.705833\n",
      "Epoch: 117/152 Iteration: 5895 Train loss: 0.760657 Train acc: 0.720000\n",
      "Epoch: 117/152 Iteration: 5900 Train loss: 0.772990 Train acc: 0.750000\n",
      "Epoch: 117/152 Iteration: 5900 Validation loss: 0.945584 Validation acc: 0.695833\n",
      "Epoch: 118/152 Iteration: 5905 Train loss: 0.721782 Train acc: 0.750000\n",
      "Epoch: 118/152 Iteration: 5910 Train loss: 0.655384 Train acc: 0.800000\n",
      "Epoch: 118/152 Iteration: 5910 Validation loss: 0.988288 Validation acc: 0.700000\n",
      "Epoch: 118/152 Iteration: 5915 Train loss: 0.728267 Train acc: 0.760000\n",
      "Epoch: 118/152 Iteration: 5920 Train loss: 0.716584 Train acc: 0.770000\n",
      "Epoch: 118/152 Iteration: 5920 Validation loss: 0.947448 Validation acc: 0.706667\n",
      "Epoch: 118/152 Iteration: 5925 Train loss: 0.670729 Train acc: 0.750000\n",
      "Epoch: 118/152 Iteration: 5930 Train loss: 0.754759 Train acc: 0.750000\n",
      "Epoch: 118/152 Iteration: 5930 Validation loss: 0.950922 Validation acc: 0.710833\n",
      "Epoch: 118/152 Iteration: 5935 Train loss: 0.677306 Train acc: 0.770000\n",
      "Epoch: 118/152 Iteration: 5940 Train loss: 0.828645 Train acc: 0.730000\n",
      "Epoch: 118/152 Iteration: 5940 Validation loss: 0.945559 Validation acc: 0.704167\n",
      "Epoch: 118/152 Iteration: 5945 Train loss: 0.740231 Train acc: 0.740000\n",
      "Epoch: 118/152 Iteration: 5950 Train loss: 0.850573 Train acc: 0.680000\n",
      "Epoch: 118/152 Iteration: 5950 Validation loss: 0.944464 Validation acc: 0.699167\n",
      "Epoch: 119/152 Iteration: 5955 Train loss: 0.793327 Train acc: 0.730000\n",
      "Epoch: 119/152 Iteration: 5960 Train loss: 0.636651 Train acc: 0.800000\n",
      "Epoch: 119/152 Iteration: 5960 Validation loss: 0.963868 Validation acc: 0.695833\n",
      "Epoch: 119/152 Iteration: 5965 Train loss: 0.742606 Train acc: 0.780000\n",
      "Epoch: 119/152 Iteration: 5970 Train loss: 0.740987 Train acc: 0.780000\n",
      "Epoch: 119/152 Iteration: 5970 Validation loss: 0.946885 Validation acc: 0.705000\n",
      "Epoch: 119/152 Iteration: 5975 Train loss: 0.636459 Train acc: 0.760000\n",
      "Epoch: 119/152 Iteration: 5980 Train loss: 0.722642 Train acc: 0.750000\n",
      "Epoch: 119/152 Iteration: 5980 Validation loss: 0.947809 Validation acc: 0.710833\n",
      "Epoch: 119/152 Iteration: 5985 Train loss: 0.691061 Train acc: 0.760000\n",
      "Epoch: 119/152 Iteration: 5990 Train loss: 0.862297 Train acc: 0.750000\n",
      "Epoch: 119/152 Iteration: 5990 Validation loss: 0.939302 Validation acc: 0.695833\n",
      "Epoch: 119/152 Iteration: 5995 Train loss: 0.676079 Train acc: 0.760000\n",
      "Epoch: 119/152 Iteration: 6000 Train loss: 0.815606 Train acc: 0.750000\n",
      "Epoch: 119/152 Iteration: 6000 Validation loss: 0.936735 Validation acc: 0.710833\n",
      "Epoch: 120/152 Iteration: 6005 Train loss: 0.760161 Train acc: 0.720000\n",
      "Epoch: 120/152 Iteration: 6010 Train loss: 0.667227 Train acc: 0.790000\n",
      "Epoch: 120/152 Iteration: 6010 Validation loss: 0.936771 Validation acc: 0.713333\n",
      "Epoch: 120/152 Iteration: 6015 Train loss: 0.670052 Train acc: 0.800000\n",
      "Epoch: 120/152 Iteration: 6020 Train loss: 0.664568 Train acc: 0.760000\n",
      "Epoch: 120/152 Iteration: 6020 Validation loss: 0.940040 Validation acc: 0.710833\n",
      "Epoch: 120/152 Iteration: 6025 Train loss: 0.692001 Train acc: 0.790000\n",
      "Epoch: 120/152 Iteration: 6030 Train loss: 0.746812 Train acc: 0.690000\n",
      "Epoch: 120/152 Iteration: 6030 Validation loss: 0.948349 Validation acc: 0.708333\n",
      "Epoch: 120/152 Iteration: 6035 Train loss: 0.671573 Train acc: 0.750000\n",
      "Epoch: 120/152 Iteration: 6040 Train loss: 0.828532 Train acc: 0.760000\n",
      "Epoch: 120/152 Iteration: 6040 Validation loss: 0.939721 Validation acc: 0.704167\n",
      "Epoch: 120/152 Iteration: 6045 Train loss: 0.703106 Train acc: 0.790000\n",
      "Epoch: 120/152 Iteration: 6050 Train loss: 0.866291 Train acc: 0.700000\n",
      "Epoch: 120/152 Iteration: 6050 Validation loss: 0.933768 Validation acc: 0.705833\n",
      "Epoch: 121/152 Iteration: 6055 Train loss: 0.750232 Train acc: 0.720000\n",
      "Epoch: 121/152 Iteration: 6060 Train loss: 0.664356 Train acc: 0.800000\n",
      "Epoch: 121/152 Iteration: 6060 Validation loss: 0.951360 Validation acc: 0.711667\n",
      "Epoch: 121/152 Iteration: 6065 Train loss: 0.706477 Train acc: 0.780000\n",
      "Epoch: 121/152 Iteration: 6070 Train loss: 0.664009 Train acc: 0.780000\n",
      "Epoch: 121/152 Iteration: 6070 Validation loss: 0.939647 Validation acc: 0.700000\n",
      "Epoch: 121/152 Iteration: 6075 Train loss: 0.723785 Train acc: 0.750000\n",
      "Epoch: 121/152 Iteration: 6080 Train loss: 0.757873 Train acc: 0.690000\n",
      "Epoch: 121/152 Iteration: 6080 Validation loss: 0.953282 Validation acc: 0.720000\n",
      "Epoch: 121/152 Iteration: 6085 Train loss: 0.622916 Train acc: 0.790000\n",
      "Epoch: 121/152 Iteration: 6090 Train loss: 0.825317 Train acc: 0.750000\n",
      "Epoch: 121/152 Iteration: 6090 Validation loss: 0.937035 Validation acc: 0.703333\n",
      "Epoch: 121/152 Iteration: 6095 Train loss: 0.786812 Train acc: 0.720000\n",
      "Epoch: 121/152 Iteration: 6100 Train loss: 0.838348 Train acc: 0.740000\n",
      "Epoch: 121/152 Iteration: 6100 Validation loss: 0.946934 Validation acc: 0.698333\n",
      "Epoch: 122/152 Iteration: 6105 Train loss: 0.722193 Train acc: 0.760000\n",
      "Epoch: 122/152 Iteration: 6110 Train loss: 0.621276 Train acc: 0.820000\n",
      "Epoch: 122/152 Iteration: 6110 Validation loss: 0.973903 Validation acc: 0.704167\n",
      "Epoch: 122/152 Iteration: 6115 Train loss: 0.719489 Train acc: 0.780000\n",
      "Epoch: 122/152 Iteration: 6120 Train loss: 0.649463 Train acc: 0.820000\n",
      "Epoch: 122/152 Iteration: 6120 Validation loss: 0.941135 Validation acc: 0.710000\n",
      "Epoch: 122/152 Iteration: 6125 Train loss: 0.641449 Train acc: 0.770000\n",
      "Epoch: 122/152 Iteration: 6130 Train loss: 0.691816 Train acc: 0.740000\n",
      "Epoch: 122/152 Iteration: 6130 Validation loss: 0.955214 Validation acc: 0.705833\n",
      "Epoch: 122/152 Iteration: 6135 Train loss: 0.650665 Train acc: 0.780000\n",
      "Epoch: 122/152 Iteration: 6140 Train loss: 0.829589 Train acc: 0.710000\n",
      "Epoch: 122/152 Iteration: 6140 Validation loss: 0.935401 Validation acc: 0.709167\n",
      "Epoch: 122/152 Iteration: 6145 Train loss: 0.711691 Train acc: 0.760000\n",
      "Epoch: 122/152 Iteration: 6150 Train loss: 0.864245 Train acc: 0.700000\n",
      "Epoch: 122/152 Iteration: 6150 Validation loss: 0.932623 Validation acc: 0.708333\n",
      "Epoch: 123/152 Iteration: 6155 Train loss: 0.748855 Train acc: 0.730000\n",
      "Epoch: 123/152 Iteration: 6160 Train loss: 0.654653 Train acc: 0.780000\n",
      "Epoch: 123/152 Iteration: 6160 Validation loss: 0.951096 Validation acc: 0.715000\n",
      "Epoch: 123/152 Iteration: 6165 Train loss: 0.686861 Train acc: 0.780000\n",
      "Epoch: 123/152 Iteration: 6170 Train loss: 0.714570 Train acc: 0.790000\n",
      "Epoch: 123/152 Iteration: 6170 Validation loss: 0.941088 Validation acc: 0.705833\n",
      "Epoch: 123/152 Iteration: 6175 Train loss: 0.675248 Train acc: 0.740000\n",
      "Epoch: 123/152 Iteration: 6180 Train loss: 0.696923 Train acc: 0.760000\n",
      "Epoch: 123/152 Iteration: 6180 Validation loss: 0.941860 Validation acc: 0.704167\n",
      "Epoch: 123/152 Iteration: 6185 Train loss: 0.673671 Train acc: 0.780000\n",
      "Epoch: 123/152 Iteration: 6190 Train loss: 0.787941 Train acc: 0.750000\n",
      "Epoch: 123/152 Iteration: 6190 Validation loss: 0.934152 Validation acc: 0.707500\n",
      "Epoch: 123/152 Iteration: 6195 Train loss: 0.719922 Train acc: 0.740000\n",
      "Epoch: 123/152 Iteration: 6200 Train loss: 0.881764 Train acc: 0.690000\n",
      "Epoch: 123/152 Iteration: 6200 Validation loss: 0.925864 Validation acc: 0.709167\n",
      "Epoch: 124/152 Iteration: 6205 Train loss: 0.803267 Train acc: 0.690000\n",
      "Epoch: 124/152 Iteration: 6210 Train loss: 0.645455 Train acc: 0.810000\n",
      "Epoch: 124/152 Iteration: 6210 Validation loss: 0.933867 Validation acc: 0.718333\n",
      "Epoch: 124/152 Iteration: 6215 Train loss: 0.730909 Train acc: 0.760000\n",
      "Epoch: 124/152 Iteration: 6220 Train loss: 0.673453 Train acc: 0.790000\n",
      "Epoch: 124/152 Iteration: 6220 Validation loss: 0.929310 Validation acc: 0.706667\n",
      "Epoch: 124/152 Iteration: 6225 Train loss: 0.671613 Train acc: 0.750000\n",
      "Epoch: 124/152 Iteration: 6230 Train loss: 0.743975 Train acc: 0.720000\n",
      "Epoch: 124/152 Iteration: 6230 Validation loss: 0.937470 Validation acc: 0.710000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 124/152 Iteration: 6235 Train loss: 0.663028 Train acc: 0.760000\n",
      "Epoch: 124/152 Iteration: 6240 Train loss: 0.805839 Train acc: 0.770000\n",
      "Epoch: 124/152 Iteration: 6240 Validation loss: 0.931401 Validation acc: 0.710000\n",
      "Epoch: 124/152 Iteration: 6245 Train loss: 0.729812 Train acc: 0.750000\n",
      "Epoch: 124/152 Iteration: 6250 Train loss: 0.742075 Train acc: 0.800000\n",
      "Epoch: 124/152 Iteration: 6250 Validation loss: 0.927541 Validation acc: 0.706667\n",
      "Epoch: 125/152 Iteration: 6255 Train loss: 0.736416 Train acc: 0.690000\n",
      "Epoch: 125/152 Iteration: 6260 Train loss: 0.618454 Train acc: 0.810000\n",
      "Epoch: 125/152 Iteration: 6260 Validation loss: 0.960020 Validation acc: 0.710000\n",
      "Epoch: 125/152 Iteration: 6265 Train loss: 0.753027 Train acc: 0.760000\n",
      "Epoch: 125/152 Iteration: 6270 Train loss: 0.755097 Train acc: 0.780000\n",
      "Epoch: 125/152 Iteration: 6270 Validation loss: 0.938108 Validation acc: 0.706667\n",
      "Epoch: 125/152 Iteration: 6275 Train loss: 0.663967 Train acc: 0.790000\n",
      "Epoch: 125/152 Iteration: 6280 Train loss: 0.697247 Train acc: 0.730000\n",
      "Epoch: 125/152 Iteration: 6280 Validation loss: 0.930320 Validation acc: 0.715833\n",
      "Epoch: 125/152 Iteration: 6285 Train loss: 0.614787 Train acc: 0.770000\n",
      "Epoch: 125/152 Iteration: 6290 Train loss: 0.843874 Train acc: 0.730000\n",
      "Epoch: 125/152 Iteration: 6290 Validation loss: 0.928346 Validation acc: 0.705000\n",
      "Epoch: 125/152 Iteration: 6295 Train loss: 0.681720 Train acc: 0.780000\n",
      "Epoch: 125/152 Iteration: 6300 Train loss: 0.813492 Train acc: 0.760000\n",
      "Epoch: 125/152 Iteration: 6300 Validation loss: 0.921769 Validation acc: 0.718333\n",
      "Epoch: 126/152 Iteration: 6305 Train loss: 0.782024 Train acc: 0.700000\n",
      "Epoch: 126/152 Iteration: 6310 Train loss: 0.627823 Train acc: 0.790000\n",
      "Epoch: 126/152 Iteration: 6310 Validation loss: 0.935686 Validation acc: 0.714167\n",
      "Epoch: 126/152 Iteration: 6315 Train loss: 0.685898 Train acc: 0.790000\n",
      "Epoch: 126/152 Iteration: 6320 Train loss: 0.706387 Train acc: 0.790000\n",
      "Epoch: 126/152 Iteration: 6320 Validation loss: 0.925612 Validation acc: 0.702500\n",
      "Epoch: 126/152 Iteration: 6325 Train loss: 0.680344 Train acc: 0.720000\n",
      "Epoch: 126/152 Iteration: 6330 Train loss: 0.698477 Train acc: 0.720000\n",
      "Epoch: 126/152 Iteration: 6330 Validation loss: 0.930567 Validation acc: 0.717500\n",
      "Epoch: 126/152 Iteration: 6335 Train loss: 0.657977 Train acc: 0.770000\n",
      "Epoch: 126/152 Iteration: 6340 Train loss: 0.761253 Train acc: 0.760000\n",
      "Epoch: 126/152 Iteration: 6340 Validation loss: 0.921111 Validation acc: 0.710833\n",
      "Epoch: 126/152 Iteration: 6345 Train loss: 0.709041 Train acc: 0.730000\n",
      "Epoch: 126/152 Iteration: 6350 Train loss: 0.804231 Train acc: 0.700000\n",
      "Epoch: 126/152 Iteration: 6350 Validation loss: 0.924479 Validation acc: 0.711667\n",
      "Epoch: 127/152 Iteration: 6355 Train loss: 0.760348 Train acc: 0.710000\n",
      "Epoch: 127/152 Iteration: 6360 Train loss: 0.610174 Train acc: 0.800000\n",
      "Epoch: 127/152 Iteration: 6360 Validation loss: 0.945962 Validation acc: 0.706667\n",
      "Epoch: 127/152 Iteration: 6365 Train loss: 0.752763 Train acc: 0.770000\n",
      "Epoch: 127/152 Iteration: 6370 Train loss: 0.704742 Train acc: 0.790000\n",
      "Epoch: 127/152 Iteration: 6370 Validation loss: 0.938634 Validation acc: 0.705833\n",
      "Epoch: 127/152 Iteration: 6375 Train loss: 0.670469 Train acc: 0.740000\n",
      "Epoch: 127/152 Iteration: 6380 Train loss: 0.755144 Train acc: 0.740000\n",
      "Epoch: 127/152 Iteration: 6380 Validation loss: 0.954313 Validation acc: 0.717500\n",
      "Epoch: 127/152 Iteration: 6385 Train loss: 0.635562 Train acc: 0.790000\n",
      "Epoch: 127/152 Iteration: 6390 Train loss: 0.754266 Train acc: 0.760000\n",
      "Epoch: 127/152 Iteration: 6390 Validation loss: 0.931326 Validation acc: 0.706667\n",
      "Epoch: 127/152 Iteration: 6395 Train loss: 0.742828 Train acc: 0.740000\n",
      "Epoch: 127/152 Iteration: 6400 Train loss: 0.814170 Train acc: 0.720000\n",
      "Epoch: 127/152 Iteration: 6400 Validation loss: 0.933228 Validation acc: 0.713333\n",
      "Epoch: 128/152 Iteration: 6405 Train loss: 0.729585 Train acc: 0.720000\n",
      "Epoch: 128/152 Iteration: 6410 Train loss: 0.674511 Train acc: 0.810000\n",
      "Epoch: 128/152 Iteration: 6410 Validation loss: 0.954063 Validation acc: 0.708333\n",
      "Epoch: 128/152 Iteration: 6415 Train loss: 0.637783 Train acc: 0.790000\n",
      "Epoch: 128/152 Iteration: 6420 Train loss: 0.664994 Train acc: 0.770000\n",
      "Epoch: 128/152 Iteration: 6420 Validation loss: 0.937516 Validation acc: 0.710833\n",
      "Epoch: 128/152 Iteration: 6425 Train loss: 0.673340 Train acc: 0.790000\n",
      "Epoch: 128/152 Iteration: 6430 Train loss: 0.679672 Train acc: 0.750000\n",
      "Epoch: 128/152 Iteration: 6430 Validation loss: 0.942932 Validation acc: 0.710000\n",
      "Epoch: 128/152 Iteration: 6435 Train loss: 0.656967 Train acc: 0.760000\n",
      "Epoch: 128/152 Iteration: 6440 Train loss: 0.805397 Train acc: 0.780000\n",
      "Epoch: 128/152 Iteration: 6440 Validation loss: 0.930515 Validation acc: 0.699167\n",
      "Epoch: 128/152 Iteration: 6445 Train loss: 0.754773 Train acc: 0.720000\n",
      "Epoch: 128/152 Iteration: 6450 Train loss: 0.829502 Train acc: 0.750000\n",
      "Epoch: 128/152 Iteration: 6450 Validation loss: 0.930654 Validation acc: 0.710833\n",
      "Epoch: 129/152 Iteration: 6455 Train loss: 0.769156 Train acc: 0.700000\n",
      "Epoch: 129/152 Iteration: 6460 Train loss: 0.622869 Train acc: 0.810000\n",
      "Epoch: 129/152 Iteration: 6460 Validation loss: 0.940849 Validation acc: 0.715833\n",
      "Epoch: 129/152 Iteration: 6465 Train loss: 0.708027 Train acc: 0.790000\n",
      "Epoch: 129/152 Iteration: 6470 Train loss: 0.659169 Train acc: 0.830000\n",
      "Epoch: 129/152 Iteration: 6470 Validation loss: 0.928750 Validation acc: 0.702500\n",
      "Epoch: 129/152 Iteration: 6475 Train loss: 0.647113 Train acc: 0.760000\n",
      "Epoch: 129/152 Iteration: 6480 Train loss: 0.747117 Train acc: 0.730000\n",
      "Epoch: 129/152 Iteration: 6480 Validation loss: 0.934481 Validation acc: 0.710000\n",
      "Epoch: 129/152 Iteration: 6485 Train loss: 0.687655 Train acc: 0.800000\n",
      "Epoch: 129/152 Iteration: 6490 Train loss: 0.809687 Train acc: 0.760000\n",
      "Epoch: 129/152 Iteration: 6490 Validation loss: 0.921413 Validation acc: 0.709167\n",
      "Epoch: 129/152 Iteration: 6495 Train loss: 0.677940 Train acc: 0.770000\n",
      "Epoch: 129/152 Iteration: 6500 Train loss: 0.773407 Train acc: 0.730000\n",
      "Epoch: 129/152 Iteration: 6500 Validation loss: 0.932109 Validation acc: 0.710000\n",
      "Epoch: 130/152 Iteration: 6505 Train loss: 0.732118 Train acc: 0.720000\n",
      "Epoch: 130/152 Iteration: 6510 Train loss: 0.617345 Train acc: 0.800000\n",
      "Epoch: 130/152 Iteration: 6510 Validation loss: 0.952569 Validation acc: 0.702500\n",
      "Epoch: 130/152 Iteration: 6515 Train loss: 0.693822 Train acc: 0.770000\n",
      "Epoch: 130/152 Iteration: 6520 Train loss: 0.689528 Train acc: 0.810000\n",
      "Epoch: 130/152 Iteration: 6520 Validation loss: 0.931434 Validation acc: 0.708333\n",
      "Epoch: 130/152 Iteration: 6525 Train loss: 0.644994 Train acc: 0.760000\n",
      "Epoch: 130/152 Iteration: 6530 Train loss: 0.734318 Train acc: 0.740000\n",
      "Epoch: 130/152 Iteration: 6530 Validation loss: 0.943838 Validation acc: 0.710833\n",
      "Epoch: 130/152 Iteration: 6535 Train loss: 0.650855 Train acc: 0.800000\n",
      "Epoch: 130/152 Iteration: 6540 Train loss: 0.795888 Train acc: 0.760000\n",
      "Epoch: 130/152 Iteration: 6540 Validation loss: 0.930096 Validation acc: 0.705833\n",
      "Epoch: 130/152 Iteration: 6545 Train loss: 0.742003 Train acc: 0.730000\n",
      "Epoch: 130/152 Iteration: 6550 Train loss: 0.829529 Train acc: 0.740000\n",
      "Epoch: 130/152 Iteration: 6550 Validation loss: 0.932579 Validation acc: 0.705833\n",
      "Epoch: 131/152 Iteration: 6555 Train loss: 0.752009 Train acc: 0.720000\n",
      "Epoch: 131/152 Iteration: 6560 Train loss: 0.695129 Train acc: 0.780000\n",
      "Epoch: 131/152 Iteration: 6560 Validation loss: 0.961743 Validation acc: 0.706667\n",
      "Epoch: 131/152 Iteration: 6565 Train loss: 0.636864 Train acc: 0.790000\n",
      "Epoch: 131/152 Iteration: 6570 Train loss: 0.746941 Train acc: 0.760000\n",
      "Epoch: 131/152 Iteration: 6570 Validation loss: 0.926716 Validation acc: 0.708333\n",
      "Epoch: 131/152 Iteration: 6575 Train loss: 0.644383 Train acc: 0.800000\n",
      "Epoch: 131/152 Iteration: 6580 Train loss: 0.682567 Train acc: 0.760000\n",
      "Epoch: 131/152 Iteration: 6580 Validation loss: 0.947685 Validation acc: 0.711667\n",
      "Epoch: 131/152 Iteration: 6585 Train loss: 0.639611 Train acc: 0.810000\n",
      "Epoch: 131/152 Iteration: 6590 Train loss: 0.757420 Train acc: 0.780000\n",
      "Epoch: 131/152 Iteration: 6590 Validation loss: 0.940126 Validation acc: 0.704167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 131/152 Iteration: 6595 Train loss: 0.666453 Train acc: 0.770000\n",
      "Epoch: 131/152 Iteration: 6600 Train loss: 0.818522 Train acc: 0.700000\n",
      "Epoch: 131/152 Iteration: 6600 Validation loss: 0.931692 Validation acc: 0.718333\n",
      "Epoch: 132/152 Iteration: 6605 Train loss: 0.747804 Train acc: 0.720000\n",
      "Epoch: 132/152 Iteration: 6610 Train loss: 0.635397 Train acc: 0.780000\n",
      "Epoch: 132/152 Iteration: 6610 Validation loss: 0.949917 Validation acc: 0.715833\n",
      "Epoch: 132/152 Iteration: 6615 Train loss: 0.702196 Train acc: 0.780000\n",
      "Epoch: 132/152 Iteration: 6620 Train loss: 0.710215 Train acc: 0.770000\n",
      "Epoch: 132/152 Iteration: 6620 Validation loss: 0.941173 Validation acc: 0.704167\n",
      "Epoch: 132/152 Iteration: 6625 Train loss: 0.679410 Train acc: 0.740000\n",
      "Epoch: 132/152 Iteration: 6630 Train loss: 0.712501 Train acc: 0.700000\n",
      "Epoch: 132/152 Iteration: 6630 Validation loss: 0.948664 Validation acc: 0.709167\n",
      "Epoch: 132/152 Iteration: 6635 Train loss: 0.618091 Train acc: 0.790000\n",
      "Epoch: 132/152 Iteration: 6640 Train loss: 0.805989 Train acc: 0.760000\n",
      "Epoch: 132/152 Iteration: 6640 Validation loss: 0.938624 Validation acc: 0.710833\n",
      "Epoch: 132/152 Iteration: 6645 Train loss: 0.683929 Train acc: 0.750000\n",
      "Epoch: 132/152 Iteration: 6650 Train loss: 0.814267 Train acc: 0.720000\n",
      "Epoch: 132/152 Iteration: 6650 Validation loss: 0.937592 Validation acc: 0.709167\n",
      "Epoch: 133/152 Iteration: 6655 Train loss: 0.710650 Train acc: 0.740000\n",
      "Epoch: 133/152 Iteration: 6660 Train loss: 0.601076 Train acc: 0.760000\n",
      "Epoch: 133/152 Iteration: 6660 Validation loss: 0.946516 Validation acc: 0.712500\n",
      "Epoch: 133/152 Iteration: 6665 Train loss: 0.642052 Train acc: 0.800000\n",
      "Epoch: 133/152 Iteration: 6670 Train loss: 0.700442 Train acc: 0.760000\n",
      "Epoch: 133/152 Iteration: 6670 Validation loss: 0.936221 Validation acc: 0.713333\n",
      "Epoch: 133/152 Iteration: 6675 Train loss: 0.654481 Train acc: 0.720000\n",
      "Epoch: 133/152 Iteration: 6680 Train loss: 0.735066 Train acc: 0.730000\n",
      "Epoch: 133/152 Iteration: 6680 Validation loss: 0.948777 Validation acc: 0.711667\n",
      "Epoch: 133/152 Iteration: 6685 Train loss: 0.650685 Train acc: 0.790000\n",
      "Epoch: 133/152 Iteration: 6690 Train loss: 0.831638 Train acc: 0.740000\n",
      "Epoch: 133/152 Iteration: 6690 Validation loss: 0.937499 Validation acc: 0.710833\n",
      "Epoch: 133/152 Iteration: 6695 Train loss: 0.712487 Train acc: 0.780000\n",
      "Epoch: 133/152 Iteration: 6700 Train loss: 0.779921 Train acc: 0.740000\n",
      "Epoch: 133/152 Iteration: 6700 Validation loss: 0.927924 Validation acc: 0.722500\n",
      "Epoch: 134/152 Iteration: 6705 Train loss: 0.752145 Train acc: 0.710000\n",
      "Epoch: 134/152 Iteration: 6710 Train loss: 0.593816 Train acc: 0.800000\n",
      "Epoch: 134/152 Iteration: 6710 Validation loss: 0.936725 Validation acc: 0.713333\n",
      "Epoch: 134/152 Iteration: 6715 Train loss: 0.682601 Train acc: 0.770000\n",
      "Epoch: 134/152 Iteration: 6720 Train loss: 0.653740 Train acc: 0.800000\n",
      "Epoch: 134/152 Iteration: 6720 Validation loss: 0.930264 Validation acc: 0.715833\n",
      "Epoch: 134/152 Iteration: 6725 Train loss: 0.588874 Train acc: 0.790000\n",
      "Epoch: 134/152 Iteration: 6730 Train loss: 0.752923 Train acc: 0.730000\n",
      "Epoch: 134/152 Iteration: 6730 Validation loss: 0.932779 Validation acc: 0.711667\n",
      "Epoch: 134/152 Iteration: 6735 Train loss: 0.630758 Train acc: 0.790000\n",
      "Epoch: 134/152 Iteration: 6740 Train loss: 0.846280 Train acc: 0.700000\n",
      "Epoch: 134/152 Iteration: 6740 Validation loss: 0.924428 Validation acc: 0.704167\n",
      "Epoch: 134/152 Iteration: 6745 Train loss: 0.668518 Train acc: 0.770000\n",
      "Epoch: 134/152 Iteration: 6750 Train loss: 0.794823 Train acc: 0.730000\n",
      "Epoch: 134/152 Iteration: 6750 Validation loss: 0.933745 Validation acc: 0.708333\n",
      "Epoch: 135/152 Iteration: 6755 Train loss: 0.714440 Train acc: 0.720000\n",
      "Epoch: 135/152 Iteration: 6760 Train loss: 0.591934 Train acc: 0.800000\n",
      "Epoch: 135/152 Iteration: 6760 Validation loss: 0.942763 Validation acc: 0.710833\n",
      "Epoch: 135/152 Iteration: 6765 Train loss: 0.717675 Train acc: 0.790000\n",
      "Epoch: 135/152 Iteration: 6770 Train loss: 0.710248 Train acc: 0.790000\n",
      "Epoch: 135/152 Iteration: 6770 Validation loss: 0.922773 Validation acc: 0.719167\n",
      "Epoch: 135/152 Iteration: 6775 Train loss: 0.704614 Train acc: 0.730000\n",
      "Epoch: 135/152 Iteration: 6780 Train loss: 0.672867 Train acc: 0.770000\n",
      "Epoch: 135/152 Iteration: 6780 Validation loss: 0.931163 Validation acc: 0.715000\n",
      "Epoch: 135/152 Iteration: 6785 Train loss: 0.604161 Train acc: 0.780000\n",
      "Epoch: 135/152 Iteration: 6790 Train loss: 0.804243 Train acc: 0.740000\n",
      "Epoch: 135/152 Iteration: 6790 Validation loss: 0.937241 Validation acc: 0.715833\n",
      "Epoch: 135/152 Iteration: 6795 Train loss: 0.748859 Train acc: 0.780000\n",
      "Epoch: 135/152 Iteration: 6800 Train loss: 0.771743 Train acc: 0.740000\n",
      "Epoch: 135/152 Iteration: 6800 Validation loss: 0.926628 Validation acc: 0.714167\n",
      "Epoch: 136/152 Iteration: 6805 Train loss: 0.709304 Train acc: 0.750000\n",
      "Epoch: 136/152 Iteration: 6810 Train loss: 0.655384 Train acc: 0.780000\n",
      "Epoch: 136/152 Iteration: 6810 Validation loss: 0.957852 Validation acc: 0.700833\n",
      "Epoch: 136/152 Iteration: 6815 Train loss: 0.684758 Train acc: 0.750000\n",
      "Epoch: 136/152 Iteration: 6820 Train loss: 0.751996 Train acc: 0.770000\n",
      "Epoch: 136/152 Iteration: 6820 Validation loss: 0.949387 Validation acc: 0.711667\n",
      "Epoch: 136/152 Iteration: 6825 Train loss: 0.676874 Train acc: 0.770000\n",
      "Epoch: 136/152 Iteration: 6830 Train loss: 0.705250 Train acc: 0.730000\n",
      "Epoch: 136/152 Iteration: 6830 Validation loss: 0.961331 Validation acc: 0.710833\n",
      "Epoch: 136/152 Iteration: 6835 Train loss: 0.591701 Train acc: 0.780000\n",
      "Epoch: 136/152 Iteration: 6840 Train loss: 0.739218 Train acc: 0.740000\n",
      "Epoch: 136/152 Iteration: 6840 Validation loss: 0.940356 Validation acc: 0.706667\n",
      "Epoch: 136/152 Iteration: 6845 Train loss: 0.630186 Train acc: 0.760000\n",
      "Epoch: 136/152 Iteration: 6850 Train loss: 0.872230 Train acc: 0.690000\n",
      "Epoch: 136/152 Iteration: 6850 Validation loss: 0.936961 Validation acc: 0.710000\n",
      "Epoch: 137/152 Iteration: 6855 Train loss: 0.716973 Train acc: 0.740000\n",
      "Epoch: 137/152 Iteration: 6860 Train loss: 0.555568 Train acc: 0.830000\n",
      "Epoch: 137/152 Iteration: 6860 Validation loss: 0.955024 Validation acc: 0.707500\n",
      "Epoch: 137/152 Iteration: 6865 Train loss: 0.640275 Train acc: 0.790000\n",
      "Epoch: 137/152 Iteration: 6870 Train loss: 0.757700 Train acc: 0.740000\n",
      "Epoch: 137/152 Iteration: 6870 Validation loss: 0.936096 Validation acc: 0.713333\n",
      "Epoch: 137/152 Iteration: 6875 Train loss: 0.629858 Train acc: 0.830000\n",
      "Epoch: 137/152 Iteration: 6880 Train loss: 0.677742 Train acc: 0.760000\n",
      "Epoch: 137/152 Iteration: 6880 Validation loss: 0.935873 Validation acc: 0.717500\n",
      "Epoch: 137/152 Iteration: 6885 Train loss: 0.645560 Train acc: 0.770000\n",
      "Epoch: 137/152 Iteration: 6890 Train loss: 0.739296 Train acc: 0.760000\n",
      "Epoch: 137/152 Iteration: 6890 Validation loss: 0.926588 Validation acc: 0.711667\n",
      "Epoch: 137/152 Iteration: 6895 Train loss: 0.688827 Train acc: 0.770000\n",
      "Epoch: 137/152 Iteration: 6900 Train loss: 0.731618 Train acc: 0.780000\n",
      "Epoch: 137/152 Iteration: 6900 Validation loss: 0.929462 Validation acc: 0.707500\n",
      "Epoch: 138/152 Iteration: 6905 Train loss: 0.710822 Train acc: 0.730000\n",
      "Epoch: 138/152 Iteration: 6910 Train loss: 0.581810 Train acc: 0.810000\n",
      "Epoch: 138/152 Iteration: 6910 Validation loss: 0.949040 Validation acc: 0.710000\n",
      "Epoch: 138/152 Iteration: 6915 Train loss: 0.655072 Train acc: 0.770000\n",
      "Epoch: 138/152 Iteration: 6920 Train loss: 0.654827 Train acc: 0.790000\n",
      "Epoch: 138/152 Iteration: 6920 Validation loss: 0.939619 Validation acc: 0.712500\n",
      "Epoch: 138/152 Iteration: 6925 Train loss: 0.643502 Train acc: 0.780000\n",
      "Epoch: 138/152 Iteration: 6930 Train loss: 0.698953 Train acc: 0.760000\n",
      "Epoch: 138/152 Iteration: 6930 Validation loss: 0.954431 Validation acc: 0.708333\n",
      "Epoch: 138/152 Iteration: 6935 Train loss: 0.625217 Train acc: 0.820000\n",
      "Epoch: 138/152 Iteration: 6940 Train loss: 0.772157 Train acc: 0.720000\n",
      "Epoch: 138/152 Iteration: 6940 Validation loss: 0.937958 Validation acc: 0.703333\n",
      "Epoch: 138/152 Iteration: 6945 Train loss: 0.728030 Train acc: 0.740000\n",
      "Epoch: 138/152 Iteration: 6950 Train loss: 0.789766 Train acc: 0.740000\n",
      "Epoch: 138/152 Iteration: 6950 Validation loss: 0.924634 Validation acc: 0.710833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 139/152 Iteration: 6955 Train loss: 0.733456 Train acc: 0.730000\n",
      "Epoch: 139/152 Iteration: 6960 Train loss: 0.631171 Train acc: 0.800000\n",
      "Epoch: 139/152 Iteration: 6960 Validation loss: 0.942381 Validation acc: 0.709167\n",
      "Epoch: 139/152 Iteration: 6965 Train loss: 0.749707 Train acc: 0.740000\n",
      "Epoch: 139/152 Iteration: 6970 Train loss: 0.685687 Train acc: 0.800000\n",
      "Epoch: 139/152 Iteration: 6970 Validation loss: 0.932078 Validation acc: 0.707500\n",
      "Epoch: 139/152 Iteration: 6975 Train loss: 0.614222 Train acc: 0.800000\n",
      "Epoch: 139/152 Iteration: 6980 Train loss: 0.708246 Train acc: 0.760000\n",
      "Epoch: 139/152 Iteration: 6980 Validation loss: 0.942046 Validation acc: 0.715833\n",
      "Epoch: 139/152 Iteration: 6985 Train loss: 0.603242 Train acc: 0.800000\n",
      "Epoch: 139/152 Iteration: 6990 Train loss: 0.775514 Train acc: 0.770000\n",
      "Epoch: 139/152 Iteration: 6990 Validation loss: 0.931643 Validation acc: 0.710833\n",
      "Epoch: 139/152 Iteration: 6995 Train loss: 0.742771 Train acc: 0.740000\n",
      "Epoch: 139/152 Iteration: 7000 Train loss: 0.780586 Train acc: 0.760000\n",
      "Epoch: 139/152 Iteration: 7000 Validation loss: 0.928054 Validation acc: 0.711667\n",
      "Epoch: 140/152 Iteration: 7005 Train loss: 0.726302 Train acc: 0.710000\n",
      "Epoch: 140/152 Iteration: 7010 Train loss: 0.557923 Train acc: 0.810000\n",
      "Epoch: 140/152 Iteration: 7010 Validation loss: 0.936125 Validation acc: 0.714167\n",
      "Epoch: 140/152 Iteration: 7015 Train loss: 0.632994 Train acc: 0.790000\n",
      "Epoch: 140/152 Iteration: 7020 Train loss: 0.611125 Train acc: 0.800000\n",
      "Epoch: 140/152 Iteration: 7020 Validation loss: 0.923354 Validation acc: 0.714167\n",
      "Epoch: 140/152 Iteration: 7025 Train loss: 0.667687 Train acc: 0.770000\n",
      "Epoch: 140/152 Iteration: 7030 Train loss: 0.649780 Train acc: 0.770000\n",
      "Epoch: 140/152 Iteration: 7030 Validation loss: 0.936989 Validation acc: 0.710000\n",
      "Epoch: 140/152 Iteration: 7035 Train loss: 0.646635 Train acc: 0.790000\n",
      "Epoch: 140/152 Iteration: 7040 Train loss: 0.709779 Train acc: 0.780000\n",
      "Epoch: 140/152 Iteration: 7040 Validation loss: 0.915875 Validation acc: 0.718333\n",
      "Epoch: 140/152 Iteration: 7045 Train loss: 0.677371 Train acc: 0.770000\n",
      "Epoch: 140/152 Iteration: 7050 Train loss: 0.753984 Train acc: 0.720000\n",
      "Epoch: 140/152 Iteration: 7050 Validation loss: 0.926739 Validation acc: 0.715833\n",
      "Epoch: 141/152 Iteration: 7055 Train loss: 0.677734 Train acc: 0.730000\n",
      "Epoch: 141/152 Iteration: 7060 Train loss: 0.588501 Train acc: 0.810000\n",
      "Epoch: 141/152 Iteration: 7060 Validation loss: 0.938569 Validation acc: 0.712500\n",
      "Epoch: 141/152 Iteration: 7065 Train loss: 0.687022 Train acc: 0.790000\n",
      "Epoch: 141/152 Iteration: 7070 Train loss: 0.645311 Train acc: 0.800000\n",
      "Epoch: 141/152 Iteration: 7070 Validation loss: 0.923648 Validation acc: 0.716667\n",
      "Epoch: 141/152 Iteration: 7075 Train loss: 0.608840 Train acc: 0.800000\n",
      "Epoch: 141/152 Iteration: 7080 Train loss: 0.665388 Train acc: 0.780000\n",
      "Epoch: 141/152 Iteration: 7080 Validation loss: 0.935715 Validation acc: 0.714167\n",
      "Epoch: 141/152 Iteration: 7085 Train loss: 0.601287 Train acc: 0.790000\n",
      "Epoch: 141/152 Iteration: 7090 Train loss: 0.732841 Train acc: 0.750000\n",
      "Epoch: 141/152 Iteration: 7090 Validation loss: 0.929192 Validation acc: 0.714167\n",
      "Epoch: 141/152 Iteration: 7095 Train loss: 0.690610 Train acc: 0.770000\n",
      "Epoch: 141/152 Iteration: 7100 Train loss: 0.752510 Train acc: 0.730000\n",
      "Epoch: 141/152 Iteration: 7100 Validation loss: 0.924187 Validation acc: 0.715000\n",
      "Epoch: 142/152 Iteration: 7105 Train loss: 0.633210 Train acc: 0.800000\n",
      "Epoch: 142/152 Iteration: 7110 Train loss: 0.587683 Train acc: 0.820000\n",
      "Epoch: 142/152 Iteration: 7110 Validation loss: 0.940595 Validation acc: 0.714167\n",
      "Epoch: 142/152 Iteration: 7115 Train loss: 0.633475 Train acc: 0.790000\n",
      "Epoch: 142/152 Iteration: 7120 Train loss: 0.671161 Train acc: 0.810000\n",
      "Epoch: 142/152 Iteration: 7120 Validation loss: 0.926638 Validation acc: 0.720833\n",
      "Epoch: 142/152 Iteration: 7125 Train loss: 0.601234 Train acc: 0.820000\n",
      "Epoch: 142/152 Iteration: 7130 Train loss: 0.691398 Train acc: 0.740000\n",
      "Epoch: 142/152 Iteration: 7130 Validation loss: 0.925417 Validation acc: 0.718333\n",
      "Epoch: 142/152 Iteration: 7135 Train loss: 0.662502 Train acc: 0.770000\n",
      "Epoch: 142/152 Iteration: 7140 Train loss: 0.736142 Train acc: 0.790000\n",
      "Epoch: 142/152 Iteration: 7140 Validation loss: 0.931327 Validation acc: 0.712500\n",
      "Epoch: 142/152 Iteration: 7145 Train loss: 0.661719 Train acc: 0.760000\n",
      "Epoch: 142/152 Iteration: 7150 Train loss: 0.802450 Train acc: 0.740000\n",
      "Epoch: 142/152 Iteration: 7150 Validation loss: 0.926749 Validation acc: 0.716667\n",
      "Epoch: 143/152 Iteration: 7155 Train loss: 0.693599 Train acc: 0.760000\n",
      "Epoch: 143/152 Iteration: 7160 Train loss: 0.577401 Train acc: 0.820000\n",
      "Epoch: 143/152 Iteration: 7160 Validation loss: 0.936285 Validation acc: 0.713333\n",
      "Epoch: 143/152 Iteration: 7165 Train loss: 0.634789 Train acc: 0.820000\n",
      "Epoch: 143/152 Iteration: 7170 Train loss: 0.678752 Train acc: 0.800000\n",
      "Epoch: 143/152 Iteration: 7170 Validation loss: 0.927270 Validation acc: 0.718333\n",
      "Epoch: 143/152 Iteration: 7175 Train loss: 0.628418 Train acc: 0.770000\n",
      "Epoch: 143/152 Iteration: 7180 Train loss: 0.684030 Train acc: 0.750000\n",
      "Epoch: 143/152 Iteration: 7180 Validation loss: 0.930802 Validation acc: 0.718333\n",
      "Epoch: 143/152 Iteration: 7185 Train loss: 0.647865 Train acc: 0.820000\n",
      "Epoch: 143/152 Iteration: 7190 Train loss: 0.679362 Train acc: 0.780000\n",
      "Epoch: 143/152 Iteration: 7190 Validation loss: 0.923790 Validation acc: 0.715833\n",
      "Epoch: 143/152 Iteration: 7195 Train loss: 0.725603 Train acc: 0.770000\n",
      "Epoch: 143/152 Iteration: 7200 Train loss: 0.750226 Train acc: 0.750000\n",
      "Epoch: 143/152 Iteration: 7200 Validation loss: 0.913463 Validation acc: 0.714167\n",
      "Epoch: 144/152 Iteration: 7205 Train loss: 0.707095 Train acc: 0.720000\n",
      "Epoch: 144/152 Iteration: 7210 Train loss: 0.600429 Train acc: 0.830000\n",
      "Epoch: 144/152 Iteration: 7210 Validation loss: 0.941440 Validation acc: 0.704167\n",
      "Epoch: 144/152 Iteration: 7215 Train loss: 0.636068 Train acc: 0.820000\n",
      "Epoch: 144/152 Iteration: 7220 Train loss: 0.677291 Train acc: 0.780000\n",
      "Epoch: 144/152 Iteration: 7220 Validation loss: 0.936454 Validation acc: 0.722500\n",
      "Epoch: 144/152 Iteration: 7225 Train loss: 0.587785 Train acc: 0.800000\n",
      "Epoch: 144/152 Iteration: 7230 Train loss: 0.662923 Train acc: 0.750000\n",
      "Epoch: 144/152 Iteration: 7230 Validation loss: 0.939128 Validation acc: 0.711667\n",
      "Epoch: 144/152 Iteration: 7235 Train loss: 0.561919 Train acc: 0.810000\n",
      "Epoch: 144/152 Iteration: 7240 Train loss: 0.762881 Train acc: 0.760000\n",
      "Epoch: 144/152 Iteration: 7240 Validation loss: 0.932659 Validation acc: 0.709167\n",
      "Epoch: 144/152 Iteration: 7245 Train loss: 0.700083 Train acc: 0.750000\n",
      "Epoch: 144/152 Iteration: 7250 Train loss: 0.763095 Train acc: 0.760000\n",
      "Epoch: 144/152 Iteration: 7250 Validation loss: 0.919608 Validation acc: 0.712500\n",
      "Epoch: 145/152 Iteration: 7255 Train loss: 0.668243 Train acc: 0.730000\n",
      "Epoch: 145/152 Iteration: 7260 Train loss: 0.583733 Train acc: 0.830000\n",
      "Epoch: 145/152 Iteration: 7260 Validation loss: 0.939088 Validation acc: 0.710833\n",
      "Epoch: 145/152 Iteration: 7265 Train loss: 0.647158 Train acc: 0.820000\n",
      "Epoch: 145/152 Iteration: 7270 Train loss: 0.642964 Train acc: 0.770000\n",
      "Epoch: 145/152 Iteration: 7270 Validation loss: 0.938094 Validation acc: 0.713333\n",
      "Epoch: 145/152 Iteration: 7275 Train loss: 0.642791 Train acc: 0.790000\n",
      "Epoch: 145/152 Iteration: 7280 Train loss: 0.726124 Train acc: 0.740000\n",
      "Epoch: 145/152 Iteration: 7280 Validation loss: 0.935690 Validation acc: 0.714167\n",
      "Epoch: 145/152 Iteration: 7285 Train loss: 0.643951 Train acc: 0.790000\n",
      "Epoch: 145/152 Iteration: 7290 Train loss: 0.764192 Train acc: 0.770000\n",
      "Epoch: 145/152 Iteration: 7290 Validation loss: 0.922710 Validation acc: 0.721667\n",
      "Epoch: 145/152 Iteration: 7295 Train loss: 0.631236 Train acc: 0.820000\n",
      "Epoch: 145/152 Iteration: 7300 Train loss: 0.795806 Train acc: 0.730000\n",
      "Epoch: 145/152 Iteration: 7300 Validation loss: 0.917547 Validation acc: 0.715000\n",
      "Epoch: 146/152 Iteration: 7305 Train loss: 0.656042 Train acc: 0.750000\n",
      "Epoch: 146/152 Iteration: 7310 Train loss: 0.550397 Train acc: 0.780000\n",
      "Epoch: 146/152 Iteration: 7310 Validation loss: 0.936340 Validation acc: 0.710000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 146/152 Iteration: 7315 Train loss: 0.705087 Train acc: 0.760000\n",
      "Epoch: 146/152 Iteration: 7320 Train loss: 0.660333 Train acc: 0.800000\n",
      "Epoch: 146/152 Iteration: 7320 Validation loss: 0.932331 Validation acc: 0.707500\n",
      "Epoch: 146/152 Iteration: 7325 Train loss: 0.614202 Train acc: 0.770000\n",
      "Epoch: 146/152 Iteration: 7330 Train loss: 0.678229 Train acc: 0.750000\n",
      "Epoch: 146/152 Iteration: 7330 Validation loss: 0.943564 Validation acc: 0.714167\n",
      "Epoch: 146/152 Iteration: 7335 Train loss: 0.626970 Train acc: 0.790000\n",
      "Epoch: 146/152 Iteration: 7340 Train loss: 0.758712 Train acc: 0.770000\n",
      "Epoch: 146/152 Iteration: 7340 Validation loss: 0.922685 Validation acc: 0.715000\n",
      "Epoch: 146/152 Iteration: 7345 Train loss: 0.735606 Train acc: 0.780000\n",
      "Epoch: 146/152 Iteration: 7350 Train loss: 0.767446 Train acc: 0.770000\n",
      "Epoch: 146/152 Iteration: 7350 Validation loss: 0.917173 Validation acc: 0.719167\n",
      "Epoch: 147/152 Iteration: 7355 Train loss: 0.705169 Train acc: 0.730000\n",
      "Epoch: 147/152 Iteration: 7360 Train loss: 0.571565 Train acc: 0.810000\n",
      "Epoch: 147/152 Iteration: 7360 Validation loss: 0.930833 Validation acc: 0.711667\n",
      "Epoch: 147/152 Iteration: 7365 Train loss: 0.726576 Train acc: 0.810000\n",
      "Epoch: 147/152 Iteration: 7370 Train loss: 0.621407 Train acc: 0.800000\n",
      "Epoch: 147/152 Iteration: 7370 Validation loss: 0.930540 Validation acc: 0.724167\n",
      "Epoch: 147/152 Iteration: 7375 Train loss: 0.602033 Train acc: 0.810000\n",
      "Epoch: 147/152 Iteration: 7380 Train loss: 0.679850 Train acc: 0.740000\n",
      "Epoch: 147/152 Iteration: 7380 Validation loss: 0.943736 Validation acc: 0.709167\n",
      "Epoch: 147/152 Iteration: 7385 Train loss: 0.582637 Train acc: 0.830000\n",
      "Epoch: 147/152 Iteration: 7390 Train loss: 0.769428 Train acc: 0.780000\n",
      "Epoch: 147/152 Iteration: 7390 Validation loss: 0.920732 Validation acc: 0.720000\n",
      "Epoch: 147/152 Iteration: 7395 Train loss: 0.681502 Train acc: 0.790000\n",
      "Epoch: 147/152 Iteration: 7400 Train loss: 0.731125 Train acc: 0.770000\n",
      "Epoch: 147/152 Iteration: 7400 Validation loss: 0.919301 Validation acc: 0.720000\n",
      "Epoch: 148/152 Iteration: 7405 Train loss: 0.721092 Train acc: 0.720000\n",
      "Epoch: 148/152 Iteration: 7410 Train loss: 0.540125 Train acc: 0.810000\n",
      "Epoch: 148/152 Iteration: 7410 Validation loss: 0.950778 Validation acc: 0.707500\n",
      "Epoch: 148/152 Iteration: 7415 Train loss: 0.665701 Train acc: 0.800000\n",
      "Epoch: 148/152 Iteration: 7420 Train loss: 0.600740 Train acc: 0.810000\n",
      "Epoch: 148/152 Iteration: 7420 Validation loss: 0.933936 Validation acc: 0.712500\n",
      "Epoch: 148/152 Iteration: 7425 Train loss: 0.669803 Train acc: 0.730000\n",
      "Epoch: 148/152 Iteration: 7430 Train loss: 0.630396 Train acc: 0.780000\n",
      "Epoch: 148/152 Iteration: 7430 Validation loss: 0.942170 Validation acc: 0.714167\n",
      "Epoch: 148/152 Iteration: 7435 Train loss: 0.617285 Train acc: 0.790000\n",
      "Epoch: 148/152 Iteration: 7440 Train loss: 0.708494 Train acc: 0.780000\n",
      "Epoch: 148/152 Iteration: 7440 Validation loss: 0.944947 Validation acc: 0.710000\n",
      "Epoch: 148/152 Iteration: 7445 Train loss: 0.679398 Train acc: 0.740000\n",
      "Epoch: 148/152 Iteration: 7450 Train loss: 0.712397 Train acc: 0.750000\n",
      "Epoch: 148/152 Iteration: 7450 Validation loss: 0.923390 Validation acc: 0.717500\n",
      "Epoch: 149/152 Iteration: 7455 Train loss: 0.701897 Train acc: 0.710000\n",
      "Epoch: 149/152 Iteration: 7460 Train loss: 0.583804 Train acc: 0.770000\n",
      "Epoch: 149/152 Iteration: 7460 Validation loss: 0.943950 Validation acc: 0.712500\n",
      "Epoch: 149/152 Iteration: 7465 Train loss: 0.627464 Train acc: 0.810000\n",
      "Epoch: 149/152 Iteration: 7470 Train loss: 0.646608 Train acc: 0.800000\n",
      "Epoch: 149/152 Iteration: 7470 Validation loss: 0.936062 Validation acc: 0.713333\n",
      "Epoch: 149/152 Iteration: 7475 Train loss: 0.628293 Train acc: 0.760000\n",
      "Epoch: 149/152 Iteration: 7480 Train loss: 0.650414 Train acc: 0.760000\n",
      "Epoch: 149/152 Iteration: 7480 Validation loss: 0.931672 Validation acc: 0.715833\n",
      "Epoch: 149/152 Iteration: 7485 Train loss: 0.617687 Train acc: 0.780000\n",
      "Epoch: 149/152 Iteration: 7490 Train loss: 0.720798 Train acc: 0.790000\n",
      "Epoch: 149/152 Iteration: 7490 Validation loss: 0.930943 Validation acc: 0.719167\n",
      "Epoch: 149/152 Iteration: 7495 Train loss: 0.672331 Train acc: 0.770000\n",
      "Epoch: 149/152 Iteration: 7500 Train loss: 0.737191 Train acc: 0.730000\n",
      "Epoch: 149/152 Iteration: 7500 Validation loss: 0.924199 Validation acc: 0.713333\n",
      "Epoch: 150/152 Iteration: 7505 Train loss: 0.654737 Train acc: 0.790000\n",
      "Epoch: 150/152 Iteration: 7510 Train loss: 0.584576 Train acc: 0.780000\n",
      "Epoch: 150/152 Iteration: 7510 Validation loss: 0.944252 Validation acc: 0.715000\n",
      "Epoch: 150/152 Iteration: 7515 Train loss: 0.618572 Train acc: 0.780000\n",
      "Epoch: 150/152 Iteration: 7520 Train loss: 0.654356 Train acc: 0.810000\n",
      "Epoch: 150/152 Iteration: 7520 Validation loss: 0.933434 Validation acc: 0.715000\n",
      "Epoch: 150/152 Iteration: 7525 Train loss: 0.644631 Train acc: 0.770000\n",
      "Epoch: 150/152 Iteration: 7530 Train loss: 0.652239 Train acc: 0.770000\n",
      "Epoch: 150/152 Iteration: 7530 Validation loss: 0.947076 Validation acc: 0.715000\n",
      "Epoch: 150/152 Iteration: 7535 Train loss: 0.544640 Train acc: 0.820000\n",
      "Epoch: 150/152 Iteration: 7540 Train loss: 0.736784 Train acc: 0.760000\n",
      "Epoch: 150/152 Iteration: 7540 Validation loss: 0.929460 Validation acc: 0.710000\n",
      "Epoch: 150/152 Iteration: 7545 Train loss: 0.589854 Train acc: 0.770000\n",
      "Epoch: 150/152 Iteration: 7550 Train loss: 0.750220 Train acc: 0.760000\n",
      "Epoch: 150/152 Iteration: 7550 Validation loss: 0.925352 Validation acc: 0.717500\n",
      "Epoch: 151/152 Iteration: 7555 Train loss: 0.732030 Train acc: 0.720000\n",
      "Epoch: 151/152 Iteration: 7560 Train loss: 0.608820 Train acc: 0.790000\n",
      "Epoch: 151/152 Iteration: 7560 Validation loss: 0.936762 Validation acc: 0.712500\n",
      "Epoch: 151/152 Iteration: 7565 Train loss: 0.692454 Train acc: 0.770000\n",
      "Epoch: 151/152 Iteration: 7570 Train loss: 0.623454 Train acc: 0.840000\n",
      "Epoch: 151/152 Iteration: 7570 Validation loss: 0.925455 Validation acc: 0.720000\n",
      "Epoch: 151/152 Iteration: 7575 Train loss: 0.599427 Train acc: 0.800000\n",
      "Epoch: 151/152 Iteration: 7580 Train loss: 0.654096 Train acc: 0.760000\n",
      "Epoch: 151/152 Iteration: 7580 Validation loss: 0.941887 Validation acc: 0.709167\n",
      "Epoch: 151/152 Iteration: 7585 Train loss: 0.629777 Train acc: 0.760000\n",
      "Epoch: 151/152 Iteration: 7590 Train loss: 0.794102 Train acc: 0.740000\n",
      "Epoch: 151/152 Iteration: 7590 Validation loss: 0.924320 Validation acc: 0.710000\n",
      "Epoch: 151/152 Iteration: 7595 Train loss: 0.619307 Train acc: 0.760000\n",
      "Epoch: 151/152 Iteration: 7600 Train loss: 0.797945 Train acc: 0.740000\n",
      "Epoch: 151/152 Iteration: 7600 Validation loss: 0.916983 Validation acc: 0.724167\n"
     ]
    }
   ],
   "source": [
    "validation_acc = []\n",
    "validation_loss = []\n",
    "\n",
    "train_acc = []\n",
    "train_loss = []\n",
    "\n",
    "with graph.as_default():\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    iteration = 1\n",
    "   \n",
    "    # Loop over epochs\n",
    "    for e in range(epochs):\n",
    "        \n",
    "        # Loop over batches\n",
    "        for x,y,x_f,x_p in get_batches(X_tr, y_tr, X_tr_f, X_tr_p, batch_size):\n",
    "            \n",
    "            # Feed dictionary\n",
    "            feed = {inputs_ : x, labels_ : y, inputs2_ : x_f, inputs3_ : x_p, keep_prob_ : 0.5, learning_rate_ : learning_rate}\n",
    "            \n",
    "            # Loss\n",
    "            loss, _ , acc = sess.run([cost, optimizer, accuracy], feed_dict = feed)\n",
    "            train_acc.append(acc)\n",
    "            train_loss.append(loss)\n",
    "            \n",
    "            # Print at each 5 iters\n",
    "            if (iteration % 5 == 0):\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {:d}\".format(iteration),\n",
    "                      \"Train loss: {:6f}\".format(loss),\n",
    "                      \"Train acc: {:.6f}\".format(acc))\n",
    "            \n",
    "            # Compute validation loss at every 10 iterations\n",
    "            if (iteration%10 == 0):                \n",
    "                val_acc_ = []\n",
    "                val_loss_ = []\n",
    "                \n",
    "                for x_v, y_v, x_v_f, x_v_p in get_batches(X_vld, y_vld, X_vld_f, X_vld_p, batch_size):\n",
    "                    # Feed\n",
    "                    feed = {inputs_ : x_v, inputs2_ : x_v_f, inputs3_ : x_v_p, labels_ : y_v, keep_prob_ : 1.0}  \n",
    "                    \n",
    "                    # Loss\n",
    "                    loss_v, acc_v = sess.run([cost, accuracy], feed_dict = feed)                    \n",
    "                    val_acc_.append(acc_v)\n",
    "                    val_loss_.append(loss_v)\n",
    "                \n",
    "                # Print info\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {:d}\".format(iteration),\n",
    "                      \"Validation loss: {:6f}\".format(np.mean(val_loss_)),\n",
    "                      \"Validation acc: {:.6f}\".format(np.mean(val_acc_)))\n",
    "                \n",
    "                # Store\n",
    "                validation_acc.append(np.mean(val_acc_))\n",
    "                validation_loss.append(np.mean(val_loss_))\n",
    "            \n",
    "            # Iterate \n",
    "            iteration += 1\n",
    "    \n",
    "    saver.save(sess,\"checkpoints-cnn/har.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14f3a154908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training and test loss\n",
    "t = np.arange(iteration-1)\n",
    "\n",
    "plt.figure(figsize = (6,6))\n",
    "plt.plot(t, np.array(train_loss), 'r-', t[t % 10 == 0], np.array(validation_loss), 'b*')\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14f3a154eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Accuracies\n",
    "plt.figure(figsize = (6,6))\n",
    "\n",
    "plt.plot(t, np.array(train_acc), 'r-', t[t % 10 == 0], validation_acc, 'b*')\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"Accuray\")\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints-cnn\\har.ckpt\n",
      "Test accuracy: 0.733121\n",
      "Test loss: 0.886976\n"
     ]
    }
   ],
   "source": [
    "test_acc = []\n",
    "test_loss = []\n",
    "test_pred = []\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    # Restore\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints-cnn'))\n",
    "    \n",
    "    for x_t, y_t, x_t_f, x_t_p in get_batches(X_test, y_test, X_test_feats, X_test_p, 157):\n",
    "        feed = {inputs_: x_t,\n",
    "                labels_: y_t,\n",
    "                inputs2_: x_t_f,\n",
    "                inputs3_: x_t_p,\n",
    "                keep_prob_: 1}\n",
    "        \n",
    "        batch_loss, batch_acc = sess.run([cost, accuracy], feed_dict=feed)\n",
    "        test_acc.append(batch_acc)\n",
    "        test_loss.append(batch_loss)\n",
    "        \n",
    "        predict=tf.argmax(logits,1)\n",
    "        best = predict.eval(feed_dict=feed)\n",
    "        test_pred.append(best)\n",
    "    \n",
    "    print(\"Test accuracy: {:.6f}\".format(np.mean(test_acc)))\n",
    "    print(\"Test loss: {:.6f}\".format(np.mean(test_loss)))\n",
    "    \n",
    "    oof_preds = np.concatenate(test_pred, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9  2  2 ... 13  2 11]\n",
      "[ 9  2  2 ... 13  2 11]\n",
      "Normalized confusion matrix\n",
      "[[0.43333333 0.03333333 0.         0.13333333 0.03333333 0.03333333\n",
      "  0.1        0.         0.03333333 0.         0.03333333 0.06666667\n",
      "  0.         0.1       ]\n",
      " [0.01010101 0.73737374 0.         0.05050505 0.         0.\n",
      "  0.         0.         0.02020202 0.01010101 0.         0.17171717\n",
      "  0.         0.        ]\n",
      " [0.00540541 0.         0.97297297 0.         0.         0.\n",
      "  0.00540541 0.         0.00540541 0.         0.         0.\n",
      "  0.01081081 0.        ]\n",
      " [0.0041841  0.041841   0.         0.52301255 0.         0.\n",
      "  0.05857741 0.         0.0209205  0.         0.0041841  0.33472803\n",
      "  0.         0.0125523 ]\n",
      " [0.         0.02777778 0.         0.22222222 0.         0.\n",
      "  0.08333333 0.         0.         0.         0.         0.66666667\n",
      "  0.         0.        ]\n",
      " [0.16666667 0.         0.         0.         0.         0.83333333\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.01030928 0.01030928 0.         0.34020619 0.         0.\n",
      "  0.32989691 0.01030928 0.01030928 0.02061856 0.         0.2371134\n",
      "  0.         0.03092784]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.05       0.9        0.05       0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.00510204 0.         0.         0.\n",
      "  0.00510204 0.         0.93877551 0.         0.02040816 0.0255102\n",
      "  0.00510204 0.        ]\n",
      " [0.         0.         0.         0.14285714 0.         0.\n",
      "  0.11904762 0.         0.04761905 0.07142857 0.         0.61904762\n",
      "  0.         0.        ]\n",
      " [0.         0.02702703 0.01351351 0.01351351 0.         0.\n",
      "  0.         0.         0.02702703 0.         0.89189189 0.02702703\n",
      "  0.         0.        ]\n",
      " [0.00215983 0.01511879 0.00431965 0.05615551 0.         0.\n",
      "  0.00647948 0.         0.02159827 0.         0.         0.89416847\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.04166667 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.95833333 0.        ]\n",
      " [0.         0.08571429 0.         0.57142857 0.         0.\n",
      "  0.02857143 0.         0.         0.         0.02857143 0.02857143\n",
      "  0.         0.25714286]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14f278cf780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(np.asarray(labels_test))\n",
    "\n",
    "print(oof_preds+1)\n",
    "\n",
    "cnf_matrix = confusion_matrix(np.asarray(labels_test), oof_preds+1)\n",
    "sample_sub = pd.read_csv('sample_submission.csv')\n",
    "class_names = list(sample_sub.columns[1:-1])\n",
    "del sample_sub;gc.collect()\n",
    "plt.figure(figsize=(12,12))\n",
    "foo = plot_confusion_matrix(cnf_matrix, classes=class_names,normalize=True,\n",
    "                      title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
